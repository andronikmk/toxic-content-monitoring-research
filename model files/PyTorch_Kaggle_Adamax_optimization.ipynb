{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of TunedKaggleModel.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c04vBzVCuzhl",
        "colab_type": "code",
        "outputId": "05f4c869-3977-4b15-b1fe-d95ed502a4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 28.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.38.0)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrXx7f2Nup_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # to handle matrix and data operation\n",
        "import pandas as pd # to read csv and handle dataframe\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchnlp.word_to_vector import FastText\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TTCKRf2up_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_location = \"TCM_7.pt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZRDPcEup_p",
        "colab_type": "code",
        "outputId": "450fc68c-55f2-40e6-c872-5ef30adddd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "vectors = FastText()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "BATCH_SIZE = 96"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wiki.en.vec: 6.60GB [14:10, 7.76MB/s]                            \n",
            "  0%|          | 0/2519371 [00:00<?, ?it/s]Skipping token 2519370 with 1-dimensional vector ['300']; likely a header\n",
            "100%|██████████| 2519371/2519371 [04:52<00:00, 8609.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKwOSxLSU6dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN_OqaFDU7OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "cef56f8e-d3f4-412a-9f2d-db00ae5eb316"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbBI8eFup_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    '''Load dataset, data cleaned using Kaggle method.'''\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Big Armor/toxic-train-kaggle-clean.csv\")\n",
        "    df[\"word_splits\"] = df[\"word_splits\"].apply(eval)\n",
        "    df = df[(df[\"word_splits\"].apply(len) > 0) & (df[\"word_splits\"].apply(len) <= 560)]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df[\"word_splits\"], df.drop(\"word_splits\", axis=1), random_state=99, test_size=0.15)\n",
        "\n",
        "    X_train = X_train.values\n",
        "    y_train = y_train.values\n",
        "\n",
        "    X_test = X_test.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    batched_X_train = []\n",
        "    batched_y_train = []\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_train):\n",
        "        batched_X_train.append(X_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_train.append(y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_train.append(X_train[i*BATCH_SIZE:])\n",
        "    batched_y_train.append(y_train[i*BATCH_SIZE:])\n",
        "\n",
        "    batched_X_test = []\n",
        "    batched_y_test = []\n",
        "\n",
        "    del X_train\n",
        "    del y_train\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_test):\n",
        "        batched_X_test.append(X_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_test.append(y_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_test.append(X_test[i*BATCH_SIZE:])\n",
        "    batched_y_test.append(y_test[i*BATCH_SIZE:])\n",
        "\n",
        "    del X_test\n",
        "    del y_test\n",
        "\n",
        "    return batched_X_train, batched_y_train, batched_X_test, batched_y_test\n",
        "\n",
        "batched_X_train, batched_y_train, batched_X_test, batched_y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3NKRSqwup_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToxicClassifierModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512\n",
        "                 ):\n",
        "        super(ToxicClassifierModel, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.BiGRU = nn.GRU(300, hidden_size = LSTM_UNITS, bidirectional=True, num_layers=1)\n",
        "        self.BiRNN = nn.RNN(input_size = 2 * LSTM_UNITS, hidden_size = LSTM_UNITS, bidirectional=True)\n",
        "        self.hidden1 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden1Activation = hidden1Activation\n",
        "        self.hidden2 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden2Activation = hidden2Activation\n",
        "        self.hidden3 = nn.Linear(4 * LSTM_UNITS, 6)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = X.permute(0, 2, 1)\n",
        "        X = F.dropout2d(X, self.dropout_rate, training=self.training)\n",
        "        X = X.permute(0, 2, 1)\n",
        "        \n",
        "        X = self.BiGRU(X)\n",
        "        \n",
        "        X = self.BiRNN(X[0])\n",
        "        \n",
        "        X = X[0]\n",
        "        \n",
        "        X = torch.cat((torch.max(X, 1).values, torch.mean(X, 1)), 1)\n",
        "        \n",
        "        X = X.add(self.hidden1Activation(self.hidden1(X)))\n",
        "        \n",
        "        X = X.add(self.hidden2Activation(self.hidden2(X)))\n",
        "        \n",
        "        X = torch.sigmoid(self.hidden3(X))\n",
        "        \n",
        "        return X\n",
        "\n",
        "class ToxicClassifierFitter():\n",
        "    def __init__(self,\n",
        "                 optimizer,\n",
        "                 error,\n",
        "                 model,\n",
        "                 vectors,\n",
        "                 device,\n",
        "                 EPOCHS = 2,\n",
        "                 seed_acc = 0.5,\n",
        "                 save_checkpoint = True,\n",
        "                 model_save_location = model_save_location\n",
        "                 ):\n",
        "        self.optimizer = optimizer\n",
        "        self.error = error\n",
        "        self.model = model\n",
        "        self.EPOCHS = EPOCHS\n",
        "        self.acc = seed_acc\n",
        "        self.vectors = vectors\n",
        "        self.device = device\n",
        "        self.model_save_location = model_save_location\n",
        "        self.save_checkpoint = save_checkpoint\n",
        "    \n",
        "    def accuracy(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        self.acc = float(correct*100) / float(6 * BATCH_SIZE * len(batched_X_test))\n",
        "            \n",
        "        return self.acc\n",
        "\n",
        "    def F1Score(self, batched_X_test, batched_y_test):\n",
        "        preds = []\n",
        "        truePreds = []\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "            truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return f1_score(truePreds, preds)\n",
        "\n",
        "    def predict(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return predicted\n",
        "    \n",
        "    def fit(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            correct = 0\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Total correct predictions\n",
        "                predicted = output.data.round()\n",
        "                correct += (predicted == var_y_batch).sum()\n",
        "                #print(correct)\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, float(correct*100) / float(6 * BATCH_SIZE*(batch_idx+1))))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                del predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.accuracy(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation accuracy Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "\n",
        "    def fitF1(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            preds = []\n",
        "            truePreds = []\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "                truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t F1:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, f1_score(truePreds, preds)))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.F1Score(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation F1 Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "                \n",
        "\n",
        "def createFitter(LSTM_UNITS = 128,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 learning_rate=0.001,\n",
        "                 beta_1 = 0.9,\n",
        "                 beta_2 = 0.999,\n",
        "                 amsgrad=False,\n",
        "                 weight_decay=0,\n",
        "                 epochs = 1,\n",
        "                 model_save_location=model_save_location,\n",
        "                 vectors=vectors\n",
        "                 ):\n",
        "    \n",
        "    # get device\n",
        "    \n",
        "    model = ToxicClassifierModel(LSTM_UNITS = LSTM_UNITS,\n",
        "                                 dropout_rate = dropout_rate,\n",
        "                                 hidden1Activation = hidden1Activation,\n",
        "                                 hidden2Activation = hidden2Activation,\n",
        "                                 #hidden1Size = hidden1Size,\n",
        "                                 #hidden2Size = hidden2Size\n",
        "                                )\n",
        "    model.to(device)\n",
        "    \n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1,beta_2), amsgrad=amsgrad, weight_decay=weight_decay)\n",
        "\n",
        "    optimizer = torch.optim.Adamax(model.parameters(), lr=learning_rate, betas=(beta_1,beta_2), weight_decay=weight_decay)\n",
        "    \n",
        "    error = nn.BCELoss()\n",
        "    \n",
        "    # return final fitter \n",
        "\n",
        "    return ToxicClassifierFitter(optimizer, error,\n",
        "                                 model,\n",
        "                                 vectors,\n",
        "                                 device,\n",
        "                                 EPOCHS = epochs,\n",
        "                                 model_save_location = model_save_location,\n",
        "                                 save_checkpoint = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7UPlD23up_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_dict = {'relu':F.relu\n",
        "                  ,'leaky_relu':F.leaky_relu\n",
        "                  ,'softmax':F.softmax\n",
        "                  ,'selu':F.selu\n",
        "                  ,'tanh':F.tanh\n",
        "                  ,'sigmoid':torch.sigmoid\n",
        "                  ,'elu':F.elu\n",
        "                  }\n",
        "                      \n",
        "TCMFitter = createFitter(\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = activation_dict[\"relu\"],\n",
        "                 hidden2Activation = activation_dict[\"sigmoid\"],\n",
        "                 learning_rate = 1e-3, #0.002683035186257151,\n",
        "                 amsgrad = False,\n",
        "                 weight_decay = 0,\n",
        "                 epochs = 20\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enm-lmmIup_8",
        "colab_type": "code",
        "outputId": "71140f61-610c-4410-a704-11b294da9882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TCMFitter.model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Big Armor/TCM_2.pt\"))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9K5-NfSuqAD",
        "colab_type": "code",
        "outputId": "030be0fb-b83b-477d-c647-200e5dad19fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TCMFitter.fitF1(batched_X_train, batched_y_train, batched_X_test, batched_y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/1395 (0%)]\tLoss: 0.041375\t F1:0.696%\n",
            "Epoch : 0 [4800/1395 (4%)]\tLoss: 0.063367\t F1:0.760%\n",
            "Epoch : 0 [9600/1395 (7%)]\tLoss: 0.030748\t F1:0.768%\n",
            "Epoch : 0 [14400/1395 (11%)]\tLoss: 0.035718\t F1:0.760%\n",
            "Epoch : 0 [19200/1395 (14%)]\tLoss: 0.084591\t F1:0.760%\n",
            "Epoch : 0 [24000/1395 (18%)]\tLoss: 0.040829\t F1:0.759%\n",
            "Epoch : 0 [28800/1395 (22%)]\tLoss: 0.038186\t F1:0.758%\n",
            "Epoch : 0 [33600/1395 (25%)]\tLoss: 0.037616\t F1:0.759%\n",
            "Epoch : 0 [38400/1395 (29%)]\tLoss: 0.040687\t F1:0.760%\n",
            "Epoch : 0 [43200/1395 (32%)]\tLoss: 0.042657\t F1:0.761%\n",
            "Epoch : 0 [48000/1395 (36%)]\tLoss: 0.027223\t F1:0.762%\n",
            "Epoch : 0 [52800/1395 (39%)]\tLoss: 0.029626\t F1:0.762%\n",
            "Epoch : 0 [57600/1395 (43%)]\tLoss: 0.024181\t F1:0.763%\n",
            "Epoch : 0 [62400/1395 (47%)]\tLoss: 0.062037\t F1:0.763%\n",
            "Epoch : 0 [67200/1395 (50%)]\tLoss: 0.030517\t F1:0.761%\n",
            "Epoch : 0 [72000/1395 (54%)]\tLoss: 0.028989\t F1:0.761%\n",
            "Epoch : 0 [76800/1395 (57%)]\tLoss: 0.066981\t F1:0.761%\n",
            "Epoch : 0 [81600/1395 (61%)]\tLoss: 0.047291\t F1:0.760%\n",
            "Epoch : 0 [86400/1395 (65%)]\tLoss: 0.054126\t F1:0.759%\n",
            "Epoch : 0 [91200/1395 (68%)]\tLoss: 0.042102\t F1:0.759%\n",
            "Epoch : 0 [96000/1395 (72%)]\tLoss: 0.061090\t F1:0.759%\n",
            "Epoch : 0 [100800/1395 (75%)]\tLoss: 0.033839\t F1:0.759%\n",
            "Epoch : 0 [105600/1395 (79%)]\tLoss: 0.047562\t F1:0.759%\n",
            "Epoch : 0 [110400/1395 (82%)]\tLoss: 0.052741\t F1:0.760%\n",
            "Epoch : 0 [115200/1395 (86%)]\tLoss: 0.032236\t F1:0.760%\n",
            "Epoch : 0 [120000/1395 (90%)]\tLoss: 0.060593\t F1:0.759%\n",
            "Epoch : 0 [124800/1395 (93%)]\tLoss: 0.047579\t F1:0.760%\n",
            "Epoch : 0 [129600/1395 (97%)]\tLoss: 0.043895\t F1:0.760%\n",
            "Validation F1 Score: 0.7667943277093469\n",
            "Saving best model...\n",
            "Epoch : 1 [0/1395 (0%)]\tLoss: 0.028576\t F1:0.809%\n",
            "Epoch : 1 [4800/1395 (4%)]\tLoss: 0.048764\t F1:0.795%\n",
            "Epoch : 1 [9600/1395 (7%)]\tLoss: 0.027587\t F1:0.796%\n",
            "Epoch : 1 [14400/1395 (11%)]\tLoss: 0.028438\t F1:0.788%\n",
            "Epoch : 1 [19200/1395 (14%)]\tLoss: 0.072937\t F1:0.788%\n",
            "Epoch : 1 [24000/1395 (18%)]\tLoss: 0.034995\t F1:0.786%\n",
            "Epoch : 1 [28800/1395 (22%)]\tLoss: 0.038763\t F1:0.783%\n",
            "Epoch : 1 [33600/1395 (25%)]\tLoss: 0.040249\t F1:0.782%\n",
            "Epoch : 1 [38400/1395 (29%)]\tLoss: 0.040574\t F1:0.781%\n",
            "Epoch : 1 [43200/1395 (32%)]\tLoss: 0.046795\t F1:0.781%\n",
            "Epoch : 1 [48000/1395 (36%)]\tLoss: 0.027853\t F1:0.781%\n",
            "Epoch : 1 [52800/1395 (39%)]\tLoss: 0.037586\t F1:0.781%\n",
            "Epoch : 1 [57600/1395 (43%)]\tLoss: 0.024121\t F1:0.781%\n",
            "Epoch : 1 [62400/1395 (47%)]\tLoss: 0.053845\t F1:0.780%\n",
            "Epoch : 1 [67200/1395 (50%)]\tLoss: 0.024831\t F1:0.778%\n",
            "Epoch : 1 [72000/1395 (54%)]\tLoss: 0.031427\t F1:0.778%\n",
            "Epoch : 1 [76800/1395 (57%)]\tLoss: 0.067313\t F1:0.778%\n",
            "Epoch : 1 [81600/1395 (61%)]\tLoss: 0.051130\t F1:0.777%\n",
            "Epoch : 1 [86400/1395 (65%)]\tLoss: 0.050529\t F1:0.776%\n",
            "Epoch : 1 [91200/1395 (68%)]\tLoss: 0.040933\t F1:0.776%\n",
            "Epoch : 1 [96000/1395 (72%)]\tLoss: 0.060338\t F1:0.776%\n",
            "Epoch : 1 [100800/1395 (75%)]\tLoss: 0.029275\t F1:0.776%\n",
            "Epoch : 1 [105600/1395 (79%)]\tLoss: 0.035668\t F1:0.776%\n",
            "Epoch : 1 [110400/1395 (82%)]\tLoss: 0.047454\t F1:0.777%\n",
            "Epoch : 1 [115200/1395 (86%)]\tLoss: 0.032633\t F1:0.776%\n",
            "Epoch : 1 [120000/1395 (90%)]\tLoss: 0.048919\t F1:0.775%\n",
            "Epoch : 1 [124800/1395 (93%)]\tLoss: 0.043356\t F1:0.775%\n",
            "Epoch : 1 [129600/1395 (97%)]\tLoss: 0.048730\t F1:0.775%\n",
            "Validation F1 Score: 0.7678441935149694\n",
            "Saving best model...\n",
            "Epoch : 2 [0/1395 (0%)]\tLoss: 0.029900\t F1:0.851%\n",
            "Epoch : 2 [4800/1395 (4%)]\tLoss: 0.043696\t F1:0.812%\n",
            "Epoch : 2 [9600/1395 (7%)]\tLoss: 0.031367\t F1:0.812%\n",
            "Epoch : 2 [14400/1395 (11%)]\tLoss: 0.029019\t F1:0.801%\n",
            "Epoch : 2 [19200/1395 (14%)]\tLoss: 0.044195\t F1:0.799%\n",
            "Epoch : 2 [24000/1395 (18%)]\tLoss: 0.036613\t F1:0.796%\n",
            "Epoch : 2 [28800/1395 (22%)]\tLoss: 0.035527\t F1:0.793%\n",
            "Epoch : 2 [33600/1395 (25%)]\tLoss: 0.039502\t F1:0.792%\n",
            "Epoch : 2 [38400/1395 (29%)]\tLoss: 0.033094\t F1:0.790%\n",
            "Epoch : 2 [43200/1395 (32%)]\tLoss: 0.043792\t F1:0.789%\n",
            "Epoch : 2 [48000/1395 (36%)]\tLoss: 0.029784\t F1:0.790%\n",
            "Epoch : 2 [52800/1395 (39%)]\tLoss: 0.029745\t F1:0.790%\n",
            "Epoch : 2 [57600/1395 (43%)]\tLoss: 0.023921\t F1:0.790%\n",
            "Epoch : 2 [62400/1395 (47%)]\tLoss: 0.059461\t F1:0.790%\n",
            "Epoch : 2 [67200/1395 (50%)]\tLoss: 0.025854\t F1:0.788%\n",
            "Epoch : 2 [72000/1395 (54%)]\tLoss: 0.030942\t F1:0.788%\n",
            "Epoch : 2 [76800/1395 (57%)]\tLoss: 0.060066\t F1:0.788%\n",
            "Epoch : 2 [81600/1395 (61%)]\tLoss: 0.054554\t F1:0.787%\n",
            "Epoch : 2 [86400/1395 (65%)]\tLoss: 0.042341\t F1:0.786%\n",
            "Epoch : 2 [91200/1395 (68%)]\tLoss: 0.041037\t F1:0.786%\n",
            "Epoch : 2 [96000/1395 (72%)]\tLoss: 0.057810\t F1:0.786%\n",
            "Epoch : 2 [100800/1395 (75%)]\tLoss: 0.026727\t F1:0.786%\n",
            "Epoch : 2 [105600/1395 (79%)]\tLoss: 0.041886\t F1:0.787%\n",
            "Epoch : 2 [110400/1395 (82%)]\tLoss: 0.048027\t F1:0.787%\n",
            "Epoch : 2 [115200/1395 (86%)]\tLoss: 0.027176\t F1:0.787%\n",
            "Epoch : 2 [120000/1395 (90%)]\tLoss: 0.050395\t F1:0.787%\n",
            "Epoch : 2 [124800/1395 (93%)]\tLoss: 0.053993\t F1:0.786%\n",
            "Epoch : 2 [129600/1395 (97%)]\tLoss: 0.039093\t F1:0.787%\n",
            "Validation F1 Score: 0.7670466321243523\n",
            "Epoch : 3 [0/1395 (0%)]\tLoss: 0.029513\t F1:0.809%\n",
            "Epoch : 3 [4800/1395 (4%)]\tLoss: 0.041900\t F1:0.822%\n",
            "Epoch : 3 [9600/1395 (7%)]\tLoss: 0.026471\t F1:0.819%\n",
            "Epoch : 3 [14400/1395 (11%)]\tLoss: 0.031526\t F1:0.807%\n",
            "Epoch : 3 [19200/1395 (14%)]\tLoss: 0.047180\t F1:0.807%\n",
            "Epoch : 3 [24000/1395 (18%)]\tLoss: 0.034717\t F1:0.804%\n",
            "Epoch : 3 [28800/1395 (22%)]\tLoss: 0.034809\t F1:0.803%\n",
            "Epoch : 3 [33600/1395 (25%)]\tLoss: 0.033697\t F1:0.802%\n",
            "Epoch : 3 [38400/1395 (29%)]\tLoss: 0.034399\t F1:0.801%\n",
            "Epoch : 3 [43200/1395 (32%)]\tLoss: 0.039620\t F1:0.801%\n",
            "Epoch : 3 [48000/1395 (36%)]\tLoss: 0.028247\t F1:0.803%\n",
            "Epoch : 3 [52800/1395 (39%)]\tLoss: 0.025636\t F1:0.802%\n",
            "Epoch : 3 [57600/1395 (43%)]\tLoss: 0.021144\t F1:0.803%\n",
            "Epoch : 3 [62400/1395 (47%)]\tLoss: 0.057223\t F1:0.802%\n",
            "Epoch : 3 [67200/1395 (50%)]\tLoss: 0.027771\t F1:0.800%\n",
            "Epoch : 3 [72000/1395 (54%)]\tLoss: 0.026505\t F1:0.800%\n",
            "Epoch : 3 [76800/1395 (57%)]\tLoss: 0.057929\t F1:0.799%\n",
            "Epoch : 3 [81600/1395 (61%)]\tLoss: 0.043821\t F1:0.798%\n",
            "Epoch : 3 [86400/1395 (65%)]\tLoss: 0.051536\t F1:0.797%\n",
            "Epoch : 3 [91200/1395 (68%)]\tLoss: 0.036479\t F1:0.797%\n",
            "Epoch : 3 [96000/1395 (72%)]\tLoss: 0.055954\t F1:0.797%\n",
            "Epoch : 3 [100800/1395 (75%)]\tLoss: 0.028511\t F1:0.797%\n",
            "Epoch : 3 [105600/1395 (79%)]\tLoss: 0.036169\t F1:0.797%\n",
            "Epoch : 3 [110400/1395 (82%)]\tLoss: 0.048426\t F1:0.797%\n",
            "Epoch : 3 [115200/1395 (86%)]\tLoss: 0.027323\t F1:0.796%\n",
            "Epoch : 3 [120000/1395 (90%)]\tLoss: 0.050028\t F1:0.796%\n",
            "Epoch : 3 [124800/1395 (93%)]\tLoss: 0.043406\t F1:0.796%\n",
            "Epoch : 3 [129600/1395 (97%)]\tLoss: 0.041691\t F1:0.796%\n",
            "Validation F1 Score: 0.764133360944295\n",
            "Epoch : 4 [0/1395 (0%)]\tLoss: 0.027784\t F1:0.851%\n",
            "Epoch : 4 [4800/1395 (4%)]\tLoss: 0.050286\t F1:0.827%\n",
            "Epoch : 4 [9600/1395 (7%)]\tLoss: 0.019528\t F1:0.821%\n",
            "Epoch : 4 [14400/1395 (11%)]\tLoss: 0.030569\t F1:0.815%\n",
            "Epoch : 4 [19200/1395 (14%)]\tLoss: 0.033343\t F1:0.813%\n",
            "Epoch : 4 [24000/1395 (18%)]\tLoss: 0.031430\t F1:0.811%\n",
            "Epoch : 4 [28800/1395 (22%)]\tLoss: 0.026667\t F1:0.809%\n",
            "Epoch : 4 [33600/1395 (25%)]\tLoss: 0.034215\t F1:0.807%\n",
            "Epoch : 4 [38400/1395 (29%)]\tLoss: 0.033954\t F1:0.806%\n",
            "Epoch : 4 [43200/1395 (32%)]\tLoss: 0.042332\t F1:0.807%\n",
            "Epoch : 4 [48000/1395 (36%)]\tLoss: 0.025474\t F1:0.809%\n",
            "Epoch : 4 [52800/1395 (39%)]\tLoss: 0.024265\t F1:0.809%\n",
            "Epoch : 4 [57600/1395 (43%)]\tLoss: 0.022394\t F1:0.808%\n",
            "Epoch : 4 [62400/1395 (47%)]\tLoss: 0.055289\t F1:0.807%\n",
            "Epoch : 4 [67200/1395 (50%)]\tLoss: 0.023841\t F1:0.805%\n",
            "Epoch : 4 [72000/1395 (54%)]\tLoss: 0.027297\t F1:0.805%\n",
            "Epoch : 4 [76800/1395 (57%)]\tLoss: 0.059007\t F1:0.804%\n",
            "Epoch : 4 [81600/1395 (61%)]\tLoss: 0.039198\t F1:0.804%\n",
            "Epoch : 4 [86400/1395 (65%)]\tLoss: 0.047353\t F1:0.802%\n",
            "Epoch : 4 [91200/1395 (68%)]\tLoss: 0.038315\t F1:0.803%\n",
            "Epoch : 4 [96000/1395 (72%)]\tLoss: 0.056124\t F1:0.803%\n",
            "Epoch : 4 [100800/1395 (75%)]\tLoss: 0.027747\t F1:0.803%\n",
            "Epoch : 4 [105600/1395 (79%)]\tLoss: 0.038019\t F1:0.803%\n",
            "Epoch : 4 [110400/1395 (82%)]\tLoss: 0.049148\t F1:0.804%\n",
            "Epoch : 4 [115200/1395 (86%)]\tLoss: 0.025835\t F1:0.803%\n",
            "Epoch : 4 [120000/1395 (90%)]\tLoss: 0.053216\t F1:0.803%\n",
            "Epoch : 4 [124800/1395 (93%)]\tLoss: 0.037511\t F1:0.802%\n",
            "Epoch : 4 [129600/1395 (97%)]\tLoss: 0.043571\t F1:0.803%\n",
            "Validation F1 Score: 0.7605042016806723\n",
            "Epoch : 5 [0/1395 (0%)]\tLoss: 0.026151\t F1:0.826%\n",
            "Epoch : 5 [4800/1395 (4%)]\tLoss: 0.041163\t F1:0.822%\n",
            "Epoch : 5 [9600/1395 (7%)]\tLoss: 0.021253\t F1:0.823%\n",
            "Epoch : 5 [14400/1395 (11%)]\tLoss: 0.029804\t F1:0.818%\n",
            "Epoch : 5 [19200/1395 (14%)]\tLoss: 0.027158\t F1:0.819%\n",
            "Epoch : 5 [24000/1395 (18%)]\tLoss: 0.032144\t F1:0.817%\n",
            "Epoch : 5 [28800/1395 (22%)]\tLoss: 0.030131\t F1:0.816%\n",
            "Epoch : 5 [33600/1395 (25%)]\tLoss: 0.038494\t F1:0.816%\n",
            "Epoch : 5 [38400/1395 (29%)]\tLoss: 0.035805\t F1:0.814%\n",
            "Epoch : 5 [43200/1395 (32%)]\tLoss: 0.035429\t F1:0.815%\n",
            "Epoch : 5 [48000/1395 (36%)]\tLoss: 0.023527\t F1:0.817%\n",
            "Epoch : 5 [52800/1395 (39%)]\tLoss: 0.029276\t F1:0.818%\n",
            "Epoch : 5 [57600/1395 (43%)]\tLoss: 0.020533\t F1:0.818%\n",
            "Epoch : 5 [62400/1395 (47%)]\tLoss: 0.050882\t F1:0.817%\n",
            "Epoch : 5 [67200/1395 (50%)]\tLoss: 0.029258\t F1:0.816%\n",
            "Epoch : 5 [72000/1395 (54%)]\tLoss: 0.028325\t F1:0.815%\n",
            "Epoch : 5 [76800/1395 (57%)]\tLoss: 0.055861\t F1:0.815%\n",
            "Epoch : 5 [81600/1395 (61%)]\tLoss: 0.036462\t F1:0.815%\n",
            "Epoch : 5 [86400/1395 (65%)]\tLoss: 0.040377\t F1:0.814%\n",
            "Epoch : 5 [91200/1395 (68%)]\tLoss: 0.037159\t F1:0.814%\n",
            "Epoch : 5 [96000/1395 (72%)]\tLoss: 0.054103\t F1:0.813%\n",
            "Epoch : 5 [100800/1395 (75%)]\tLoss: 0.029812\t F1:0.813%\n",
            "Epoch : 5 [105600/1395 (79%)]\tLoss: 0.031971\t F1:0.813%\n",
            "Epoch : 5 [110400/1395 (82%)]\tLoss: 0.047379\t F1:0.814%\n",
            "Epoch : 5 [115200/1395 (86%)]\tLoss: 0.025476\t F1:0.813%\n",
            "Epoch : 5 [120000/1395 (90%)]\tLoss: 0.046408\t F1:0.813%\n",
            "Epoch : 5 [124800/1395 (93%)]\tLoss: 0.039797\t F1:0.813%\n",
            "Epoch : 5 [129600/1395 (97%)]\tLoss: 0.035672\t F1:0.813%\n",
            "Validation F1 Score: 0.7643796220213639\n",
            "Epoch : 6 [0/1395 (0%)]\tLoss: 0.026549\t F1:0.809%\n",
            "Epoch : 6 [4800/1395 (4%)]\tLoss: 0.042983\t F1:0.836%\n",
            "Epoch : 6 [9600/1395 (7%)]\tLoss: 0.019437\t F1:0.836%\n",
            "Epoch : 6 [14400/1395 (11%)]\tLoss: 0.025269\t F1:0.832%\n",
            "Epoch : 6 [19200/1395 (14%)]\tLoss: 0.030894\t F1:0.832%\n",
            "Epoch : 6 [24000/1395 (18%)]\tLoss: 0.033788\t F1:0.830%\n",
            "Epoch : 6 [28800/1395 (22%)]\tLoss: 0.023031\t F1:0.829%\n",
            "Epoch : 6 [33600/1395 (25%)]\tLoss: 0.041978\t F1:0.828%\n",
            "Epoch : 6 [38400/1395 (29%)]\tLoss: 0.029554\t F1:0.827%\n",
            "Epoch : 6 [43200/1395 (32%)]\tLoss: 0.035612\t F1:0.826%\n",
            "Epoch : 6 [48000/1395 (36%)]\tLoss: 0.031234\t F1:0.826%\n",
            "Epoch : 6 [52800/1395 (39%)]\tLoss: 0.026795\t F1:0.826%\n",
            "Epoch : 6 [57600/1395 (43%)]\tLoss: 0.021057\t F1:0.826%\n",
            "Epoch : 6 [62400/1395 (47%)]\tLoss: 0.045219\t F1:0.825%\n",
            "Epoch : 6 [67200/1395 (50%)]\tLoss: 0.024762\t F1:0.824%\n",
            "Epoch : 6 [72000/1395 (54%)]\tLoss: 0.024508\t F1:0.823%\n",
            "Epoch : 6 [76800/1395 (57%)]\tLoss: 0.049495\t F1:0.822%\n",
            "Epoch : 6 [81600/1395 (61%)]\tLoss: 0.035030\t F1:0.821%\n",
            "Epoch : 6 [86400/1395 (65%)]\tLoss: 0.039990\t F1:0.820%\n",
            "Epoch : 6 [91200/1395 (68%)]\tLoss: 0.042905\t F1:0.820%\n",
            "Epoch : 6 [96000/1395 (72%)]\tLoss: 0.052373\t F1:0.820%\n",
            "Epoch : 6 [100800/1395 (75%)]\tLoss: 0.028983\t F1:0.820%\n",
            "Epoch : 6 [105600/1395 (79%)]\tLoss: 0.030570\t F1:0.820%\n",
            "Epoch : 6 [110400/1395 (82%)]\tLoss: 0.047621\t F1:0.820%\n",
            "Epoch : 6 [115200/1395 (86%)]\tLoss: 0.021635\t F1:0.819%\n",
            "Epoch : 6 [120000/1395 (90%)]\tLoss: 0.039857\t F1:0.819%\n",
            "Epoch : 6 [124800/1395 (93%)]\tLoss: 0.029238\t F1:0.819%\n",
            "Epoch : 6 [129600/1395 (97%)]\tLoss: 0.037179\t F1:0.819%\n",
            "Validation F1 Score: 0.760811090420029\n",
            "Epoch : 7 [0/1395 (0%)]\tLoss: 0.025550\t F1:0.844%\n",
            "Epoch : 7 [4800/1395 (4%)]\tLoss: 0.042535\t F1:0.844%\n",
            "Epoch : 7 [9600/1395 (7%)]\tLoss: 0.024619\t F1:0.842%\n",
            "Epoch : 7 [14400/1395 (11%)]\tLoss: 0.023118\t F1:0.838%\n",
            "Epoch : 7 [19200/1395 (14%)]\tLoss: 0.024537\t F1:0.840%\n",
            "Epoch : 7 [24000/1395 (18%)]\tLoss: 0.033007\t F1:0.837%\n",
            "Epoch : 7 [28800/1395 (22%)]\tLoss: 0.028460\t F1:0.835%\n",
            "Epoch : 7 [33600/1395 (25%)]\tLoss: 0.035400\t F1:0.833%\n",
            "Epoch : 7 [38400/1395 (29%)]\tLoss: 0.031716\t F1:0.833%\n",
            "Epoch : 7 [43200/1395 (32%)]\tLoss: 0.041636\t F1:0.833%\n",
            "Epoch : 7 [48000/1395 (36%)]\tLoss: 0.025880\t F1:0.834%\n",
            "Epoch : 7 [52800/1395 (39%)]\tLoss: 0.025717\t F1:0.834%\n",
            "Epoch : 7 [57600/1395 (43%)]\tLoss: 0.021492\t F1:0.835%\n",
            "Epoch : 7 [62400/1395 (47%)]\tLoss: 0.048628\t F1:0.835%\n",
            "Epoch : 7 [67200/1395 (50%)]\tLoss: 0.023522\t F1:0.834%\n",
            "Epoch : 7 [72000/1395 (54%)]\tLoss: 0.025943\t F1:0.833%\n",
            "Epoch : 7 [76800/1395 (57%)]\tLoss: 0.051863\t F1:0.833%\n",
            "Epoch : 7 [81600/1395 (61%)]\tLoss: 0.040264\t F1:0.831%\n",
            "Epoch : 7 [86400/1395 (65%)]\tLoss: 0.040698\t F1:0.831%\n",
            "Epoch : 7 [91200/1395 (68%)]\tLoss: 0.033926\t F1:0.831%\n",
            "Epoch : 7 [96000/1395 (72%)]\tLoss: 0.049568\t F1:0.830%\n",
            "Epoch : 7 [100800/1395 (75%)]\tLoss: 0.022877\t F1:0.830%\n",
            "Epoch : 7 [105600/1395 (79%)]\tLoss: 0.039708\t F1:0.830%\n",
            "Epoch : 7 [110400/1395 (82%)]\tLoss: 0.043894\t F1:0.830%\n",
            "Epoch : 7 [115200/1395 (86%)]\tLoss: 0.024986\t F1:0.830%\n",
            "Epoch : 7 [120000/1395 (90%)]\tLoss: 0.040228\t F1:0.829%\n",
            "Epoch : 7 [124800/1395 (93%)]\tLoss: 0.038896\t F1:0.829%\n",
            "Epoch : 7 [129600/1395 (97%)]\tLoss: 0.035698\t F1:0.830%\n",
            "Validation F1 Score: 0.7570353571796722\n",
            "Epoch : 8 [0/1395 (0%)]\tLoss: 0.025454\t F1:0.840%\n",
            "Epoch : 8 [4800/1395 (4%)]\tLoss: 0.036799\t F1:0.851%\n",
            "Epoch : 8 [9600/1395 (7%)]\tLoss: 0.023373\t F1:0.849%\n",
            "Epoch : 8 [14400/1395 (11%)]\tLoss: 0.027989\t F1:0.845%\n",
            "Epoch : 8 [19200/1395 (14%)]\tLoss: 0.025111\t F1:0.846%\n",
            "Epoch : 8 [24000/1395 (18%)]\tLoss: 0.037213\t F1:0.843%\n",
            "Epoch : 8 [28800/1395 (22%)]\tLoss: 0.018918\t F1:0.841%\n",
            "Epoch : 8 [33600/1395 (25%)]\tLoss: 0.031255\t F1:0.840%\n",
            "Epoch : 8 [38400/1395 (29%)]\tLoss: 0.024919\t F1:0.840%\n",
            "Epoch : 8 [43200/1395 (32%)]\tLoss: 0.032310\t F1:0.841%\n",
            "Epoch : 8 [48000/1395 (36%)]\tLoss: 0.028181\t F1:0.841%\n",
            "Epoch : 8 [52800/1395 (39%)]\tLoss: 0.020709\t F1:0.841%\n",
            "Epoch : 8 [57600/1395 (43%)]\tLoss: 0.021531\t F1:0.842%\n",
            "Epoch : 8 [62400/1395 (47%)]\tLoss: 0.048549\t F1:0.841%\n",
            "Epoch : 8 [67200/1395 (50%)]\tLoss: 0.028163\t F1:0.840%\n",
            "Epoch : 8 [72000/1395 (54%)]\tLoss: 0.030184\t F1:0.840%\n",
            "Epoch : 8 [76800/1395 (57%)]\tLoss: 0.054369\t F1:0.839%\n",
            "Epoch : 8 [81600/1395 (61%)]\tLoss: 0.030664\t F1:0.838%\n",
            "Epoch : 8 [86400/1395 (65%)]\tLoss: 0.033017\t F1:0.838%\n",
            "Epoch : 8 [91200/1395 (68%)]\tLoss: 0.033667\t F1:0.839%\n",
            "Epoch : 8 [96000/1395 (72%)]\tLoss: 0.040378\t F1:0.838%\n",
            "Epoch : 8 [100800/1395 (75%)]\tLoss: 0.020901\t F1:0.838%\n",
            "Epoch : 8 [105600/1395 (79%)]\tLoss: 0.025634\t F1:0.837%\n",
            "Epoch : 8 [110400/1395 (82%)]\tLoss: 0.043024\t F1:0.838%\n",
            "Epoch : 8 [115200/1395 (86%)]\tLoss: 0.022283\t F1:0.837%\n",
            "Epoch : 8 [120000/1395 (90%)]\tLoss: 0.036276\t F1:0.837%\n",
            "Epoch : 8 [124800/1395 (93%)]\tLoss: 0.034394\t F1:0.837%\n",
            "Epoch : 8 [129600/1395 (97%)]\tLoss: 0.032204\t F1:0.837%\n",
            "Validation F1 Score: 0.7592592592592592\n",
            "Epoch : 9 [0/1395 (0%)]\tLoss: 0.023768\t F1:0.870%\n",
            "Epoch : 9 [4800/1395 (4%)]\tLoss: 0.039948\t F1:0.853%\n",
            "Epoch : 9 [9600/1395 (7%)]\tLoss: 0.020604\t F1:0.853%\n",
            "Epoch : 9 [14400/1395 (11%)]\tLoss: 0.018009\t F1:0.846%\n",
            "Epoch : 9 [19200/1395 (14%)]\tLoss: 0.022196\t F1:0.849%\n",
            "Epoch : 9 [24000/1395 (18%)]\tLoss: 0.030801\t F1:0.849%\n",
            "Epoch : 9 [28800/1395 (22%)]\tLoss: 0.021830\t F1:0.850%\n",
            "Epoch : 9 [33600/1395 (25%)]\tLoss: 0.029759\t F1:0.850%\n",
            "Epoch : 9 [38400/1395 (29%)]\tLoss: 0.023269\t F1:0.850%\n",
            "Epoch : 9 [43200/1395 (32%)]\tLoss: 0.033630\t F1:0.850%\n",
            "Epoch : 9 [48000/1395 (36%)]\tLoss: 0.028024\t F1:0.850%\n",
            "Epoch : 9 [52800/1395 (39%)]\tLoss: 0.019718\t F1:0.850%\n",
            "Epoch : 9 [57600/1395 (43%)]\tLoss: 0.021027\t F1:0.849%\n",
            "Epoch : 9 [62400/1395 (47%)]\tLoss: 0.037511\t F1:0.849%\n",
            "Epoch : 9 [67200/1395 (50%)]\tLoss: 0.023664\t F1:0.848%\n",
            "Epoch : 9 [72000/1395 (54%)]\tLoss: 0.023562\t F1:0.848%\n",
            "Epoch : 9 [76800/1395 (57%)]\tLoss: 0.041356\t F1:0.847%\n",
            "Epoch : 9 [81600/1395 (61%)]\tLoss: 0.027400\t F1:0.845%\n",
            "Epoch : 9 [86400/1395 (65%)]\tLoss: 0.034900\t F1:0.845%\n",
            "Epoch : 9 [91200/1395 (68%)]\tLoss: 0.034798\t F1:0.845%\n",
            "Epoch : 9 [96000/1395 (72%)]\tLoss: 0.034292\t F1:0.845%\n",
            "Epoch : 9 [100800/1395 (75%)]\tLoss: 0.020681\t F1:0.845%\n",
            "Epoch : 9 [105600/1395 (79%)]\tLoss: 0.030283\t F1:0.845%\n",
            "Epoch : 9 [110400/1395 (82%)]\tLoss: 0.037335\t F1:0.846%\n",
            "Epoch : 9 [115200/1395 (86%)]\tLoss: 0.027815\t F1:0.845%\n",
            "Epoch : 9 [120000/1395 (90%)]\tLoss: 0.031308\t F1:0.844%\n",
            "Epoch : 9 [124800/1395 (93%)]\tLoss: 0.038924\t F1:0.844%\n",
            "Epoch : 9 [129600/1395 (97%)]\tLoss: 0.035766\t F1:0.845%\n",
            "Validation F1 Score: 0.7564102564102563\n",
            "Epoch : 10 [0/1395 (0%)]\tLoss: 0.024631\t F1:0.875%\n",
            "Epoch : 10 [4800/1395 (4%)]\tLoss: 0.036095\t F1:0.873%\n",
            "Epoch : 10 [9600/1395 (7%)]\tLoss: 0.024082\t F1:0.867%\n",
            "Epoch : 10 [14400/1395 (11%)]\tLoss: 0.023019\t F1:0.863%\n",
            "Epoch : 10 [19200/1395 (14%)]\tLoss: 0.019426\t F1:0.863%\n",
            "Epoch : 10 [24000/1395 (18%)]\tLoss: 0.026247\t F1:0.862%\n",
            "Epoch : 10 [28800/1395 (22%)]\tLoss: 0.022679\t F1:0.861%\n",
            "Epoch : 10 [33600/1395 (25%)]\tLoss: 0.023533\t F1:0.861%\n",
            "Epoch : 10 [38400/1395 (29%)]\tLoss: 0.026495\t F1:0.859%\n",
            "Epoch : 10 [43200/1395 (32%)]\tLoss: 0.028069\t F1:0.859%\n",
            "Epoch : 10 [48000/1395 (36%)]\tLoss: 0.025580\t F1:0.860%\n",
            "Epoch : 10 [52800/1395 (39%)]\tLoss: 0.017590\t F1:0.860%\n",
            "Epoch : 10 [57600/1395 (43%)]\tLoss: 0.021568\t F1:0.859%\n",
            "Epoch : 10 [62400/1395 (47%)]\tLoss: 0.047020\t F1:0.858%\n",
            "Epoch : 10 [67200/1395 (50%)]\tLoss: 0.015776\t F1:0.858%\n",
            "Epoch : 10 [72000/1395 (54%)]\tLoss: 0.020537\t F1:0.857%\n",
            "Epoch : 10 [76800/1395 (57%)]\tLoss: 0.037883\t F1:0.857%\n",
            "Epoch : 10 [81600/1395 (61%)]\tLoss: 0.029626\t F1:0.856%\n",
            "Epoch : 10 [86400/1395 (65%)]\tLoss: 0.035082\t F1:0.856%\n",
            "Epoch : 10 [91200/1395 (68%)]\tLoss: 0.028281\t F1:0.855%\n",
            "Epoch : 10 [96000/1395 (72%)]\tLoss: 0.035531\t F1:0.855%\n",
            "Epoch : 10 [100800/1395 (75%)]\tLoss: 0.024078\t F1:0.855%\n",
            "Epoch : 10 [105600/1395 (79%)]\tLoss: 0.031039\t F1:0.855%\n",
            "Epoch : 10 [110400/1395 (82%)]\tLoss: 0.039246\t F1:0.855%\n",
            "Epoch : 10 [115200/1395 (86%)]\tLoss: 0.019842\t F1:0.854%\n",
            "Epoch : 10 [120000/1395 (90%)]\tLoss: 0.037636\t F1:0.854%\n",
            "Epoch : 10 [124800/1395 (93%)]\tLoss: 0.030224\t F1:0.854%\n",
            "Epoch : 10 [129600/1395 (97%)]\tLoss: 0.037555\t F1:0.854%\n",
            "Validation F1 Score: 0.739228537659826\n",
            "Epoch : 11 [0/1395 (0%)]\tLoss: 0.021031\t F1:0.909%\n",
            "Epoch : 11 [4800/1395 (4%)]\tLoss: 0.029676\t F1:0.871%\n",
            "Epoch : 11 [9600/1395 (7%)]\tLoss: 0.025158\t F1:0.869%\n",
            "Epoch : 11 [14400/1395 (11%)]\tLoss: 0.020588\t F1:0.866%\n",
            "Epoch : 11 [19200/1395 (14%)]\tLoss: 0.017103\t F1:0.867%\n",
            "Epoch : 11 [24000/1395 (18%)]\tLoss: 0.021926\t F1:0.867%\n",
            "Epoch : 11 [28800/1395 (22%)]\tLoss: 0.019628\t F1:0.864%\n",
            "Epoch : 11 [33600/1395 (25%)]\tLoss: 0.025709\t F1:0.863%\n",
            "Epoch : 11 [38400/1395 (29%)]\tLoss: 0.025384\t F1:0.863%\n",
            "Epoch : 11 [43200/1395 (32%)]\tLoss: 0.024917\t F1:0.863%\n",
            "Epoch : 11 [48000/1395 (36%)]\tLoss: 0.019557\t F1:0.864%\n",
            "Epoch : 11 [52800/1395 (39%)]\tLoss: 0.014710\t F1:0.865%\n",
            "Epoch : 11 [57600/1395 (43%)]\tLoss: 0.021996\t F1:0.865%\n",
            "Epoch : 11 [62400/1395 (47%)]\tLoss: 0.035996\t F1:0.865%\n",
            "Epoch : 11 [67200/1395 (50%)]\tLoss: 0.022457\t F1:0.864%\n",
            "Epoch : 11 [72000/1395 (54%)]\tLoss: 0.024160\t F1:0.863%\n",
            "Epoch : 11 [76800/1395 (57%)]\tLoss: 0.033052\t F1:0.863%\n",
            "Epoch : 11 [81600/1395 (61%)]\tLoss: 0.024559\t F1:0.862%\n",
            "Epoch : 11 [86400/1395 (65%)]\tLoss: 0.031687\t F1:0.861%\n",
            "Epoch : 11 [91200/1395 (68%)]\tLoss: 0.038671\t F1:0.862%\n",
            "Epoch : 11 [96000/1395 (72%)]\tLoss: 0.039439\t F1:0.861%\n",
            "Epoch : 11 [100800/1395 (75%)]\tLoss: 0.014299\t F1:0.861%\n",
            "Epoch : 11 [105600/1395 (79%)]\tLoss: 0.024235\t F1:0.861%\n",
            "Epoch : 11 [110400/1395 (82%)]\tLoss: 0.045038\t F1:0.861%\n",
            "Epoch : 11 [115200/1395 (86%)]\tLoss: 0.021942\t F1:0.860%\n",
            "Epoch : 11 [120000/1395 (90%)]\tLoss: 0.030583\t F1:0.860%\n",
            "Epoch : 11 [124800/1395 (93%)]\tLoss: 0.023534\t F1:0.860%\n",
            "Epoch : 11 [129600/1395 (97%)]\tLoss: 0.028584\t F1:0.860%\n",
            "Validation F1 Score: 0.753469387755102\n",
            "Epoch : 12 [0/1395 (0%)]\tLoss: 0.023119\t F1:0.894%\n",
            "Epoch : 12 [4800/1395 (4%)]\tLoss: 0.029493\t F1:0.879%\n",
            "Epoch : 12 [9600/1395 (7%)]\tLoss: 0.017832\t F1:0.876%\n",
            "Epoch : 12 [14400/1395 (11%)]\tLoss: 0.024278\t F1:0.872%\n",
            "Epoch : 12 [19200/1395 (14%)]\tLoss: 0.025753\t F1:0.874%\n",
            "Epoch : 12 [24000/1395 (18%)]\tLoss: 0.023898\t F1:0.875%\n",
            "Epoch : 12 [28800/1395 (22%)]\tLoss: 0.019652\t F1:0.873%\n",
            "Epoch : 12 [33600/1395 (25%)]\tLoss: 0.024235\t F1:0.872%\n",
            "Epoch : 12 [38400/1395 (29%)]\tLoss: 0.022477\t F1:0.872%\n",
            "Epoch : 12 [43200/1395 (32%)]\tLoss: 0.025538\t F1:0.872%\n",
            "Epoch : 12 [48000/1395 (36%)]\tLoss: 0.022492\t F1:0.873%\n",
            "Epoch : 12 [52800/1395 (39%)]\tLoss: 0.021020\t F1:0.873%\n",
            "Epoch : 12 [57600/1395 (43%)]\tLoss: 0.020835\t F1:0.873%\n",
            "Epoch : 12 [62400/1395 (47%)]\tLoss: 0.045796\t F1:0.872%\n",
            "Epoch : 12 [67200/1395 (50%)]\tLoss: 0.021116\t F1:0.872%\n",
            "Epoch : 12 [72000/1395 (54%)]\tLoss: 0.021091\t F1:0.871%\n",
            "Epoch : 12 [76800/1395 (57%)]\tLoss: 0.041064\t F1:0.871%\n",
            "Epoch : 12 [81600/1395 (61%)]\tLoss: 0.027275\t F1:0.870%\n",
            "Epoch : 12 [86400/1395 (65%)]\tLoss: 0.034788\t F1:0.869%\n",
            "Epoch : 12 [91200/1395 (68%)]\tLoss: 0.033581\t F1:0.870%\n",
            "Epoch : 12 [96000/1395 (72%)]\tLoss: 0.031192\t F1:0.869%\n",
            "Epoch : 12 [100800/1395 (75%)]\tLoss: 0.016371\t F1:0.869%\n",
            "Epoch : 12 [105600/1395 (79%)]\tLoss: 0.020153\t F1:0.869%\n",
            "Epoch : 12 [110400/1395 (82%)]\tLoss: 0.038737\t F1:0.869%\n",
            "Epoch : 12 [115200/1395 (86%)]\tLoss: 0.014741\t F1:0.868%\n",
            "Epoch : 12 [120000/1395 (90%)]\tLoss: 0.021090\t F1:0.868%\n",
            "Epoch : 12 [124800/1395 (93%)]\tLoss: 0.026385\t F1:0.868%\n",
            "Epoch : 12 [129600/1395 (97%)]\tLoss: 0.027994\t F1:0.868%\n",
            "Validation F1 Score: 0.7497216880882501\n",
            "Epoch : 13 [0/1395 (0%)]\tLoss: 0.018959\t F1:0.913%\n",
            "Epoch : 13 [4800/1395 (4%)]\tLoss: 0.026962\t F1:0.880%\n",
            "Epoch : 13 [9600/1395 (7%)]\tLoss: 0.025570\t F1:0.876%\n",
            "Epoch : 13 [14400/1395 (11%)]\tLoss: 0.030692\t F1:0.875%\n",
            "Epoch : 13 [19200/1395 (14%)]\tLoss: 0.025071\t F1:0.877%\n",
            "Epoch : 13 [24000/1395 (18%)]\tLoss: 0.019872\t F1:0.878%\n",
            "Epoch : 13 [28800/1395 (22%)]\tLoss: 0.011142\t F1:0.877%\n",
            "Epoch : 13 [33600/1395 (25%)]\tLoss: 0.023098\t F1:0.875%\n",
            "Epoch : 13 [38400/1395 (29%)]\tLoss: 0.023936\t F1:0.876%\n",
            "Epoch : 13 [43200/1395 (32%)]\tLoss: 0.015715\t F1:0.877%\n",
            "Epoch : 13 [48000/1395 (36%)]\tLoss: 0.021315\t F1:0.877%\n",
            "Epoch : 13 [52800/1395 (39%)]\tLoss: 0.019115\t F1:0.876%\n",
            "Epoch : 13 [57600/1395 (43%)]\tLoss: 0.019276\t F1:0.876%\n",
            "Epoch : 13 [62400/1395 (47%)]\tLoss: 0.030829\t F1:0.876%\n",
            "Epoch : 13 [67200/1395 (50%)]\tLoss: 0.023057\t F1:0.876%\n",
            "Epoch : 13 [72000/1395 (54%)]\tLoss: 0.017982\t F1:0.875%\n",
            "Epoch : 13 [76800/1395 (57%)]\tLoss: 0.029624\t F1:0.874%\n",
            "Epoch : 13 [81600/1395 (61%)]\tLoss: 0.027184\t F1:0.874%\n",
            "Epoch : 13 [86400/1395 (65%)]\tLoss: 0.027813\t F1:0.873%\n",
            "Epoch : 13 [91200/1395 (68%)]\tLoss: 0.028431\t F1:0.874%\n",
            "Epoch : 13 [96000/1395 (72%)]\tLoss: 0.033716\t F1:0.873%\n",
            "Epoch : 13 [100800/1395 (75%)]\tLoss: 0.013783\t F1:0.873%\n",
            "Epoch : 13 [105600/1395 (79%)]\tLoss: 0.030464\t F1:0.873%\n",
            "Epoch : 13 [110400/1395 (82%)]\tLoss: 0.037171\t F1:0.873%\n",
            "Epoch : 13 [115200/1395 (86%)]\tLoss: 0.011719\t F1:0.873%\n",
            "Epoch : 13 [120000/1395 (90%)]\tLoss: 0.030433\t F1:0.873%\n",
            "Epoch : 13 [124800/1395 (93%)]\tLoss: 0.023686\t F1:0.873%\n",
            "Epoch : 13 [129600/1395 (97%)]\tLoss: 0.035116\t F1:0.873%\n",
            "Validation F1 Score: 0.7485667485667485\n",
            "Epoch : 14 [0/1395 (0%)]\tLoss: 0.021027\t F1:0.844%\n",
            "Epoch : 14 [4800/1395 (4%)]\tLoss: 0.027883\t F1:0.884%\n",
            "Epoch : 14 [9600/1395 (7%)]\tLoss: 0.018273\t F1:0.886%\n",
            "Epoch : 14 [14400/1395 (11%)]\tLoss: 0.024916\t F1:0.885%\n",
            "Epoch : 14 [19200/1395 (14%)]\tLoss: 0.020973\t F1:0.884%\n",
            "Epoch : 14 [24000/1395 (18%)]\tLoss: 0.023318\t F1:0.883%\n",
            "Epoch : 14 [28800/1395 (22%)]\tLoss: 0.014021\t F1:0.884%\n",
            "Epoch : 14 [33600/1395 (25%)]\tLoss: 0.021479\t F1:0.883%\n",
            "Epoch : 14 [38400/1395 (29%)]\tLoss: 0.021180\t F1:0.881%\n",
            "Epoch : 14 [43200/1395 (32%)]\tLoss: 0.027075\t F1:0.882%\n",
            "Epoch : 14 [48000/1395 (36%)]\tLoss: 0.023949\t F1:0.882%\n",
            "Epoch : 14 [52800/1395 (39%)]\tLoss: 0.014950\t F1:0.883%\n",
            "Epoch : 14 [57600/1395 (43%)]\tLoss: 0.013606\t F1:0.883%\n",
            "Epoch : 14 [62400/1395 (47%)]\tLoss: 0.025839\t F1:0.882%\n",
            "Epoch : 14 [67200/1395 (50%)]\tLoss: 0.019686\t F1:0.881%\n",
            "Epoch : 14 [72000/1395 (54%)]\tLoss: 0.017780\t F1:0.881%\n",
            "Epoch : 14 [76800/1395 (57%)]\tLoss: 0.035655\t F1:0.881%\n",
            "Epoch : 14 [81600/1395 (61%)]\tLoss: 0.017194\t F1:0.880%\n",
            "Epoch : 14 [86400/1395 (65%)]\tLoss: 0.028843\t F1:0.879%\n",
            "Epoch : 14 [91200/1395 (68%)]\tLoss: 0.034466\t F1:0.879%\n",
            "Epoch : 14 [96000/1395 (72%)]\tLoss: 0.034895\t F1:0.879%\n",
            "Epoch : 14 [100800/1395 (75%)]\tLoss: 0.011287\t F1:0.879%\n",
            "Epoch : 14 [105600/1395 (79%)]\tLoss: 0.027016\t F1:0.878%\n",
            "Epoch : 14 [110400/1395 (82%)]\tLoss: 0.035540\t F1:0.879%\n",
            "Epoch : 14 [115200/1395 (86%)]\tLoss: 0.013906\t F1:0.878%\n",
            "Epoch : 14 [120000/1395 (90%)]\tLoss: 0.027348\t F1:0.878%\n",
            "Epoch : 14 [124800/1395 (93%)]\tLoss: 0.017727\t F1:0.878%\n",
            "Epoch : 14 [129600/1395 (97%)]\tLoss: 0.027314\t F1:0.878%\n",
            "Validation F1 Score: 0.7405709522817253\n",
            "Epoch : 15 [0/1395 (0%)]\tLoss: 0.015466\t F1:0.889%\n",
            "Epoch : 15 [4800/1395 (4%)]\tLoss: 0.021387\t F1:0.889%\n",
            "Epoch : 15 [9600/1395 (7%)]\tLoss: 0.024358\t F1:0.891%\n",
            "Epoch : 15 [14400/1395 (11%)]\tLoss: 0.014789\t F1:0.888%\n",
            "Epoch : 15 [19200/1395 (14%)]\tLoss: 0.013777\t F1:0.890%\n",
            "Epoch : 15 [24000/1395 (18%)]\tLoss: 0.031065\t F1:0.890%\n",
            "Epoch : 15 [28800/1395 (22%)]\tLoss: 0.019925\t F1:0.890%\n",
            "Epoch : 15 [33600/1395 (25%)]\tLoss: 0.024853\t F1:0.888%\n",
            "Epoch : 15 [38400/1395 (29%)]\tLoss: 0.019124\t F1:0.888%\n",
            "Epoch : 15 [43200/1395 (32%)]\tLoss: 0.029534\t F1:0.887%\n",
            "Epoch : 15 [48000/1395 (36%)]\tLoss: 0.019157\t F1:0.887%\n",
            "Epoch : 15 [52800/1395 (39%)]\tLoss: 0.011590\t F1:0.886%\n",
            "Epoch : 15 [57600/1395 (43%)]\tLoss: 0.012737\t F1:0.886%\n",
            "Epoch : 15 [62400/1395 (47%)]\tLoss: 0.037880\t F1:0.887%\n",
            "Epoch : 15 [67200/1395 (50%)]\tLoss: 0.024394\t F1:0.886%\n",
            "Epoch : 15 [72000/1395 (54%)]\tLoss: 0.020199\t F1:0.885%\n",
            "Epoch : 15 [76800/1395 (57%)]\tLoss: 0.026823\t F1:0.885%\n",
            "Epoch : 15 [81600/1395 (61%)]\tLoss: 0.020118\t F1:0.884%\n",
            "Epoch : 15 [86400/1395 (65%)]\tLoss: 0.023370\t F1:0.884%\n",
            "Epoch : 15 [91200/1395 (68%)]\tLoss: 0.034133\t F1:0.885%\n",
            "Epoch : 15 [96000/1395 (72%)]\tLoss: 0.022384\t F1:0.885%\n",
            "Epoch : 15 [100800/1395 (75%)]\tLoss: 0.014256\t F1:0.885%\n",
            "Epoch : 15 [105600/1395 (79%)]\tLoss: 0.027457\t F1:0.885%\n",
            "Epoch : 15 [110400/1395 (82%)]\tLoss: 0.022574\t F1:0.885%\n",
            "Epoch : 15 [115200/1395 (86%)]\tLoss: 0.011691\t F1:0.885%\n",
            "Epoch : 15 [120000/1395 (90%)]\tLoss: 0.020271\t F1:0.884%\n",
            "Epoch : 15 [124800/1395 (93%)]\tLoss: 0.021807\t F1:0.884%\n",
            "Epoch : 15 [129600/1395 (97%)]\tLoss: 0.030068\t F1:0.885%\n",
            "Validation F1 Score: 0.7372819387861694\n",
            "Epoch : 16 [0/1395 (0%)]\tLoss: 0.022870\t F1:0.870%\n",
            "Epoch : 16 [4800/1395 (4%)]\tLoss: 0.024583\t F1:0.890%\n",
            "Epoch : 16 [9600/1395 (7%)]\tLoss: 0.022258\t F1:0.888%\n",
            "Epoch : 16 [14400/1395 (11%)]\tLoss: 0.022498\t F1:0.888%\n",
            "Epoch : 16 [19200/1395 (14%)]\tLoss: 0.010943\t F1:0.892%\n",
            "Epoch : 16 [24000/1395 (18%)]\tLoss: 0.027396\t F1:0.892%\n",
            "Epoch : 16 [28800/1395 (22%)]\tLoss: 0.016724\t F1:0.893%\n",
            "Epoch : 16 [33600/1395 (25%)]\tLoss: 0.021489\t F1:0.893%\n",
            "Epoch : 16 [38400/1395 (29%)]\tLoss: 0.017532\t F1:0.895%\n",
            "Epoch : 16 [43200/1395 (32%)]\tLoss: 0.015715\t F1:0.895%\n",
            "Epoch : 16 [48000/1395 (36%)]\tLoss: 0.019831\t F1:0.895%\n",
            "Epoch : 16 [52800/1395 (39%)]\tLoss: 0.017962\t F1:0.895%\n",
            "Epoch : 16 [57600/1395 (43%)]\tLoss: 0.014404\t F1:0.894%\n",
            "Epoch : 16 [62400/1395 (47%)]\tLoss: 0.019886\t F1:0.895%\n",
            "Epoch : 16 [67200/1395 (50%)]\tLoss: 0.016243\t F1:0.894%\n",
            "Epoch : 16 [72000/1395 (54%)]\tLoss: 0.016634\t F1:0.893%\n",
            "Epoch : 16 [76800/1395 (57%)]\tLoss: 0.037975\t F1:0.892%\n",
            "Epoch : 16 [81600/1395 (61%)]\tLoss: 0.017814\t F1:0.891%\n",
            "Epoch : 16 [86400/1395 (65%)]\tLoss: 0.028499\t F1:0.891%\n",
            "Epoch : 16 [91200/1395 (68%)]\tLoss: 0.027883\t F1:0.891%\n",
            "Epoch : 16 [96000/1395 (72%)]\tLoss: 0.020840\t F1:0.891%\n",
            "Epoch : 16 [100800/1395 (75%)]\tLoss: 0.010363\t F1:0.891%\n",
            "Epoch : 16 [105600/1395 (79%)]\tLoss: 0.024789\t F1:0.891%\n",
            "Epoch : 16 [110400/1395 (82%)]\tLoss: 0.032708\t F1:0.891%\n",
            "Epoch : 16 [115200/1395 (86%)]\tLoss: 0.018374\t F1:0.891%\n",
            "Epoch : 16 [120000/1395 (90%)]\tLoss: 0.029197\t F1:0.890%\n",
            "Epoch : 16 [124800/1395 (93%)]\tLoss: 0.026607\t F1:0.890%\n",
            "Epoch : 16 [129600/1395 (97%)]\tLoss: 0.024385\t F1:0.891%\n",
            "Validation F1 Score: 0.738280428841707\n",
            "Epoch : 17 [0/1395 (0%)]\tLoss: 0.024687\t F1:0.889%\n",
            "Epoch : 17 [4800/1395 (4%)]\tLoss: 0.017662\t F1:0.908%\n",
            "Epoch : 17 [9600/1395 (7%)]\tLoss: 0.016737\t F1:0.901%\n",
            "Epoch : 17 [14400/1395 (11%)]\tLoss: 0.021076\t F1:0.899%\n",
            "Epoch : 17 [19200/1395 (14%)]\tLoss: 0.024659\t F1:0.900%\n",
            "Epoch : 17 [24000/1395 (18%)]\tLoss: 0.019131\t F1:0.899%\n",
            "Epoch : 17 [28800/1395 (22%)]\tLoss: 0.012840\t F1:0.898%\n",
            "Epoch : 17 [33600/1395 (25%)]\tLoss: 0.024676\t F1:0.898%\n",
            "Epoch : 17 [38400/1395 (29%)]\tLoss: 0.015703\t F1:0.899%\n",
            "Epoch : 17 [43200/1395 (32%)]\tLoss: 0.011943\t F1:0.899%\n",
            "Epoch : 17 [48000/1395 (36%)]\tLoss: 0.015632\t F1:0.899%\n",
            "Epoch : 17 [52800/1395 (39%)]\tLoss: 0.014980\t F1:0.899%\n",
            "Epoch : 17 [57600/1395 (43%)]\tLoss: 0.016628\t F1:0.899%\n",
            "Epoch : 17 [62400/1395 (47%)]\tLoss: 0.033917\t F1:0.898%\n",
            "Epoch : 17 [67200/1395 (50%)]\tLoss: 0.016447\t F1:0.898%\n",
            "Epoch : 17 [72000/1395 (54%)]\tLoss: 0.018821\t F1:0.898%\n",
            "Epoch : 17 [76800/1395 (57%)]\tLoss: 0.027325\t F1:0.898%\n",
            "Epoch : 17 [81600/1395 (61%)]\tLoss: 0.011623\t F1:0.897%\n",
            "Epoch : 17 [86400/1395 (65%)]\tLoss: 0.027276\t F1:0.896%\n",
            "Epoch : 17 [91200/1395 (68%)]\tLoss: 0.017758\t F1:0.897%\n",
            "Epoch : 17 [96000/1395 (72%)]\tLoss: 0.023218\t F1:0.896%\n",
            "Epoch : 17 [100800/1395 (75%)]\tLoss: 0.010992\t F1:0.896%\n",
            "Epoch : 17 [105600/1395 (79%)]\tLoss: 0.018431\t F1:0.896%\n",
            "Epoch : 17 [110400/1395 (82%)]\tLoss: 0.029915\t F1:0.896%\n",
            "Epoch : 17 [115200/1395 (86%)]\tLoss: 0.011124\t F1:0.895%\n",
            "Epoch : 17 [120000/1395 (90%)]\tLoss: 0.018019\t F1:0.895%\n",
            "Epoch : 17 [124800/1395 (93%)]\tLoss: 0.027800\t F1:0.895%\n",
            "Epoch : 17 [129600/1395 (97%)]\tLoss: 0.040274\t F1:0.895%\n",
            "Validation F1 Score: 0.7360512871882199\n",
            "Epoch : 18 [0/1395 (0%)]\tLoss: 0.018285\t F1:0.894%\n",
            "Epoch : 18 [4800/1395 (4%)]\tLoss: 0.018715\t F1:0.906%\n",
            "Epoch : 18 [9600/1395 (7%)]\tLoss: 0.018536\t F1:0.907%\n",
            "Epoch : 18 [14400/1395 (11%)]\tLoss: 0.019219\t F1:0.906%\n",
            "Epoch : 18 [19200/1395 (14%)]\tLoss: 0.010960\t F1:0.910%\n",
            "Epoch : 18 [24000/1395 (18%)]\tLoss: 0.014256\t F1:0.908%\n",
            "Epoch : 18 [28800/1395 (22%)]\tLoss: 0.005372\t F1:0.907%\n",
            "Epoch : 18 [33600/1395 (25%)]\tLoss: 0.029973\t F1:0.906%\n",
            "Epoch : 18 [38400/1395 (29%)]\tLoss: 0.014587\t F1:0.906%\n",
            "Epoch : 18 [43200/1395 (32%)]\tLoss: 0.011512\t F1:0.906%\n",
            "Epoch : 18 [48000/1395 (36%)]\tLoss: 0.023570\t F1:0.905%\n",
            "Epoch : 18 [52800/1395 (39%)]\tLoss: 0.022926\t F1:0.905%\n",
            "Epoch : 18 [57600/1395 (43%)]\tLoss: 0.011740\t F1:0.904%\n",
            "Epoch : 18 [62400/1395 (47%)]\tLoss: 0.017946\t F1:0.904%\n",
            "Epoch : 18 [67200/1395 (50%)]\tLoss: 0.017047\t F1:0.904%\n",
            "Epoch : 18 [72000/1395 (54%)]\tLoss: 0.013896\t F1:0.903%\n",
            "Epoch : 18 [76800/1395 (57%)]\tLoss: 0.028832\t F1:0.903%\n",
            "Epoch : 18 [81600/1395 (61%)]\tLoss: 0.014748\t F1:0.903%\n",
            "Epoch : 18 [86400/1395 (65%)]\tLoss: 0.025496\t F1:0.902%\n",
            "Epoch : 18 [91200/1395 (68%)]\tLoss: 0.032212\t F1:0.902%\n",
            "Epoch : 18 [96000/1395 (72%)]\tLoss: 0.028208\t F1:0.901%\n",
            "Epoch : 18 [100800/1395 (75%)]\tLoss: 0.009156\t F1:0.901%\n",
            "Epoch : 18 [105600/1395 (79%)]\tLoss: 0.016748\t F1:0.902%\n",
            "Epoch : 18 [110400/1395 (82%)]\tLoss: 0.038498\t F1:0.902%\n",
            "Epoch : 18 [115200/1395 (86%)]\tLoss: 0.010462\t F1:0.901%\n",
            "Epoch : 18 [120000/1395 (90%)]\tLoss: 0.019387\t F1:0.900%\n",
            "Epoch : 18 [124800/1395 (93%)]\tLoss: 0.017791\t F1:0.901%\n",
            "Epoch : 18 [129600/1395 (97%)]\tLoss: 0.020273\t F1:0.901%\n",
            "Validation F1 Score: 0.7385943279901356\n",
            "Epoch : 19 [0/1395 (0%)]\tLoss: 0.013955\t F1:0.913%\n",
            "Epoch : 19 [4800/1395 (4%)]\tLoss: 0.026808\t F1:0.908%\n",
            "Epoch : 19 [9600/1395 (7%)]\tLoss: 0.012226\t F1:0.911%\n",
            "Epoch : 19 [14400/1395 (11%)]\tLoss: 0.021598\t F1:0.910%\n",
            "Epoch : 19 [19200/1395 (14%)]\tLoss: 0.015378\t F1:0.910%\n",
            "Epoch : 19 [24000/1395 (18%)]\tLoss: 0.015087\t F1:0.909%\n",
            "Epoch : 19 [28800/1395 (22%)]\tLoss: 0.006589\t F1:0.909%\n",
            "Epoch : 19 [33600/1395 (25%)]\tLoss: 0.017669\t F1:0.908%\n",
            "Epoch : 19 [38400/1395 (29%)]\tLoss: 0.024554\t F1:0.907%\n",
            "Epoch : 19 [43200/1395 (32%)]\tLoss: 0.012876\t F1:0.907%\n",
            "Epoch : 19 [48000/1395 (36%)]\tLoss: 0.017184\t F1:0.906%\n",
            "Epoch : 19 [52800/1395 (39%)]\tLoss: 0.010964\t F1:0.905%\n",
            "Epoch : 19 [57600/1395 (43%)]\tLoss: 0.013799\t F1:0.904%\n",
            "Epoch : 19 [62400/1395 (47%)]\tLoss: 0.016825\t F1:0.905%\n",
            "Epoch : 19 [67200/1395 (50%)]\tLoss: 0.011486\t F1:0.905%\n",
            "Epoch : 19 [72000/1395 (54%)]\tLoss: 0.009257\t F1:0.905%\n",
            "Epoch : 19 [76800/1395 (57%)]\tLoss: 0.024842\t F1:0.904%\n",
            "Epoch : 19 [81600/1395 (61%)]\tLoss: 0.017166\t F1:0.904%\n",
            "Epoch : 19 [86400/1395 (65%)]\tLoss: 0.027457\t F1:0.904%\n",
            "Epoch : 19 [91200/1395 (68%)]\tLoss: 0.016952\t F1:0.904%\n",
            "Epoch : 19 [96000/1395 (72%)]\tLoss: 0.024079\t F1:0.904%\n",
            "Epoch : 19 [100800/1395 (75%)]\tLoss: 0.010363\t F1:0.904%\n",
            "Epoch : 19 [105600/1395 (79%)]\tLoss: 0.018266\t F1:0.904%\n",
            "Epoch : 19 [110400/1395 (82%)]\tLoss: 0.037643\t F1:0.904%\n",
            "Epoch : 19 [115200/1395 (86%)]\tLoss: 0.006964\t F1:0.903%\n",
            "Epoch : 19 [120000/1395 (90%)]\tLoss: 0.022742\t F1:0.903%\n",
            "Epoch : 19 [124800/1395 (93%)]\tLoss: 0.030284\t F1:0.903%\n",
            "Epoch : 19 [129600/1395 (97%)]\tLoss: 0.017674\t F1:0.903%\n",
            "Validation F1 Score: 0.7434860314175525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KQyP_QBuqAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(TCMFitter.model.state_dict(), \"TCM_4.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npXIw8yuqAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2FZy8iOmNf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}