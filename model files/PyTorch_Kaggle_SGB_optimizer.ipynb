{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "PyTorch_Kaggle_SGB_optimizer.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c04vBzVCuzhl",
        "colab_type": "code",
        "outputId": "66d93d56-3388-4880-df91-b35a9823cccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-nlp in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.38.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrXx7f2Nup_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # to handle matrix and data operation\n",
        "import pandas as pd # to read csv and handle dataframe\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchnlp.word_to_vector import FastText\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TTCKRf2up_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_location = \"TCM_7.pt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZRDPcEup_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = FastText()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "BATCH_SIZE = 96"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN_OqaFDU7OM",
        "colab_type": "code",
        "outputId": "0d791c25-5ff2-458b-92fd-aa8c28b41c46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbBI8eFup_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    '''Load dataset, data cleaned using Kaggle method.'''\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Big Armor/toxic-train-kaggle-clean.csv\")\n",
        "    df[\"word_splits\"] = df[\"word_splits\"].apply(eval)\n",
        "    df = df[(df[\"word_splits\"].apply(len) > 0) & (df[\"word_splits\"].apply(len) <= 560)]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df[\"word_splits\"], df.drop(\"word_splits\", axis=1), random_state=99, test_size=0.15)\n",
        "\n",
        "    X_train = X_train.values\n",
        "    y_train = y_train.values\n",
        "\n",
        "    X_test = X_test.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    batched_X_train = []\n",
        "    batched_y_train = []\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_train):\n",
        "        batched_X_train.append(X_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_train.append(y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_train.append(X_train[i*BATCH_SIZE:])\n",
        "    batched_y_train.append(y_train[i*BATCH_SIZE:])\n",
        "\n",
        "    batched_X_test = []\n",
        "    batched_y_test = []\n",
        "\n",
        "    del X_train\n",
        "    del y_train\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_test):\n",
        "        batched_X_test.append(X_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_test.append(y_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_test.append(X_test[i*BATCH_SIZE:])\n",
        "    batched_y_test.append(y_test[i*BATCH_SIZE:])\n",
        "\n",
        "    del X_test\n",
        "    del y_test\n",
        "\n",
        "    return batched_X_train, batched_y_train, batched_X_test, batched_y_test\n",
        "\n",
        "batched_X_train, batched_y_train, batched_X_test, batched_y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3NKRSqwup_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToxicClassifierModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512\n",
        "                 ):\n",
        "        super(ToxicClassifierModel, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.BiGRU = nn.GRU(300, hidden_size = LSTM_UNITS, bidirectional=True, num_layers=1)\n",
        "        self.BiRNN = nn.RNN(input_size = 2 * LSTM_UNITS, hidden_size = LSTM_UNITS, bidirectional=True)\n",
        "        self.hidden1 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden1Activation = hidden1Activation\n",
        "        self.hidden2 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden2Activation = hidden2Activation\n",
        "        self.hidden3 = nn.Linear(4 * LSTM_UNITS, 6)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = X.permute(0, 2, 1)\n",
        "        X = F.dropout2d(X, self.dropout_rate, training=self.training)\n",
        "        X = X.permute(0, 2, 1)\n",
        "        \n",
        "        X = self.BiGRU(X)\n",
        "        \n",
        "        X = self.BiRNN(X[0])\n",
        "        \n",
        "        X = X[0]\n",
        "        \n",
        "        X = torch.cat((torch.max(X, 1).values, torch.mean(X, 1)), 1)\n",
        "        \n",
        "        X = X.add(self.hidden1Activation(self.hidden1(X)))\n",
        "        \n",
        "        X = X.add(self.hidden2Activation(self.hidden2(X)))\n",
        "        \n",
        "        X = torch.sigmoid(self.hidden3(X))\n",
        "        \n",
        "        return X\n",
        "\n",
        "class ToxicClassifierFitter():\n",
        "    def __init__(self,\n",
        "                 optimizer,\n",
        "                 error,\n",
        "                 model,\n",
        "                 vectors,\n",
        "                 device,\n",
        "                 EPOCHS = 2,\n",
        "                 seed_acc = 0.5,\n",
        "                 save_checkpoint = True,\n",
        "                 model_save_location = model_save_location\n",
        "                 ):\n",
        "        self.optimizer = optimizer\n",
        "        self.error = error\n",
        "        self.model = model\n",
        "        self.EPOCHS = EPOCHS\n",
        "        self.acc = seed_acc\n",
        "        self.vectors = vectors\n",
        "        self.device = device\n",
        "        self.model_save_location = model_save_location\n",
        "        self.save_checkpoint = save_checkpoint\n",
        "    \n",
        "    def accuracy(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        self.acc = float(correct*100) / float(6 * BATCH_SIZE * len(batched_X_test))\n",
        "            \n",
        "        return self.acc\n",
        "\n",
        "    def F1Score(self, batched_X_test, batched_y_test):\n",
        "        preds = []\n",
        "        truePreds = []\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "            truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return f1_score(truePreds, preds)\n",
        "\n",
        "    def predict(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return predicted\n",
        "    \n",
        "    def fit(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            correct = 0\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Total correct predictions\n",
        "                predicted = output.data.round()\n",
        "                correct += (predicted == var_y_batch).sum()\n",
        "                #print(correct)\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, float(correct*100) / float(6 * BATCH_SIZE*(batch_idx+1))))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                del predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.accuracy(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation accuracy Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "\n",
        "    def fitF1(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            preds = []\n",
        "            truePreds = []\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "                truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t F1:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, f1_score(truePreds, preds)))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.F1Score(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation F1 Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "                \n",
        "\n",
        "def createFitter(LSTM_UNITS = 128,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 learning_rate=0.001,\n",
        "                 beta_1 = 0.9,\n",
        "                 beta_2 = 0.999,\n",
        "                 amsgrad=False,\n",
        "                 weight_decay=0,\n",
        "                 epochs = 1,\n",
        "                 model_save_location=model_save_location,\n",
        "                 vectors=vectors\n",
        "                 ):\n",
        "    \n",
        "    # get device\n",
        "    \n",
        "    model = ToxicClassifierModel(LSTM_UNITS = LSTM_UNITS,\n",
        "                                 dropout_rate = dropout_rate,\n",
        "                                 hidden1Activation = hidden1Activation,\n",
        "                                 hidden2Activation = hidden2Activation,\n",
        "                                 #hidden1Size = hidden1Size,\n",
        "                                 #hidden2Size = hidden2Size\n",
        "                                )\n",
        "    model.to(device)\n",
        "    \n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    \n",
        "    error = nn.BCELoss()\n",
        "    \n",
        "    # return final fitter \n",
        "\n",
        "    return ToxicClassifierFitter(optimizer, error,\n",
        "                                 model,\n",
        "                                 vectors,\n",
        "                                 device,\n",
        "                                 EPOCHS = epochs,\n",
        "                                 model_save_location = model_save_location,\n",
        "                                 save_checkpoint = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7UPlD23up_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_dict = {'relu':F.relu\n",
        "                  ,'leaky_relu':F.leaky_relu\n",
        "                  ,'softmax':F.softmax\n",
        "                  ,'selu':F.selu\n",
        "                  ,'tanh':F.tanh\n",
        "                  ,'sigmoid':torch.sigmoid\n",
        "                  ,'elu':F.elu\n",
        "                  }\n",
        "                      \n",
        "TCMFitter = createFitter(\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = activation_dict[\"relu\"],\n",
        "                 hidden2Activation = activation_dict[\"sigmoid\"],\n",
        "                 learning_rate = 1e-3, #0.002683035186257151,\n",
        "                 amsgrad = False,\n",
        "                 weight_decay = 0,\n",
        "                 epochs = 20\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enm-lmmIup_8",
        "colab_type": "code",
        "outputId": "54faa146-3dee-424d-a69a-06f7970742e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TCMFitter.model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Big Armor/TCM_2.pt\"))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9K5-NfSuqAD",
        "colab_type": "code",
        "outputId": "e1628b21-1b3c-485d-f28a-2031273f7260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TCMFitter.fitF1(batched_X_train, batched_y_train, batched_X_test, batched_y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/1395 (0%)]\tLoss: 0.042500\t F1:0.783%\n",
            "Epoch : 0 [4800/1395 (4%)]\tLoss: 0.063939\t F1:0.778%\n",
            "Epoch : 0 [9600/1395 (7%)]\tLoss: 0.032550\t F1:0.780%\n",
            "Epoch : 0 [14400/1395 (11%)]\tLoss: 0.031149\t F1:0.773%\n",
            "Epoch : 0 [19200/1395 (14%)]\tLoss: 0.089736\t F1:0.772%\n",
            "Epoch : 0 [24000/1395 (18%)]\tLoss: 0.041241\t F1:0.770%\n",
            "Epoch : 0 [28800/1395 (22%)]\tLoss: 0.048844\t F1:0.767%\n",
            "Epoch : 0 [33600/1395 (25%)]\tLoss: 0.053838\t F1:0.765%\n",
            "Epoch : 0 [38400/1395 (29%)]\tLoss: 0.041258\t F1:0.764%\n",
            "Epoch : 0 [43200/1395 (32%)]\tLoss: 0.045652\t F1:0.763%\n",
            "Epoch : 0 [48000/1395 (36%)]\tLoss: 0.030224\t F1:0.765%\n",
            "Epoch : 0 [52800/1395 (39%)]\tLoss: 0.028807\t F1:0.765%\n",
            "Epoch : 0 [57600/1395 (43%)]\tLoss: 0.026224\t F1:0.766%\n",
            "Epoch : 0 [62400/1395 (47%)]\tLoss: 0.079567\t F1:0.765%\n",
            "Epoch : 0 [67200/1395 (50%)]\tLoss: 0.028095\t F1:0.763%\n",
            "Epoch : 0 [72000/1395 (54%)]\tLoss: 0.024855\t F1:0.762%\n",
            "Epoch : 0 [76800/1395 (57%)]\tLoss: 0.072603\t F1:0.762%\n",
            "Epoch : 0 [81600/1395 (61%)]\tLoss: 0.056104\t F1:0.761%\n",
            "Epoch : 0 [86400/1395 (65%)]\tLoss: 0.060275\t F1:0.760%\n",
            "Epoch : 0 [91200/1395 (68%)]\tLoss: 0.039694\t F1:0.759%\n",
            "Epoch : 0 [96000/1395 (72%)]\tLoss: 0.078784\t F1:0.759%\n",
            "Epoch : 0 [100800/1395 (75%)]\tLoss: 0.035269\t F1:0.759%\n",
            "Epoch : 0 [105600/1395 (79%)]\tLoss: 0.055427\t F1:0.759%\n",
            "Epoch : 0 [110400/1395 (82%)]\tLoss: 0.049902\t F1:0.760%\n",
            "Epoch : 0 [115200/1395 (86%)]\tLoss: 0.029473\t F1:0.759%\n",
            "Epoch : 0 [120000/1395 (90%)]\tLoss: 0.065494\t F1:0.759%\n",
            "Epoch : 0 [124800/1395 (93%)]\tLoss: 0.059502\t F1:0.759%\n",
            "Epoch : 0 [129600/1395 (97%)]\tLoss: 0.056146\t F1:0.759%\n",
            "Validation F1 Score: 0.7602102709260008\n",
            "Saving best model...\n",
            "Epoch : 1 [0/1395 (0%)]\tLoss: 0.040353\t F1:0.826%\n",
            "Epoch : 1 [4800/1395 (4%)]\tLoss: 0.059215\t F1:0.775%\n",
            "Epoch : 1 [9600/1395 (7%)]\tLoss: 0.031549\t F1:0.782%\n",
            "Epoch : 1 [14400/1395 (11%)]\tLoss: 0.042655\t F1:0.775%\n",
            "Epoch : 1 [19200/1395 (14%)]\tLoss: 0.084086\t F1:0.775%\n",
            "Epoch : 1 [24000/1395 (18%)]\tLoss: 0.041475\t F1:0.773%\n",
            "Epoch : 1 [28800/1395 (22%)]\tLoss: 0.041615\t F1:0.770%\n",
            "Epoch : 1 [33600/1395 (25%)]\tLoss: 0.061440\t F1:0.768%\n",
            "Epoch : 1 [38400/1395 (29%)]\tLoss: 0.039836\t F1:0.766%\n",
            "Epoch : 1 [43200/1395 (32%)]\tLoss: 0.045163\t F1:0.766%\n",
            "Epoch : 1 [48000/1395 (36%)]\tLoss: 0.027358\t F1:0.767%\n",
            "Epoch : 1 [52800/1395 (39%)]\tLoss: 0.038311\t F1:0.767%\n",
            "Epoch : 1 [57600/1395 (43%)]\tLoss: 0.028029\t F1:0.768%\n",
            "Epoch : 1 [62400/1395 (47%)]\tLoss: 0.078349\t F1:0.767%\n",
            "Epoch : 1 [67200/1395 (50%)]\tLoss: 0.025342\t F1:0.766%\n",
            "Epoch : 1 [72000/1395 (54%)]\tLoss: 0.022535\t F1:0.765%\n",
            "Epoch : 1 [76800/1395 (57%)]\tLoss: 0.078287\t F1:0.765%\n",
            "Epoch : 1 [81600/1395 (61%)]\tLoss: 0.053754\t F1:0.764%\n",
            "Epoch : 1 [86400/1395 (65%)]\tLoss: 0.059408\t F1:0.763%\n",
            "Epoch : 1 [91200/1395 (68%)]\tLoss: 0.041767\t F1:0.763%\n",
            "Epoch : 1 [96000/1395 (72%)]\tLoss: 0.081877\t F1:0.762%\n",
            "Epoch : 1 [100800/1395 (75%)]\tLoss: 0.031814\t F1:0.763%\n",
            "Epoch : 1 [105600/1395 (79%)]\tLoss: 0.060601\t F1:0.763%\n",
            "Epoch : 1 [110400/1395 (82%)]\tLoss: 0.043773\t F1:0.764%\n",
            "Epoch : 1 [115200/1395 (86%)]\tLoss: 0.033884\t F1:0.763%\n",
            "Epoch : 1 [120000/1395 (90%)]\tLoss: 0.067534\t F1:0.763%\n",
            "Epoch : 1 [124800/1395 (93%)]\tLoss: 0.058010\t F1:0.763%\n",
            "Epoch : 1 [129600/1395 (97%)]\tLoss: 0.060075\t F1:0.763%\n",
            "Validation F1 Score: 0.7597198253984366\n",
            "Epoch : 2 [0/1395 (0%)]\tLoss: 0.042830\t F1:0.739%\n",
            "Epoch : 2 [4800/1395 (4%)]\tLoss: 0.057509\t F1:0.777%\n",
            "Epoch : 2 [9600/1395 (7%)]\tLoss: 0.026678\t F1:0.778%\n",
            "Epoch : 2 [14400/1395 (11%)]\tLoss: 0.033354\t F1:0.769%\n",
            "Epoch : 2 [19200/1395 (14%)]\tLoss: 0.071108\t F1:0.769%\n",
            "Epoch : 2 [24000/1395 (18%)]\tLoss: 0.042606\t F1:0.768%\n",
            "Epoch : 2 [28800/1395 (22%)]\tLoss: 0.043920\t F1:0.766%\n",
            "Epoch : 2 [33600/1395 (25%)]\tLoss: 0.051088\t F1:0.766%\n",
            "Epoch : 2 [38400/1395 (29%)]\tLoss: 0.039947\t F1:0.765%\n",
            "Epoch : 2 [43200/1395 (32%)]\tLoss: 0.045389\t F1:0.765%\n",
            "Epoch : 2 [48000/1395 (36%)]\tLoss: 0.026973\t F1:0.766%\n",
            "Epoch : 2 [52800/1395 (39%)]\tLoss: 0.028983\t F1:0.767%\n",
            "Epoch : 2 [57600/1395 (43%)]\tLoss: 0.027862\t F1:0.767%\n",
            "Epoch : 2 [62400/1395 (47%)]\tLoss: 0.076187\t F1:0.767%\n",
            "Epoch : 2 [67200/1395 (50%)]\tLoss: 0.025780\t F1:0.765%\n",
            "Epoch : 2 [72000/1395 (54%)]\tLoss: 0.025511\t F1:0.764%\n",
            "Epoch : 2 [76800/1395 (57%)]\tLoss: 0.086309\t F1:0.764%\n",
            "Epoch : 2 [81600/1395 (61%)]\tLoss: 0.069020\t F1:0.762%\n",
            "Epoch : 2 [86400/1395 (65%)]\tLoss: 0.054635\t F1:0.762%\n",
            "Epoch : 2 [91200/1395 (68%)]\tLoss: 0.041398\t F1:0.762%\n",
            "Epoch : 2 [96000/1395 (72%)]\tLoss: 0.080349\t F1:0.762%\n",
            "Epoch : 2 [100800/1395 (75%)]\tLoss: 0.038406\t F1:0.762%\n",
            "Epoch : 2 [105600/1395 (79%)]\tLoss: 0.052663\t F1:0.762%\n",
            "Epoch : 2 [110400/1395 (82%)]\tLoss: 0.052683\t F1:0.763%\n",
            "Epoch : 2 [115200/1395 (86%)]\tLoss: 0.033680\t F1:0.762%\n",
            "Epoch : 2 [120000/1395 (90%)]\tLoss: 0.066522\t F1:0.762%\n",
            "Epoch : 2 [124800/1395 (93%)]\tLoss: 0.061868\t F1:0.762%\n",
            "Epoch : 2 [129600/1395 (97%)]\tLoss: 0.060290\t F1:0.762%\n",
            "Validation F1 Score: 0.7613739993920358\n",
            "Saving best model...\n",
            "Epoch : 3 [0/1395 (0%)]\tLoss: 0.037450\t F1:0.809%\n",
            "Epoch : 3 [4800/1395 (4%)]\tLoss: 0.054663\t F1:0.775%\n",
            "Epoch : 3 [9600/1395 (7%)]\tLoss: 0.029809\t F1:0.782%\n",
            "Epoch : 3 [14400/1395 (11%)]\tLoss: 0.038923\t F1:0.773%\n",
            "Epoch : 3 [19200/1395 (14%)]\tLoss: 0.094759\t F1:0.773%\n",
            "Epoch : 3 [24000/1395 (18%)]\tLoss: 0.043057\t F1:0.770%\n",
            "Epoch : 3 [28800/1395 (22%)]\tLoss: 0.039335\t F1:0.766%\n",
            "Epoch : 3 [33600/1395 (25%)]\tLoss: 0.057000\t F1:0.766%\n",
            "Epoch : 3 [38400/1395 (29%)]\tLoss: 0.042326\t F1:0.765%\n",
            "Epoch : 3 [43200/1395 (32%)]\tLoss: 0.047996\t F1:0.765%\n",
            "Epoch : 3 [48000/1395 (36%)]\tLoss: 0.028641\t F1:0.767%\n",
            "Epoch : 3 [52800/1395 (39%)]\tLoss: 0.032914\t F1:0.768%\n",
            "Epoch : 3 [57600/1395 (43%)]\tLoss: 0.032089\t F1:0.768%\n",
            "Epoch : 3 [62400/1395 (47%)]\tLoss: 0.070722\t F1:0.768%\n",
            "Epoch : 3 [67200/1395 (50%)]\tLoss: 0.025015\t F1:0.766%\n",
            "Epoch : 3 [72000/1395 (54%)]\tLoss: 0.028740\t F1:0.764%\n",
            "Epoch : 3 [76800/1395 (57%)]\tLoss: 0.076692\t F1:0.764%\n",
            "Epoch : 3 [81600/1395 (61%)]\tLoss: 0.056288\t F1:0.763%\n",
            "Epoch : 3 [86400/1395 (65%)]\tLoss: 0.057786\t F1:0.762%\n",
            "Epoch : 3 [91200/1395 (68%)]\tLoss: 0.043344\t F1:0.762%\n",
            "Epoch : 3 [96000/1395 (72%)]\tLoss: 0.073941\t F1:0.762%\n",
            "Epoch : 3 [100800/1395 (75%)]\tLoss: 0.031812\t F1:0.762%\n",
            "Epoch : 3 [105600/1395 (79%)]\tLoss: 0.054897\t F1:0.762%\n",
            "Epoch : 3 [110400/1395 (82%)]\tLoss: 0.050210\t F1:0.763%\n",
            "Epoch : 3 [115200/1395 (86%)]\tLoss: 0.028876\t F1:0.762%\n",
            "Epoch : 3 [120000/1395 (90%)]\tLoss: 0.071485\t F1:0.762%\n",
            "Epoch : 3 [124800/1395 (93%)]\tLoss: 0.058740\t F1:0.762%\n",
            "Epoch : 3 [129600/1395 (97%)]\tLoss: 0.046980\t F1:0.762%\n",
            "Validation F1 Score: 0.7646879756468797\n",
            "Saving best model...\n",
            "Epoch : 4 [0/1395 (0%)]\tLoss: 0.043577\t F1:0.784%\n",
            "Epoch : 4 [4800/1395 (4%)]\tLoss: 0.066131\t F1:0.777%\n",
            "Epoch : 4 [9600/1395 (7%)]\tLoss: 0.031203\t F1:0.781%\n",
            "Epoch : 4 [14400/1395 (11%)]\tLoss: 0.032666\t F1:0.772%\n",
            "Epoch : 4 [19200/1395 (14%)]\tLoss: 0.084614\t F1:0.771%\n",
            "Epoch : 4 [24000/1395 (18%)]\tLoss: 0.047304\t F1:0.769%\n",
            "Epoch : 4 [28800/1395 (22%)]\tLoss: 0.043928\t F1:0.769%\n",
            "Epoch : 4 [33600/1395 (25%)]\tLoss: 0.060488\t F1:0.768%\n",
            "Epoch : 4 [38400/1395 (29%)]\tLoss: 0.042404\t F1:0.766%\n",
            "Epoch : 4 [43200/1395 (32%)]\tLoss: 0.048756\t F1:0.765%\n",
            "Epoch : 4 [48000/1395 (36%)]\tLoss: 0.029852\t F1:0.767%\n",
            "Epoch : 4 [52800/1395 (39%)]\tLoss: 0.032088\t F1:0.767%\n",
            "Epoch : 4 [57600/1395 (43%)]\tLoss: 0.028064\t F1:0.767%\n",
            "Epoch : 4 [62400/1395 (47%)]\tLoss: 0.080514\t F1:0.767%\n",
            "Epoch : 4 [67200/1395 (50%)]\tLoss: 0.027325\t F1:0.765%\n",
            "Epoch : 4 [72000/1395 (54%)]\tLoss: 0.026636\t F1:0.765%\n",
            "Epoch : 4 [76800/1395 (57%)]\tLoss: 0.075604\t F1:0.765%\n",
            "Epoch : 4 [81600/1395 (61%)]\tLoss: 0.073542\t F1:0.763%\n",
            "Epoch : 4 [86400/1395 (65%)]\tLoss: 0.072355\t F1:0.762%\n",
            "Epoch : 4 [91200/1395 (68%)]\tLoss: 0.039010\t F1:0.763%\n",
            "Epoch : 4 [96000/1395 (72%)]\tLoss: 0.064014\t F1:0.762%\n",
            "Epoch : 4 [100800/1395 (75%)]\tLoss: 0.034716\t F1:0.762%\n",
            "Epoch : 4 [105600/1395 (79%)]\tLoss: 0.057342\t F1:0.762%\n",
            "Epoch : 4 [110400/1395 (82%)]\tLoss: 0.048488\t F1:0.762%\n",
            "Epoch : 4 [115200/1395 (86%)]\tLoss: 0.031291\t F1:0.761%\n",
            "Epoch : 4 [120000/1395 (90%)]\tLoss: 0.058061\t F1:0.762%\n",
            "Epoch : 4 [124800/1395 (93%)]\tLoss: 0.053639\t F1:0.762%\n",
            "Epoch : 4 [129600/1395 (97%)]\tLoss: 0.050848\t F1:0.762%\n",
            "Validation F1 Score: 0.7583817385101396\n",
            "Epoch : 5 [0/1395 (0%)]\tLoss: 0.041023\t F1:0.756%\n",
            "Epoch : 5 [4800/1395 (4%)]\tLoss: 0.062768\t F1:0.781%\n",
            "Epoch : 5 [9600/1395 (7%)]\tLoss: 0.030903\t F1:0.783%\n",
            "Epoch : 5 [14400/1395 (11%)]\tLoss: 0.033573\t F1:0.775%\n",
            "Epoch : 5 [19200/1395 (14%)]\tLoss: 0.091094\t F1:0.774%\n",
            "Epoch : 5 [24000/1395 (18%)]\tLoss: 0.040683\t F1:0.772%\n",
            "Epoch : 5 [28800/1395 (22%)]\tLoss: 0.041913\t F1:0.770%\n",
            "Epoch : 5 [33600/1395 (25%)]\tLoss: 0.058152\t F1:0.768%\n",
            "Epoch : 5 [38400/1395 (29%)]\tLoss: 0.045507\t F1:0.768%\n",
            "Epoch : 5 [43200/1395 (32%)]\tLoss: 0.047204\t F1:0.766%\n",
            "Epoch : 5 [48000/1395 (36%)]\tLoss: 0.030360\t F1:0.767%\n",
            "Epoch : 5 [52800/1395 (39%)]\tLoss: 0.032679\t F1:0.768%\n",
            "Epoch : 5 [57600/1395 (43%)]\tLoss: 0.029432\t F1:0.768%\n",
            "Epoch : 5 [62400/1395 (47%)]\tLoss: 0.078911\t F1:0.767%\n",
            "Epoch : 5 [67200/1395 (50%)]\tLoss: 0.024014\t F1:0.765%\n",
            "Epoch : 5 [72000/1395 (54%)]\tLoss: 0.026419\t F1:0.765%\n",
            "Epoch : 5 [76800/1395 (57%)]\tLoss: 0.071152\t F1:0.764%\n",
            "Epoch : 5 [81600/1395 (61%)]\tLoss: 0.056282\t F1:0.763%\n",
            "Epoch : 5 [86400/1395 (65%)]\tLoss: 0.065035\t F1:0.762%\n",
            "Epoch : 5 [91200/1395 (68%)]\tLoss: 0.044503\t F1:0.762%\n",
            "Epoch : 5 [96000/1395 (72%)]\tLoss: 0.074712\t F1:0.762%\n",
            "Epoch : 5 [100800/1395 (75%)]\tLoss: 0.035917\t F1:0.761%\n",
            "Epoch : 5 [105600/1395 (79%)]\tLoss: 0.043643\t F1:0.762%\n",
            "Epoch : 5 [110400/1395 (82%)]\tLoss: 0.054545\t F1:0.762%\n",
            "Epoch : 5 [115200/1395 (86%)]\tLoss: 0.027183\t F1:0.761%\n",
            "Epoch : 5 [120000/1395 (90%)]\tLoss: 0.071124\t F1:0.761%\n",
            "Epoch : 5 [124800/1395 (93%)]\tLoss: 0.061677\t F1:0.761%\n",
            "Epoch : 5 [129600/1395 (97%)]\tLoss: 0.054989\t F1:0.761%\n",
            "Validation F1 Score: 0.7630481229016177\n",
            "Epoch : 6 [0/1395 (0%)]\tLoss: 0.045316\t F1:0.766%\n",
            "Epoch : 6 [4800/1395 (4%)]\tLoss: 0.059784\t F1:0.774%\n",
            "Epoch : 6 [9600/1395 (7%)]\tLoss: 0.024956\t F1:0.781%\n",
            "Epoch : 6 [14400/1395 (11%)]\tLoss: 0.034785\t F1:0.772%\n",
            "Epoch : 6 [19200/1395 (14%)]\tLoss: 0.087153\t F1:0.773%\n",
            "Epoch : 6 [24000/1395 (18%)]\tLoss: 0.036817\t F1:0.771%\n",
            "Epoch : 6 [28800/1395 (22%)]\tLoss: 0.041197\t F1:0.769%\n",
            "Epoch : 6 [33600/1395 (25%)]\tLoss: 0.058863\t F1:0.767%\n",
            "Epoch : 6 [38400/1395 (29%)]\tLoss: 0.046877\t F1:0.766%\n",
            "Epoch : 6 [43200/1395 (32%)]\tLoss: 0.043322\t F1:0.766%\n",
            "Epoch : 6 [48000/1395 (36%)]\tLoss: 0.030217\t F1:0.768%\n",
            "Epoch : 6 [52800/1395 (39%)]\tLoss: 0.032603\t F1:0.768%\n",
            "Epoch : 6 [57600/1395 (43%)]\tLoss: 0.026843\t F1:0.769%\n",
            "Epoch : 6 [62400/1395 (47%)]\tLoss: 0.065595\t F1:0.768%\n",
            "Epoch : 6 [67200/1395 (50%)]\tLoss: 0.024492\t F1:0.767%\n",
            "Epoch : 6 [72000/1395 (54%)]\tLoss: 0.023612\t F1:0.766%\n",
            "Epoch : 6 [76800/1395 (57%)]\tLoss: 0.068879\t F1:0.766%\n",
            "Epoch : 6 [81600/1395 (61%)]\tLoss: 0.058794\t F1:0.764%\n",
            "Epoch : 6 [86400/1395 (65%)]\tLoss: 0.058517\t F1:0.763%\n",
            "Epoch : 6 [91200/1395 (68%)]\tLoss: 0.042165\t F1:0.763%\n",
            "Epoch : 6 [96000/1395 (72%)]\tLoss: 0.073089\t F1:0.763%\n",
            "Epoch : 6 [100800/1395 (75%)]\tLoss: 0.035154\t F1:0.763%\n",
            "Epoch : 6 [105600/1395 (79%)]\tLoss: 0.053666\t F1:0.763%\n",
            "Epoch : 6 [110400/1395 (82%)]\tLoss: 0.052973\t F1:0.763%\n",
            "Epoch : 6 [115200/1395 (86%)]\tLoss: 0.027229\t F1:0.763%\n",
            "Epoch : 6 [120000/1395 (90%)]\tLoss: 0.072470\t F1:0.763%\n",
            "Epoch : 6 [124800/1395 (93%)]\tLoss: 0.056804\t F1:0.762%\n",
            "Epoch : 6 [129600/1395 (97%)]\tLoss: 0.057063\t F1:0.762%\n",
            "Validation F1 Score: 0.7615439746083751\n",
            "Epoch : 7 [0/1395 (0%)]\tLoss: 0.043357\t F1:0.766%\n",
            "Epoch : 7 [4800/1395 (4%)]\tLoss: 0.055638\t F1:0.779%\n",
            "Epoch : 7 [9600/1395 (7%)]\tLoss: 0.034160\t F1:0.778%\n",
            "Epoch : 7 [14400/1395 (11%)]\tLoss: 0.036365\t F1:0.769%\n",
            "Epoch : 7 [19200/1395 (14%)]\tLoss: 0.084672\t F1:0.768%\n",
            "Epoch : 7 [24000/1395 (18%)]\tLoss: 0.036984\t F1:0.765%\n",
            "Epoch : 7 [28800/1395 (22%)]\tLoss: 0.034009\t F1:0.764%\n",
            "Epoch : 7 [33600/1395 (25%)]\tLoss: 0.052979\t F1:0.765%\n",
            "Epoch : 7 [38400/1395 (29%)]\tLoss: 0.039803\t F1:0.764%\n",
            "Epoch : 7 [43200/1395 (32%)]\tLoss: 0.046098\t F1:0.763%\n",
            "Epoch : 7 [48000/1395 (36%)]\tLoss: 0.029683\t F1:0.765%\n",
            "Epoch : 7 [52800/1395 (39%)]\tLoss: 0.031178\t F1:0.766%\n",
            "Epoch : 7 [57600/1395 (43%)]\tLoss: 0.023010\t F1:0.767%\n",
            "Epoch : 7 [62400/1395 (47%)]\tLoss: 0.077886\t F1:0.767%\n",
            "Epoch : 7 [67200/1395 (50%)]\tLoss: 0.029515\t F1:0.765%\n",
            "Epoch : 7 [72000/1395 (54%)]\tLoss: 0.026405\t F1:0.765%\n",
            "Epoch : 7 [76800/1395 (57%)]\tLoss: 0.078481\t F1:0.764%\n",
            "Epoch : 7 [81600/1395 (61%)]\tLoss: 0.058417\t F1:0.762%\n",
            "Epoch : 7 [86400/1395 (65%)]\tLoss: 0.064400\t F1:0.762%\n",
            "Epoch : 7 [91200/1395 (68%)]\tLoss: 0.041017\t F1:0.762%\n",
            "Epoch : 7 [96000/1395 (72%)]\tLoss: 0.070125\t F1:0.762%\n",
            "Epoch : 7 [100800/1395 (75%)]\tLoss: 0.036667\t F1:0.762%\n",
            "Epoch : 7 [105600/1395 (79%)]\tLoss: 0.048756\t F1:0.762%\n",
            "Epoch : 7 [110400/1395 (82%)]\tLoss: 0.050546\t F1:0.763%\n",
            "Epoch : 7 [115200/1395 (86%)]\tLoss: 0.028691\t F1:0.762%\n",
            "Epoch : 7 [120000/1395 (90%)]\tLoss: 0.058216\t F1:0.762%\n",
            "Epoch : 7 [124800/1395 (93%)]\tLoss: 0.059241\t F1:0.762%\n",
            "Epoch : 7 [129600/1395 (97%)]\tLoss: 0.057368\t F1:0.762%\n",
            "Validation F1 Score: 0.7634617349545315\n",
            "Epoch : 8 [0/1395 (0%)]\tLoss: 0.041216\t F1:0.816%\n",
            "Epoch : 8 [4800/1395 (4%)]\tLoss: 0.062773\t F1:0.776%\n",
            "Epoch : 8 [9600/1395 (7%)]\tLoss: 0.026919\t F1:0.782%\n",
            "Epoch : 8 [14400/1395 (11%)]\tLoss: 0.029637\t F1:0.775%\n",
            "Epoch : 8 [19200/1395 (14%)]\tLoss: 0.091282\t F1:0.773%\n",
            "Epoch : 8 [24000/1395 (18%)]\tLoss: 0.031770\t F1:0.772%\n",
            "Epoch : 8 [28800/1395 (22%)]\tLoss: 0.038226\t F1:0.770%\n",
            "Epoch : 8 [33600/1395 (25%)]\tLoss: 0.051689\t F1:0.770%\n",
            "Epoch : 8 [38400/1395 (29%)]\tLoss: 0.044671\t F1:0.770%\n",
            "Epoch : 8 [43200/1395 (32%)]\tLoss: 0.042739\t F1:0.769%\n",
            "Epoch : 8 [48000/1395 (36%)]\tLoss: 0.025371\t F1:0.770%\n",
            "Epoch : 8 [52800/1395 (39%)]\tLoss: 0.031053\t F1:0.771%\n",
            "Epoch : 8 [57600/1395 (43%)]\tLoss: 0.028142\t F1:0.771%\n",
            "Epoch : 8 [62400/1395 (47%)]\tLoss: 0.071955\t F1:0.769%\n",
            "Epoch : 8 [67200/1395 (50%)]\tLoss: 0.026516\t F1:0.767%\n",
            "Epoch : 8 [72000/1395 (54%)]\tLoss: 0.025599\t F1:0.767%\n",
            "Epoch : 8 [76800/1395 (57%)]\tLoss: 0.071252\t F1:0.766%\n",
            "Epoch : 8 [81600/1395 (61%)]\tLoss: 0.059582\t F1:0.765%\n",
            "Epoch : 8 [86400/1395 (65%)]\tLoss: 0.063967\t F1:0.763%\n",
            "Epoch : 8 [91200/1395 (68%)]\tLoss: 0.040491\t F1:0.763%\n",
            "Epoch : 8 [96000/1395 (72%)]\tLoss: 0.078533\t F1:0.763%\n",
            "Epoch : 8 [100800/1395 (75%)]\tLoss: 0.031728\t F1:0.763%\n",
            "Epoch : 8 [105600/1395 (79%)]\tLoss: 0.056225\t F1:0.763%\n",
            "Epoch : 8 [110400/1395 (82%)]\tLoss: 0.049685\t F1:0.764%\n",
            "Epoch : 8 [115200/1395 (86%)]\tLoss: 0.028176\t F1:0.763%\n",
            "Epoch : 8 [120000/1395 (90%)]\tLoss: 0.066590\t F1:0.763%\n",
            "Epoch : 8 [124800/1395 (93%)]\tLoss: 0.059228\t F1:0.762%\n",
            "Epoch : 8 [129600/1395 (97%)]\tLoss: 0.053691\t F1:0.763%\n",
            "Validation F1 Score: 0.7614369051274179\n",
            "Epoch : 9 [0/1395 (0%)]\tLoss: 0.039441\t F1:0.739%\n",
            "Epoch : 9 [4800/1395 (4%)]\tLoss: 0.059045\t F1:0.783%\n",
            "Epoch : 9 [9600/1395 (7%)]\tLoss: 0.030260\t F1:0.785%\n",
            "Epoch : 9 [14400/1395 (11%)]\tLoss: 0.035077\t F1:0.775%\n",
            "Epoch : 9 [19200/1395 (14%)]\tLoss: 0.078763\t F1:0.777%\n",
            "Epoch : 9 [24000/1395 (18%)]\tLoss: 0.033913\t F1:0.774%\n",
            "Epoch : 9 [28800/1395 (22%)]\tLoss: 0.040994\t F1:0.772%\n",
            "Epoch : 9 [33600/1395 (25%)]\tLoss: 0.048172\t F1:0.770%\n",
            "Epoch : 9 [38400/1395 (29%)]\tLoss: 0.040724\t F1:0.769%\n",
            "Epoch : 9 [43200/1395 (32%)]\tLoss: 0.042435\t F1:0.767%\n",
            "Epoch : 9 [48000/1395 (36%)]\tLoss: 0.028817\t F1:0.769%\n",
            "Epoch : 9 [52800/1395 (39%)]\tLoss: 0.035252\t F1:0.768%\n",
            "Epoch : 9 [57600/1395 (43%)]\tLoss: 0.028259\t F1:0.769%\n",
            "Epoch : 9 [62400/1395 (47%)]\tLoss: 0.077697\t F1:0.767%\n",
            "Epoch : 9 [67200/1395 (50%)]\tLoss: 0.025181\t F1:0.766%\n",
            "Epoch : 9 [72000/1395 (54%)]\tLoss: 0.031919\t F1:0.765%\n",
            "Epoch : 9 [76800/1395 (57%)]\tLoss: 0.071462\t F1:0.765%\n",
            "Epoch : 9 [81600/1395 (61%)]\tLoss: 0.061310\t F1:0.764%\n",
            "Epoch : 9 [86400/1395 (65%)]\tLoss: 0.060166\t F1:0.763%\n",
            "Epoch : 9 [91200/1395 (68%)]\tLoss: 0.044864\t F1:0.763%\n",
            "Epoch : 9 [96000/1395 (72%)]\tLoss: 0.080146\t F1:0.763%\n",
            "Epoch : 9 [100800/1395 (75%)]\tLoss: 0.031629\t F1:0.763%\n",
            "Epoch : 9 [105600/1395 (79%)]\tLoss: 0.054489\t F1:0.763%\n",
            "Epoch : 9 [110400/1395 (82%)]\tLoss: 0.043211\t F1:0.764%\n",
            "Epoch : 9 [115200/1395 (86%)]\tLoss: 0.027492\t F1:0.763%\n",
            "Epoch : 9 [120000/1395 (90%)]\tLoss: 0.056049\t F1:0.763%\n",
            "Epoch : 9 [124800/1395 (93%)]\tLoss: 0.059182\t F1:0.763%\n",
            "Epoch : 9 [129600/1395 (97%)]\tLoss: 0.044405\t F1:0.764%\n",
            "Validation F1 Score: 0.7598522167487686\n",
            "Epoch : 10 [0/1395 (0%)]\tLoss: 0.038851\t F1:0.727%\n",
            "Epoch : 10 [4800/1395 (4%)]\tLoss: 0.057713\t F1:0.770%\n",
            "Epoch : 10 [9600/1395 (7%)]\tLoss: 0.024657\t F1:0.782%\n",
            "Epoch : 10 [14400/1395 (11%)]\tLoss: 0.028959\t F1:0.775%\n",
            "Epoch : 10 [19200/1395 (14%)]\tLoss: 0.092627\t F1:0.773%\n",
            "Epoch : 10 [24000/1395 (18%)]\tLoss: 0.037016\t F1:0.771%\n",
            "Epoch : 10 [28800/1395 (22%)]\tLoss: 0.034931\t F1:0.770%\n",
            "Epoch : 10 [33600/1395 (25%)]\tLoss: 0.042559\t F1:0.769%\n",
            "Epoch : 10 [38400/1395 (29%)]\tLoss: 0.047229\t F1:0.768%\n",
            "Epoch : 10 [43200/1395 (32%)]\tLoss: 0.046704\t F1:0.766%\n",
            "Epoch : 10 [48000/1395 (36%)]\tLoss: 0.028751\t F1:0.768%\n",
            "Epoch : 10 [52800/1395 (39%)]\tLoss: 0.036946\t F1:0.768%\n",
            "Epoch : 10 [57600/1395 (43%)]\tLoss: 0.024486\t F1:0.768%\n",
            "Epoch : 10 [62400/1395 (47%)]\tLoss: 0.071961\t F1:0.767%\n",
            "Epoch : 10 [67200/1395 (50%)]\tLoss: 0.026283\t F1:0.765%\n",
            "Epoch : 10 [72000/1395 (54%)]\tLoss: 0.027941\t F1:0.765%\n",
            "Epoch : 10 [76800/1395 (57%)]\tLoss: 0.075071\t F1:0.765%\n",
            "Epoch : 10 [81600/1395 (61%)]\tLoss: 0.055814\t F1:0.763%\n",
            "Epoch : 10 [86400/1395 (65%)]\tLoss: 0.061598\t F1:0.762%\n",
            "Epoch : 10 [91200/1395 (68%)]\tLoss: 0.041562\t F1:0.762%\n",
            "Epoch : 10 [96000/1395 (72%)]\tLoss: 0.069750\t F1:0.762%\n",
            "Epoch : 10 [100800/1395 (75%)]\tLoss: 0.033376\t F1:0.762%\n",
            "Epoch : 10 [105600/1395 (79%)]\tLoss: 0.051233\t F1:0.762%\n",
            "Epoch : 10 [110400/1395 (82%)]\tLoss: 0.047046\t F1:0.763%\n",
            "Epoch : 10 [115200/1395 (86%)]\tLoss: 0.024384\t F1:0.762%\n",
            "Epoch : 10 [120000/1395 (90%)]\tLoss: 0.065519\t F1:0.762%\n",
            "Epoch : 10 [124800/1395 (93%)]\tLoss: 0.055353\t F1:0.761%\n",
            "Epoch : 10 [129600/1395 (97%)]\tLoss: 0.051511\t F1:0.762%\n",
            "Validation F1 Score: 0.7597868415658947\n",
            "Epoch : 11 [0/1395 (0%)]\tLoss: 0.048394\t F1:0.727%\n",
            "Epoch : 11 [4800/1395 (4%)]\tLoss: 0.059266\t F1:0.775%\n",
            "Epoch : 11 [9600/1395 (7%)]\tLoss: 0.029447\t F1:0.783%\n",
            "Epoch : 11 [14400/1395 (11%)]\tLoss: 0.035103\t F1:0.776%\n",
            "Epoch : 11 [19200/1395 (14%)]\tLoss: 0.091523\t F1:0.773%\n",
            "Epoch : 11 [24000/1395 (18%)]\tLoss: 0.042156\t F1:0.772%\n",
            "Epoch : 11 [28800/1395 (22%)]\tLoss: 0.039490\t F1:0.768%\n",
            "Epoch : 11 [33600/1395 (25%)]\tLoss: 0.052049\t F1:0.768%\n",
            "Epoch : 11 [38400/1395 (29%)]\tLoss: 0.041929\t F1:0.767%\n",
            "Epoch : 11 [43200/1395 (32%)]\tLoss: 0.044425\t F1:0.766%\n",
            "Epoch : 11 [48000/1395 (36%)]\tLoss: 0.029378\t F1:0.767%\n",
            "Epoch : 11 [52800/1395 (39%)]\tLoss: 0.028496\t F1:0.767%\n",
            "Epoch : 11 [57600/1395 (43%)]\tLoss: 0.031959\t F1:0.767%\n",
            "Epoch : 11 [62400/1395 (47%)]\tLoss: 0.075915\t F1:0.766%\n",
            "Epoch : 11 [67200/1395 (50%)]\tLoss: 0.029072\t F1:0.764%\n",
            "Epoch : 11 [72000/1395 (54%)]\tLoss: 0.031136\t F1:0.764%\n",
            "Epoch : 11 [76800/1395 (57%)]\tLoss: 0.067167\t F1:0.763%\n",
            "Epoch : 11 [81600/1395 (61%)]\tLoss: 0.064207\t F1:0.762%\n",
            "Epoch : 11 [86400/1395 (65%)]\tLoss: 0.063163\t F1:0.761%\n",
            "Epoch : 11 [91200/1395 (68%)]\tLoss: 0.038295\t F1:0.761%\n",
            "Epoch : 11 [96000/1395 (72%)]\tLoss: 0.076559\t F1:0.761%\n",
            "Epoch : 11 [100800/1395 (75%)]\tLoss: 0.028185\t F1:0.761%\n",
            "Epoch : 11 [105600/1395 (79%)]\tLoss: 0.054704\t F1:0.761%\n",
            "Epoch : 11 [110400/1395 (82%)]\tLoss: 0.045397\t F1:0.762%\n",
            "Epoch : 11 [115200/1395 (86%)]\tLoss: 0.027424\t F1:0.762%\n",
            "Epoch : 11 [120000/1395 (90%)]\tLoss: 0.062699\t F1:0.762%\n",
            "Epoch : 11 [124800/1395 (93%)]\tLoss: 0.058464\t F1:0.762%\n",
            "Epoch : 11 [129600/1395 (97%)]\tLoss: 0.055710\t F1:0.762%\n",
            "Validation F1 Score: 0.7642945290004113\n",
            "Epoch : 12 [0/1395 (0%)]\tLoss: 0.040824\t F1:0.756%\n",
            "Epoch : 12 [4800/1395 (4%)]\tLoss: 0.052963\t F1:0.775%\n",
            "Epoch : 12 [9600/1395 (7%)]\tLoss: 0.025546\t F1:0.780%\n",
            "Epoch : 12 [14400/1395 (11%)]\tLoss: 0.035235\t F1:0.771%\n",
            "Epoch : 12 [19200/1395 (14%)]\tLoss: 0.080685\t F1:0.770%\n",
            "Epoch : 12 [24000/1395 (18%)]\tLoss: 0.038437\t F1:0.766%\n",
            "Epoch : 12 [28800/1395 (22%)]\tLoss: 0.041124\t F1:0.766%\n",
            "Epoch : 12 [33600/1395 (25%)]\tLoss: 0.050749\t F1:0.766%\n",
            "Epoch : 12 [38400/1395 (29%)]\tLoss: 0.035688\t F1:0.766%\n",
            "Epoch : 12 [43200/1395 (32%)]\tLoss: 0.040200\t F1:0.766%\n",
            "Epoch : 12 [48000/1395 (36%)]\tLoss: 0.027118\t F1:0.767%\n",
            "Epoch : 12 [52800/1395 (39%)]\tLoss: 0.033744\t F1:0.767%\n",
            "Epoch : 12 [57600/1395 (43%)]\tLoss: 0.030470\t F1:0.767%\n",
            "Epoch : 12 [62400/1395 (47%)]\tLoss: 0.073061\t F1:0.767%\n",
            "Epoch : 12 [67200/1395 (50%)]\tLoss: 0.027028\t F1:0.765%\n",
            "Epoch : 12 [72000/1395 (54%)]\tLoss: 0.030465\t F1:0.764%\n",
            "Epoch : 12 [76800/1395 (57%)]\tLoss: 0.071370\t F1:0.764%\n",
            "Epoch : 12 [81600/1395 (61%)]\tLoss: 0.051981\t F1:0.762%\n",
            "Epoch : 12 [86400/1395 (65%)]\tLoss: 0.056002\t F1:0.762%\n",
            "Epoch : 12 [91200/1395 (68%)]\tLoss: 0.042991\t F1:0.762%\n",
            "Epoch : 12 [96000/1395 (72%)]\tLoss: 0.068317\t F1:0.762%\n",
            "Epoch : 12 [100800/1395 (75%)]\tLoss: 0.037372\t F1:0.763%\n",
            "Epoch : 12 [105600/1395 (79%)]\tLoss: 0.050773\t F1:0.763%\n",
            "Epoch : 12 [110400/1395 (82%)]\tLoss: 0.051001\t F1:0.763%\n",
            "Epoch : 12 [115200/1395 (86%)]\tLoss: 0.028796\t F1:0.762%\n",
            "Epoch : 12 [120000/1395 (90%)]\tLoss: 0.056293\t F1:0.762%\n",
            "Epoch : 12 [124800/1395 (93%)]\tLoss: 0.052431\t F1:0.762%\n",
            "Epoch : 12 [129600/1395 (97%)]\tLoss: 0.051316\t F1:0.762%\n",
            "Validation F1 Score: 0.7594547504355846\n",
            "Epoch : 13 [0/1395 (0%)]\tLoss: 0.041338\t F1:0.773%\n",
            "Epoch : 13 [4800/1395 (4%)]\tLoss: 0.055327\t F1:0.772%\n",
            "Epoch : 13 [9600/1395 (7%)]\tLoss: 0.027480\t F1:0.778%\n",
            "Epoch : 13 [14400/1395 (11%)]\tLoss: 0.035254\t F1:0.770%\n",
            "Epoch : 13 [19200/1395 (14%)]\tLoss: 0.094405\t F1:0.771%\n",
            "Epoch : 13 [24000/1395 (18%)]\tLoss: 0.034398\t F1:0.768%\n",
            "Epoch : 13 [28800/1395 (22%)]\tLoss: 0.041820\t F1:0.766%\n",
            "Epoch : 13 [33600/1395 (25%)]\tLoss: 0.044728\t F1:0.766%\n",
            "Epoch : 13 [38400/1395 (29%)]\tLoss: 0.041946\t F1:0.765%\n",
            "Epoch : 13 [43200/1395 (32%)]\tLoss: 0.042200\t F1:0.765%\n",
            "Epoch : 13 [48000/1395 (36%)]\tLoss: 0.029666\t F1:0.767%\n",
            "Epoch : 13 [52800/1395 (39%)]\tLoss: 0.030171\t F1:0.766%\n",
            "Epoch : 13 [57600/1395 (43%)]\tLoss: 0.030286\t F1:0.767%\n",
            "Epoch : 13 [62400/1395 (47%)]\tLoss: 0.073496\t F1:0.766%\n",
            "Epoch : 13 [67200/1395 (50%)]\tLoss: 0.028030\t F1:0.764%\n",
            "Epoch : 13 [72000/1395 (54%)]\tLoss: 0.025603\t F1:0.763%\n",
            "Epoch : 13 [76800/1395 (57%)]\tLoss: 0.071962\t F1:0.763%\n",
            "Epoch : 13 [81600/1395 (61%)]\tLoss: 0.053026\t F1:0.761%\n",
            "Epoch : 13 [86400/1395 (65%)]\tLoss: 0.054066\t F1:0.760%\n",
            "Epoch : 13 [91200/1395 (68%)]\tLoss: 0.048771\t F1:0.760%\n",
            "Epoch : 13 [96000/1395 (72%)]\tLoss: 0.067151\t F1:0.760%\n",
            "Epoch : 13 [100800/1395 (75%)]\tLoss: 0.034227\t F1:0.760%\n",
            "Epoch : 13 [105600/1395 (79%)]\tLoss: 0.050734\t F1:0.761%\n",
            "Epoch : 13 [110400/1395 (82%)]\tLoss: 0.051221\t F1:0.761%\n",
            "Epoch : 13 [115200/1395 (86%)]\tLoss: 0.033370\t F1:0.761%\n",
            "Epoch : 13 [120000/1395 (90%)]\tLoss: 0.064840\t F1:0.761%\n",
            "Epoch : 13 [124800/1395 (93%)]\tLoss: 0.061378\t F1:0.761%\n",
            "Epoch : 13 [129600/1395 (97%)]\tLoss: 0.046313\t F1:0.761%\n",
            "Validation F1 Score: 0.7620416966211359\n",
            "Epoch : 14 [0/1395 (0%)]\tLoss: 0.046299\t F1:0.682%\n",
            "Epoch : 14 [4800/1395 (4%)]\tLoss: 0.053017\t F1:0.779%\n",
            "Epoch : 14 [9600/1395 (7%)]\tLoss: 0.027122\t F1:0.782%\n",
            "Epoch : 14 [14400/1395 (11%)]\tLoss: 0.038434\t F1:0.772%\n",
            "Epoch : 14 [19200/1395 (14%)]\tLoss: 0.087332\t F1:0.770%\n",
            "Epoch : 14 [24000/1395 (18%)]\tLoss: 0.040197\t F1:0.769%\n",
            "Epoch : 14 [28800/1395 (22%)]\tLoss: 0.040735\t F1:0.767%\n",
            "Epoch : 14 [33600/1395 (25%)]\tLoss: 0.048522\t F1:0.767%\n",
            "Epoch : 14 [38400/1395 (29%)]\tLoss: 0.044889\t F1:0.766%\n",
            "Epoch : 14 [43200/1395 (32%)]\tLoss: 0.041844\t F1:0.766%\n",
            "Epoch : 14 [48000/1395 (36%)]\tLoss: 0.027549\t F1:0.767%\n",
            "Epoch : 14 [52800/1395 (39%)]\tLoss: 0.030987\t F1:0.768%\n",
            "Epoch : 14 [57600/1395 (43%)]\tLoss: 0.026164\t F1:0.769%\n",
            "Epoch : 14 [62400/1395 (47%)]\tLoss: 0.072727\t F1:0.767%\n",
            "Epoch : 14 [67200/1395 (50%)]\tLoss: 0.025317\t F1:0.765%\n",
            "Epoch : 14 [72000/1395 (54%)]\tLoss: 0.030415\t F1:0.764%\n",
            "Epoch : 14 [76800/1395 (57%)]\tLoss: 0.074435\t F1:0.764%\n",
            "Epoch : 14 [81600/1395 (61%)]\tLoss: 0.049637\t F1:0.762%\n",
            "Epoch : 14 [86400/1395 (65%)]\tLoss: 0.058445\t F1:0.761%\n",
            "Epoch : 14 [91200/1395 (68%)]\tLoss: 0.041403\t F1:0.761%\n",
            "Epoch : 14 [96000/1395 (72%)]\tLoss: 0.076299\t F1:0.761%\n",
            "Epoch : 14 [100800/1395 (75%)]\tLoss: 0.033129\t F1:0.761%\n",
            "Epoch : 14 [105600/1395 (79%)]\tLoss: 0.044528\t F1:0.761%\n",
            "Epoch : 14 [110400/1395 (82%)]\tLoss: 0.055068\t F1:0.762%\n",
            "Epoch : 14 [115200/1395 (86%)]\tLoss: 0.036504\t F1:0.761%\n",
            "Epoch : 14 [120000/1395 (90%)]\tLoss: 0.062872\t F1:0.761%\n",
            "Epoch : 14 [124800/1395 (93%)]\tLoss: 0.058649\t F1:0.760%\n",
            "Epoch : 14 [129600/1395 (97%)]\tLoss: 0.048779\t F1:0.761%\n",
            "Validation F1 Score: 0.7608494921514313\n",
            "Epoch : 15 [0/1395 (0%)]\tLoss: 0.040878\t F1:0.826%\n",
            "Epoch : 15 [4800/1395 (4%)]\tLoss: 0.049720\t F1:0.779%\n",
            "Epoch : 15 [9600/1395 (7%)]\tLoss: 0.027646\t F1:0.779%\n",
            "Epoch : 15 [14400/1395 (11%)]\tLoss: 0.038166\t F1:0.773%\n",
            "Epoch : 15 [19200/1395 (14%)]\tLoss: 0.078723\t F1:0.775%\n",
            "Epoch : 15 [24000/1395 (18%)]\tLoss: 0.035594\t F1:0.773%\n",
            "Epoch : 15 [28800/1395 (22%)]\tLoss: 0.037160\t F1:0.771%\n",
            "Epoch : 15 [33600/1395 (25%)]\tLoss: 0.054900\t F1:0.770%\n",
            "Epoch : 15 [38400/1395 (29%)]\tLoss: 0.044988\t F1:0.769%\n",
            "Epoch : 15 [43200/1395 (32%)]\tLoss: 0.040266\t F1:0.767%\n",
            "Epoch : 15 [48000/1395 (36%)]\tLoss: 0.026672\t F1:0.769%\n",
            "Epoch : 15 [52800/1395 (39%)]\tLoss: 0.028998\t F1:0.768%\n",
            "Epoch : 15 [57600/1395 (43%)]\tLoss: 0.024770\t F1:0.769%\n",
            "Epoch : 15 [62400/1395 (47%)]\tLoss: 0.071101\t F1:0.768%\n",
            "Epoch : 15 [67200/1395 (50%)]\tLoss: 0.025353\t F1:0.766%\n",
            "Epoch : 15 [72000/1395 (54%)]\tLoss: 0.026374\t F1:0.766%\n",
            "Epoch : 15 [76800/1395 (57%)]\tLoss: 0.083615\t F1:0.766%\n",
            "Epoch : 15 [81600/1395 (61%)]\tLoss: 0.051736\t F1:0.764%\n",
            "Epoch : 15 [86400/1395 (65%)]\tLoss: 0.058904\t F1:0.764%\n",
            "Epoch : 15 [91200/1395 (68%)]\tLoss: 0.039236\t F1:0.763%\n",
            "Epoch : 15 [96000/1395 (72%)]\tLoss: 0.072696\t F1:0.763%\n",
            "Epoch : 15 [100800/1395 (75%)]\tLoss: 0.032407\t F1:0.763%\n",
            "Epoch : 15 [105600/1395 (79%)]\tLoss: 0.053700\t F1:0.763%\n",
            "Epoch : 15 [110400/1395 (82%)]\tLoss: 0.055074\t F1:0.764%\n",
            "Epoch : 15 [115200/1395 (86%)]\tLoss: 0.026666\t F1:0.763%\n",
            "Epoch : 15 [120000/1395 (90%)]\tLoss: 0.057825\t F1:0.763%\n",
            "Epoch : 15 [124800/1395 (93%)]\tLoss: 0.053069\t F1:0.762%\n",
            "Epoch : 15 [129600/1395 (97%)]\tLoss: 0.048885\t F1:0.763%\n",
            "Validation F1 Score: 0.75869878525839\n",
            "Epoch : 16 [0/1395 (0%)]\tLoss: 0.042816\t F1:0.756%\n",
            "Epoch : 16 [4800/1395 (4%)]\tLoss: 0.056077\t F1:0.772%\n",
            "Epoch : 16 [9600/1395 (7%)]\tLoss: 0.027630\t F1:0.782%\n",
            "Epoch : 16 [14400/1395 (11%)]\tLoss: 0.043555\t F1:0.776%\n",
            "Epoch : 16 [19200/1395 (14%)]\tLoss: 0.067865\t F1:0.773%\n",
            "Epoch : 16 [24000/1395 (18%)]\tLoss: 0.037672\t F1:0.769%\n",
            "Epoch : 16 [28800/1395 (22%)]\tLoss: 0.036314\t F1:0.767%\n",
            "Epoch : 16 [33600/1395 (25%)]\tLoss: 0.046695\t F1:0.766%\n",
            "Epoch : 16 [38400/1395 (29%)]\tLoss: 0.039689\t F1:0.766%\n",
            "Epoch : 16 [43200/1395 (32%)]\tLoss: 0.038595\t F1:0.765%\n",
            "Epoch : 16 [48000/1395 (36%)]\tLoss: 0.027526\t F1:0.767%\n",
            "Epoch : 16 [52800/1395 (39%)]\tLoss: 0.033441\t F1:0.766%\n",
            "Epoch : 16 [57600/1395 (43%)]\tLoss: 0.024587\t F1:0.767%\n",
            "Epoch : 16 [62400/1395 (47%)]\tLoss: 0.070069\t F1:0.766%\n",
            "Epoch : 16 [67200/1395 (50%)]\tLoss: 0.026564\t F1:0.764%\n",
            "Epoch : 16 [72000/1395 (54%)]\tLoss: 0.037783\t F1:0.763%\n",
            "Epoch : 16 [76800/1395 (57%)]\tLoss: 0.065863\t F1:0.763%\n",
            "Epoch : 16 [81600/1395 (61%)]\tLoss: 0.057043\t F1:0.762%\n",
            "Epoch : 16 [86400/1395 (65%)]\tLoss: 0.060146\t F1:0.761%\n",
            "Epoch : 16 [91200/1395 (68%)]\tLoss: 0.041555\t F1:0.761%\n",
            "Epoch : 16 [96000/1395 (72%)]\tLoss: 0.070779\t F1:0.761%\n",
            "Epoch : 16 [100800/1395 (75%)]\tLoss: 0.034440\t F1:0.761%\n",
            "Epoch : 16 [105600/1395 (79%)]\tLoss: 0.045247\t F1:0.761%\n",
            "Epoch : 16 [110400/1395 (82%)]\tLoss: 0.049062\t F1:0.762%\n",
            "Epoch : 16 [115200/1395 (86%)]\tLoss: 0.030343\t F1:0.761%\n",
            "Epoch : 16 [120000/1395 (90%)]\tLoss: 0.057525\t F1:0.761%\n",
            "Epoch : 16 [124800/1395 (93%)]\tLoss: 0.055032\t F1:0.761%\n",
            "Epoch : 16 [129600/1395 (97%)]\tLoss: 0.044720\t F1:0.761%\n",
            "Validation F1 Score: 0.7622672564550972\n",
            "Epoch : 17 [0/1395 (0%)]\tLoss: 0.041526\t F1:0.750%\n",
            "Epoch : 17 [4800/1395 (4%)]\tLoss: 0.051112\t F1:0.781%\n",
            "Epoch : 17 [9600/1395 (7%)]\tLoss: 0.023372\t F1:0.788%\n",
            "Epoch : 17 [14400/1395 (11%)]\tLoss: 0.037307\t F1:0.776%\n",
            "Epoch : 17 [19200/1395 (14%)]\tLoss: 0.090516\t F1:0.774%\n",
            "Epoch : 17 [24000/1395 (18%)]\tLoss: 0.036683\t F1:0.771%\n",
            "Epoch : 17 [28800/1395 (22%)]\tLoss: 0.041664\t F1:0.769%\n",
            "Epoch : 17 [33600/1395 (25%)]\tLoss: 0.047305\t F1:0.768%\n",
            "Epoch : 17 [38400/1395 (29%)]\tLoss: 0.041981\t F1:0.767%\n",
            "Epoch : 17 [43200/1395 (32%)]\tLoss: 0.041342\t F1:0.766%\n",
            "Epoch : 17 [48000/1395 (36%)]\tLoss: 0.026080\t F1:0.767%\n",
            "Epoch : 17 [52800/1395 (39%)]\tLoss: 0.032531\t F1:0.767%\n",
            "Epoch : 17 [57600/1395 (43%)]\tLoss: 0.024454\t F1:0.768%\n",
            "Epoch : 17 [62400/1395 (47%)]\tLoss: 0.068228\t F1:0.767%\n",
            "Epoch : 17 [67200/1395 (50%)]\tLoss: 0.023216\t F1:0.765%\n",
            "Epoch : 17 [72000/1395 (54%)]\tLoss: 0.029032\t F1:0.764%\n",
            "Epoch : 17 [76800/1395 (57%)]\tLoss: 0.077147\t F1:0.764%\n",
            "Epoch : 17 [81600/1395 (61%)]\tLoss: 0.057581\t F1:0.763%\n",
            "Epoch : 17 [86400/1395 (65%)]\tLoss: 0.050353\t F1:0.761%\n",
            "Epoch : 17 [91200/1395 (68%)]\tLoss: 0.042182\t F1:0.762%\n",
            "Epoch : 17 [96000/1395 (72%)]\tLoss: 0.064346\t F1:0.762%\n",
            "Epoch : 17 [100800/1395 (75%)]\tLoss: 0.033607\t F1:0.762%\n",
            "Epoch : 17 [105600/1395 (79%)]\tLoss: 0.048745\t F1:0.762%\n",
            "Epoch : 17 [110400/1395 (82%)]\tLoss: 0.049773\t F1:0.763%\n",
            "Epoch : 17 [115200/1395 (86%)]\tLoss: 0.030258\t F1:0.762%\n",
            "Epoch : 17 [120000/1395 (90%)]\tLoss: 0.059270\t F1:0.762%\n",
            "Epoch : 17 [124800/1395 (93%)]\tLoss: 0.062166\t F1:0.762%\n",
            "Epoch : 17 [129600/1395 (97%)]\tLoss: 0.046877\t F1:0.762%\n",
            "Validation F1 Score: 0.762573582567386\n",
            "Epoch : 18 [0/1395 (0%)]\tLoss: 0.042333\t F1:0.714%\n",
            "Epoch : 18 [4800/1395 (4%)]\tLoss: 0.047384\t F1:0.771%\n",
            "Epoch : 18 [9600/1395 (7%)]\tLoss: 0.026553\t F1:0.779%\n",
            "Epoch : 18 [14400/1395 (11%)]\tLoss: 0.034595\t F1:0.771%\n",
            "Epoch : 18 [19200/1395 (14%)]\tLoss: 0.085593\t F1:0.770%\n",
            "Epoch : 18 [24000/1395 (18%)]\tLoss: 0.044211\t F1:0.767%\n",
            "Epoch : 18 [28800/1395 (22%)]\tLoss: 0.039594\t F1:0.765%\n",
            "Epoch : 18 [33600/1395 (25%)]\tLoss: 0.055148\t F1:0.766%\n",
            "Epoch : 18 [38400/1395 (29%)]\tLoss: 0.043997\t F1:0.766%\n",
            "Epoch : 18 [43200/1395 (32%)]\tLoss: 0.038310\t F1:0.765%\n",
            "Epoch : 18 [48000/1395 (36%)]\tLoss: 0.024873\t F1:0.767%\n",
            "Epoch : 18 [52800/1395 (39%)]\tLoss: 0.034051\t F1:0.767%\n",
            "Epoch : 18 [57600/1395 (43%)]\tLoss: 0.027030\t F1:0.768%\n",
            "Epoch : 18 [62400/1395 (47%)]\tLoss: 0.063959\t F1:0.767%\n",
            "Epoch : 18 [67200/1395 (50%)]\tLoss: 0.025225\t F1:0.765%\n",
            "Epoch : 18 [72000/1395 (54%)]\tLoss: 0.026378\t F1:0.763%\n",
            "Epoch : 18 [76800/1395 (57%)]\tLoss: 0.072021\t F1:0.763%\n",
            "Epoch : 18 [81600/1395 (61%)]\tLoss: 0.054279\t F1:0.761%\n",
            "Epoch : 18 [86400/1395 (65%)]\tLoss: 0.065431\t F1:0.760%\n",
            "Epoch : 18 [91200/1395 (68%)]\tLoss: 0.037020\t F1:0.760%\n",
            "Epoch : 18 [96000/1395 (72%)]\tLoss: 0.069904\t F1:0.760%\n",
            "Epoch : 18 [100800/1395 (75%)]\tLoss: 0.035131\t F1:0.760%\n",
            "Epoch : 18 [105600/1395 (79%)]\tLoss: 0.051963\t F1:0.760%\n",
            "Epoch : 18 [110400/1395 (82%)]\tLoss: 0.048717\t F1:0.761%\n",
            "Epoch : 18 [115200/1395 (86%)]\tLoss: 0.032898\t F1:0.760%\n",
            "Epoch : 18 [120000/1395 (90%)]\tLoss: 0.066862\t F1:0.760%\n",
            "Epoch : 18 [124800/1395 (93%)]\tLoss: 0.051272\t F1:0.760%\n",
            "Epoch : 18 [129600/1395 (97%)]\tLoss: 0.046896\t F1:0.760%\n",
            "Validation F1 Score: 0.7584855050036108\n",
            "Epoch : 19 [0/1395 (0%)]\tLoss: 0.037043\t F1:0.783%\n",
            "Epoch : 19 [4800/1395 (4%)]\tLoss: 0.049672\t F1:0.775%\n",
            "Epoch : 19 [9600/1395 (7%)]\tLoss: 0.027586\t F1:0.781%\n",
            "Epoch : 19 [14400/1395 (11%)]\tLoss: 0.034002\t F1:0.771%\n",
            "Epoch : 19 [19200/1395 (14%)]\tLoss: 0.082496\t F1:0.772%\n",
            "Epoch : 19 [24000/1395 (18%)]\tLoss: 0.038181\t F1:0.769%\n",
            "Epoch : 19 [28800/1395 (22%)]\tLoss: 0.042297\t F1:0.766%\n",
            "Epoch : 19 [33600/1395 (25%)]\tLoss: 0.054325\t F1:0.766%\n",
            "Epoch : 19 [38400/1395 (29%)]\tLoss: 0.036213\t F1:0.765%\n",
            "Epoch : 19 [43200/1395 (32%)]\tLoss: 0.039853\t F1:0.765%\n",
            "Epoch : 19 [48000/1395 (36%)]\tLoss: 0.027215\t F1:0.768%\n",
            "Epoch : 19 [52800/1395 (39%)]\tLoss: 0.033335\t F1:0.768%\n",
            "Epoch : 19 [57600/1395 (43%)]\tLoss: 0.031533\t F1:0.768%\n",
            "Epoch : 19 [62400/1395 (47%)]\tLoss: 0.069906\t F1:0.767%\n",
            "Epoch : 19 [67200/1395 (50%)]\tLoss: 0.023181\t F1:0.765%\n",
            "Epoch : 19 [72000/1395 (54%)]\tLoss: 0.028561\t F1:0.764%\n",
            "Epoch : 19 [76800/1395 (57%)]\tLoss: 0.064217\t F1:0.764%\n",
            "Epoch : 19 [81600/1395 (61%)]\tLoss: 0.048545\t F1:0.762%\n",
            "Epoch : 19 [86400/1395 (65%)]\tLoss: 0.052584\t F1:0.762%\n",
            "Epoch : 19 [91200/1395 (68%)]\tLoss: 0.046410\t F1:0.762%\n",
            "Epoch : 19 [96000/1395 (72%)]\tLoss: 0.074551\t F1:0.762%\n",
            "Epoch : 19 [100800/1395 (75%)]\tLoss: 0.036113\t F1:0.762%\n",
            "Epoch : 19 [105600/1395 (79%)]\tLoss: 0.046764\t F1:0.762%\n",
            "Epoch : 19 [110400/1395 (82%)]\tLoss: 0.052469\t F1:0.763%\n",
            "Epoch : 19 [115200/1395 (86%)]\tLoss: 0.029833\t F1:0.762%\n",
            "Epoch : 19 [120000/1395 (90%)]\tLoss: 0.063612\t F1:0.762%\n",
            "Epoch : 19 [124800/1395 (93%)]\tLoss: 0.053337\t F1:0.762%\n",
            "Epoch : 19 [129600/1395 (97%)]\tLoss: 0.051010\t F1:0.762%\n",
            "Validation F1 Score: 0.7591422355744328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KQyP_QBuqAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(TCMFitter.model.state_dict(), \"TCM_4.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npXIw8yuqAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2FZy8iOmNf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}