{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of TunedKaggleModel.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "c04vBzVCuzhl",
        "colab_type": "code",
        "outputId": "05f4c869-3977-4b15-b1fe-d95ed502a4bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "!pip install pytorch-nlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 28.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 6.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (1.18.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-nlp) (4.38.0)\n",
            "Installing collected packages: pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrXx7f2Nup_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # to handle matrix and data operation\n",
        "import pandas as pd # to read csv and handle dataframe\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torchnlp.word_to_vector import FastText\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TTCKRf2up_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_location = \"TCM_7.pt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXZRDPcEup_p",
        "colab_type": "code",
        "outputId": "450fc68c-55f2-40e6-c872-5ef30adddd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "vectors = FastText()\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "BATCH_SIZE = 96"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wiki.en.vec: 6.60GB [14:10, 7.76MB/s]                            \n",
            "  0%|          | 0/2519371 [00:00<?, ?it/s]Skipping token 2519370 with 1-dimensional vector ['300']; likely a header\n",
            "100%|██████████| 2519371/2519371 [04:52<00:00, 8609.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKwOSxLSU6dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN_OqaFDU7OM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "cef56f8e-d3f4-412a-9f2d-db00ae5eb316"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxbBI8eFup_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data():\n",
        "    '''Load dataset, data cleaned using Kaggle method.'''\n",
        "    df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Big Armor/toxic-train-kaggle-clean.csv\")\n",
        "    df[\"word_splits\"] = df[\"word_splits\"].apply(eval)\n",
        "    df = df[(df[\"word_splits\"].apply(len) > 0) & (df[\"word_splits\"].apply(len) <= 560)]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df[\"word_splits\"], df.drop(\"word_splits\", axis=1), random_state=99, test_size=0.15)\n",
        "\n",
        "    X_train = X_train.values\n",
        "    y_train = y_train.values\n",
        "\n",
        "    X_test = X_test.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    batched_X_train = []\n",
        "    batched_y_train = []\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_train):\n",
        "        batched_X_train.append(X_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_train.append(y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_train.append(X_train[i*BATCH_SIZE:])\n",
        "    batched_y_train.append(y_train[i*BATCH_SIZE:])\n",
        "\n",
        "    batched_X_test = []\n",
        "    batched_y_test = []\n",
        "\n",
        "    del X_train\n",
        "    del y_train\n",
        "\n",
        "    i=0\n",
        "    while (i+1) * BATCH_SIZE < len(X_test):\n",
        "        batched_X_test.append(X_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        batched_y_test.append(y_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
        "        i+=1\n",
        "    batched_X_test.append(X_test[i*BATCH_SIZE:])\n",
        "    batched_y_test.append(y_test[i*BATCH_SIZE:])\n",
        "\n",
        "    del X_test\n",
        "    del y_test\n",
        "\n",
        "    return batched_X_train, batched_y_train, batched_X_test, batched_y_test\n",
        "\n",
        "batched_X_train, batched_y_train, batched_X_test, batched_y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3NKRSqwup_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ToxicClassifierModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512\n",
        "                 ):\n",
        "        super(ToxicClassifierModel, self).__init__()\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.BiGRU = nn.GRU(300, hidden_size = LSTM_UNITS, bidirectional=True, num_layers=1)\n",
        "        self.BiRNN = nn.RNN(input_size = 2 * LSTM_UNITS, hidden_size = LSTM_UNITS, bidirectional=True)\n",
        "        self.hidden1 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden1Activation = hidden1Activation\n",
        "        self.hidden2 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
        "        self.hidden2Activation = hidden2Activation\n",
        "        self.hidden3 = nn.Linear(4 * LSTM_UNITS, 6)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = X.permute(0, 2, 1)\n",
        "        X = F.dropout2d(X, self.dropout_rate, training=self.training)\n",
        "        X = X.permute(0, 2, 1)\n",
        "        \n",
        "        X = self.BiGRU(X)\n",
        "        \n",
        "        X = self.BiRNN(X[0])\n",
        "        \n",
        "        X = X[0]\n",
        "        \n",
        "        X = torch.cat((torch.max(X, 1).values, torch.mean(X, 1)), 1)\n",
        "        \n",
        "        X = X.add(self.hidden1Activation(self.hidden1(X)))\n",
        "        \n",
        "        X = X.add(self.hidden2Activation(self.hidden2(X)))\n",
        "        \n",
        "        X = torch.sigmoid(self.hidden3(X))\n",
        "        \n",
        "        return X\n",
        "\n",
        "class ToxicClassifierFitter():\n",
        "    def __init__(self,\n",
        "                 optimizer,\n",
        "                 error,\n",
        "                 model,\n",
        "                 vectors,\n",
        "                 device,\n",
        "                 EPOCHS = 2,\n",
        "                 seed_acc = 0.5,\n",
        "                 save_checkpoint = True,\n",
        "                 model_save_location = model_save_location\n",
        "                 ):\n",
        "        self.optimizer = optimizer\n",
        "        self.error = error\n",
        "        self.model = model\n",
        "        self.EPOCHS = EPOCHS\n",
        "        self.acc = seed_acc\n",
        "        self.vectors = vectors\n",
        "        self.device = device\n",
        "        self.model_save_location = model_save_location\n",
        "        self.save_checkpoint = save_checkpoint\n",
        "    \n",
        "    def accuracy(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            correct += (predicted == var_y_batch).sum()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        self.acc = float(correct*100) / float(6 * BATCH_SIZE * len(batched_X_test))\n",
        "            \n",
        "        return self.acc\n",
        "\n",
        "    def F1Score(self, batched_X_test, batched_y_test):\n",
        "        preds = []\n",
        "        truePreds = []\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "            truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return f1_score(truePreds, preds)\n",
        "\n",
        "    def predict(self, batched_X_test, batched_y_test):\n",
        "        correct = 0\n",
        "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
        "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "            output = self.model(var_X_batch)\n",
        "\n",
        "            # Total correct predictions\n",
        "            predicted = output.data.round()\n",
        "            del var_X_batch\n",
        "            del var_y_batch\n",
        "            del output\n",
        "            del predicted\n",
        "            torch.cuda.empty_cache()\n",
        "            \n",
        "        return predicted\n",
        "    \n",
        "    def fit(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            correct = 0\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # Total correct predictions\n",
        "                predicted = output.data.round()\n",
        "                correct += (predicted == var_y_batch).sum()\n",
        "                #print(correct)\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, float(correct*100) / float(6 * BATCH_SIZE*(batch_idx+1))))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                del predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.accuracy(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation accuracy Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "\n",
        "    def fitF1(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
        "        for epoch in range(self.EPOCHS):\n",
        "            preds = []\n",
        "            truePreds = []\n",
        "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
        "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
        "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(var_X_batch)\n",
        "                loss = self.error(output, var_y_batch)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
        "                truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
        "\n",
        "                if batch_idx % 50 == 0:\n",
        "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t F1:{:.3f}%'.format(\n",
        "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, f1_score(truePreds, preds)))\n",
        "                del var_X_batch\n",
        "                del var_y_batch\n",
        "                del loss\n",
        "                del output\n",
        "                torch.cuda.empty_cache()\n",
        "            \n",
        "            torch.cuda.empty_cache()\n",
        "            if self.save_checkpoint:\n",
        "                acc2 = self.F1Score(batched_X_test, batched_y_test)\n",
        "                \n",
        "                print(\"Validation F1 Score:\", acc2)\n",
        "                \n",
        "                if acc2 > self.acc:\n",
        "                    print(\"Saving best model...\")\n",
        "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
        "                 \n",
        "                    self.acc = acc2\n",
        "                \n",
        "\n",
        "def createFitter(LSTM_UNITS = 128,\n",
        "                 #hidden1Size = 512,\n",
        "                 #hidden2Size = 512,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = F.relu,\n",
        "                 hidden2Activation = F.relu,\n",
        "                 learning_rate=0.001,\n",
        "                 beta_1 = 0.9,\n",
        "                 beta_2 = 0.999,\n",
        "                 amsgrad=False,\n",
        "                 weight_decay=0,\n",
        "                 epochs = 1,\n",
        "                 model_save_location=model_save_location,\n",
        "                 vectors=vectors\n",
        "                 ):\n",
        "    \n",
        "    # get device\n",
        "    \n",
        "    model = ToxicClassifierModel(LSTM_UNITS = LSTM_UNITS,\n",
        "                                 dropout_rate = dropout_rate,\n",
        "                                 hidden1Activation = hidden1Activation,\n",
        "                                 hidden2Activation = hidden2Activation,\n",
        "                                 #hidden1Size = hidden1Size,\n",
        "                                 #hidden2Size = hidden2Size\n",
        "                                )\n",
        "    model.to(device)\n",
        "    \n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1,beta_2), amsgrad=amsgrad, weight_decay=weight_decay)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(beta_1,beta_2), amsgrad=amsgrad, weight_decay=weight_decay)\n",
        "    \n",
        "    error = nn.BCELoss()\n",
        "    \n",
        "    # return final fitter \n",
        "\n",
        "    return ToxicClassifierFitter(optimizer, error,\n",
        "                                 model,\n",
        "                                 vectors,\n",
        "                                 device,\n",
        "                                 EPOCHS = epochs,\n",
        "                                 model_save_location = model_save_location,\n",
        "                                 save_checkpoint = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7UPlD23up_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_dict = {'relu':F.relu\n",
        "                  ,'leaky_relu':F.leaky_relu\n",
        "                  ,'softmax':F.softmax\n",
        "                  ,'selu':F.selu\n",
        "                  ,'tanh':F.tanh\n",
        "                  ,'sigmoid':torch.sigmoid\n",
        "                  ,'elu':F.elu\n",
        "                  }\n",
        "                      \n",
        "TCMFitter = createFitter(\n",
        "                 LSTM_UNITS = 128,\n",
        "                 dropout_rate = 0.2,\n",
        "                 hidden1Activation = activation_dict[\"relu\"],\n",
        "                 hidden2Activation = activation_dict[\"sigmoid\"],\n",
        "                 learning_rate = 1e-3, #0.002683035186257151,\n",
        "                 amsgrad = False,\n",
        "                 weight_decay = 0,\n",
        "                 epochs = 20\n",
        "                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enm-lmmIup_8",
        "colab_type": "code",
        "outputId": "575a140e-767a-4fd6-a4da-41feab6803e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "TCMFitter.model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Big Armor/TCM_2.pt\"))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9K5-NfSuqAD",
        "colab_type": "code",
        "outputId": "859c58b7-c47c-438e-8012-f77a89e058cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TCMFitter.fitF1(batched_X_train, batched_y_train, batched_X_test, batched_y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 0 [0/1395 (0%)]\tLoss: 0.044758\t F1:0.739%\n",
            "Epoch : 0 [4800/1395 (4%)]\tLoss: 0.053086\t F1:0.768%\n",
            "Epoch : 0 [9600/1395 (7%)]\tLoss: 0.033887\t F1:0.767%\n",
            "Epoch : 0 [14400/1395 (11%)]\tLoss: 0.042324\t F1:0.762%\n",
            "Epoch : 0 [19200/1395 (14%)]\tLoss: 0.083485\t F1:0.763%\n",
            "Epoch : 0 [24000/1395 (18%)]\tLoss: 0.041964\t F1:0.763%\n",
            "Epoch : 0 [28800/1395 (22%)]\tLoss: 0.041304\t F1:0.761%\n",
            "Epoch : 0 [33600/1395 (25%)]\tLoss: 0.050023\t F1:0.760%\n",
            "Epoch : 0 [38400/1395 (29%)]\tLoss: 0.050448\t F1:0.759%\n",
            "Epoch : 0 [43200/1395 (32%)]\tLoss: 0.049691\t F1:0.758%\n",
            "Epoch : 0 [48000/1395 (36%)]\tLoss: 0.032903\t F1:0.760%\n",
            "Epoch : 0 [52800/1395 (39%)]\tLoss: 0.035051\t F1:0.760%\n",
            "Epoch : 0 [57600/1395 (43%)]\tLoss: 0.026435\t F1:0.761%\n",
            "Epoch : 0 [62400/1395 (47%)]\tLoss: 0.063054\t F1:0.761%\n",
            "Epoch : 0 [67200/1395 (50%)]\tLoss: 0.030862\t F1:0.759%\n",
            "Epoch : 0 [72000/1395 (54%)]\tLoss: 0.032690\t F1:0.759%\n",
            "Epoch : 0 [76800/1395 (57%)]\tLoss: 0.067879\t F1:0.758%\n",
            "Epoch : 0 [81600/1395 (61%)]\tLoss: 0.059362\t F1:0.756%\n",
            "Epoch : 0 [86400/1395 (65%)]\tLoss: 0.054229\t F1:0.755%\n",
            "Epoch : 0 [91200/1395 (68%)]\tLoss: 0.048194\t F1:0.755%\n",
            "Epoch : 0 [96000/1395 (72%)]\tLoss: 0.065283\t F1:0.755%\n",
            "Epoch : 0 [100800/1395 (75%)]\tLoss: 0.032058\t F1:0.755%\n",
            "Epoch : 0 [105600/1395 (79%)]\tLoss: 0.047618\t F1:0.755%\n",
            "Epoch : 0 [110400/1395 (82%)]\tLoss: 0.051726\t F1:0.756%\n",
            "Epoch : 0 [115200/1395 (86%)]\tLoss: 0.038582\t F1:0.755%\n",
            "Epoch : 0 [120000/1395 (90%)]\tLoss: 0.055824\t F1:0.754%\n",
            "Epoch : 0 [124800/1395 (93%)]\tLoss: 0.048215\t F1:0.754%\n",
            "Epoch : 0 [129600/1395 (97%)]\tLoss: 0.058945\t F1:0.755%\n",
            "Validation F1 Score: 0.7464834805364736\n",
            "Saving best model...\n",
            "Epoch : 1 [0/1395 (0%)]\tLoss: 0.037300\t F1:0.791%\n",
            "Epoch : 1 [4800/1395 (4%)]\tLoss: 0.049584\t F1:0.787%\n",
            "Epoch : 1 [9600/1395 (7%)]\tLoss: 0.029220\t F1:0.784%\n",
            "Epoch : 1 [14400/1395 (11%)]\tLoss: 0.041123\t F1:0.774%\n",
            "Epoch : 1 [19200/1395 (14%)]\tLoss: 0.052024\t F1:0.779%\n",
            "Epoch : 1 [24000/1395 (18%)]\tLoss: 0.040715\t F1:0.777%\n",
            "Epoch : 1 [28800/1395 (22%)]\tLoss: 0.036988\t F1:0.776%\n",
            "Epoch : 1 [33600/1395 (25%)]\tLoss: 0.036951\t F1:0.774%\n",
            "Epoch : 1 [38400/1395 (29%)]\tLoss: 0.050939\t F1:0.773%\n",
            "Epoch : 1 [43200/1395 (32%)]\tLoss: 0.045157\t F1:0.772%\n",
            "Epoch : 1 [48000/1395 (36%)]\tLoss: 0.030982\t F1:0.773%\n",
            "Epoch : 1 [52800/1395 (39%)]\tLoss: 0.028694\t F1:0.773%\n",
            "Epoch : 1 [57600/1395 (43%)]\tLoss: 0.024067\t F1:0.774%\n",
            "Epoch : 1 [62400/1395 (47%)]\tLoss: 0.060032\t F1:0.774%\n",
            "Epoch : 1 [67200/1395 (50%)]\tLoss: 0.030626\t F1:0.772%\n",
            "Epoch : 1 [72000/1395 (54%)]\tLoss: 0.032177\t F1:0.773%\n",
            "Epoch : 1 [76800/1395 (57%)]\tLoss: 0.068116\t F1:0.772%\n",
            "Epoch : 1 [81600/1395 (61%)]\tLoss: 0.050070\t F1:0.771%\n",
            "Epoch : 1 [86400/1395 (65%)]\tLoss: 0.060195\t F1:0.770%\n",
            "Epoch : 1 [91200/1395 (68%)]\tLoss: 0.035594\t F1:0.770%\n",
            "Epoch : 1 [96000/1395 (72%)]\tLoss: 0.055264\t F1:0.769%\n",
            "Epoch : 1 [100800/1395 (75%)]\tLoss: 0.033411\t F1:0.769%\n",
            "Epoch : 1 [105600/1395 (79%)]\tLoss: 0.035781\t F1:0.769%\n",
            "Epoch : 1 [110400/1395 (82%)]\tLoss: 0.052060\t F1:0.769%\n",
            "Epoch : 1 [115200/1395 (86%)]\tLoss: 0.037258\t F1:0.769%\n",
            "Epoch : 1 [120000/1395 (90%)]\tLoss: 0.055458\t F1:0.768%\n",
            "Epoch : 1 [124800/1395 (93%)]\tLoss: 0.048013\t F1:0.767%\n",
            "Epoch : 1 [129600/1395 (97%)]\tLoss: 0.053691\t F1:0.768%\n",
            "Validation F1 Score: 0.7541328840686533\n",
            "Saving best model...\n",
            "Epoch : 2 [0/1395 (0%)]\tLoss: 0.038448\t F1:0.756%\n",
            "Epoch : 2 [4800/1395 (4%)]\tLoss: 0.051958\t F1:0.797%\n",
            "Epoch : 2 [9600/1395 (7%)]\tLoss: 0.034191\t F1:0.796%\n",
            "Epoch : 2 [14400/1395 (11%)]\tLoss: 0.031449\t F1:0.792%\n",
            "Epoch : 2 [19200/1395 (14%)]\tLoss: 0.043857\t F1:0.795%\n",
            "Epoch : 2 [24000/1395 (18%)]\tLoss: 0.037715\t F1:0.794%\n",
            "Epoch : 2 [28800/1395 (22%)]\tLoss: 0.033853\t F1:0.794%\n",
            "Epoch : 2 [33600/1395 (25%)]\tLoss: 0.031407\t F1:0.794%\n",
            "Epoch : 2 [38400/1395 (29%)]\tLoss: 0.046946\t F1:0.794%\n",
            "Epoch : 2 [43200/1395 (32%)]\tLoss: 0.045654\t F1:0.792%\n",
            "Epoch : 2 [48000/1395 (36%)]\tLoss: 0.029261\t F1:0.793%\n",
            "Epoch : 2 [52800/1395 (39%)]\tLoss: 0.033358\t F1:0.792%\n",
            "Epoch : 2 [57600/1395 (43%)]\tLoss: 0.024165\t F1:0.792%\n",
            "Epoch : 2 [62400/1395 (47%)]\tLoss: 0.050896\t F1:0.792%\n",
            "Epoch : 2 [67200/1395 (50%)]\tLoss: 0.027668\t F1:0.790%\n",
            "Epoch : 2 [72000/1395 (54%)]\tLoss: 0.034936\t F1:0.790%\n",
            "Epoch : 2 [76800/1395 (57%)]\tLoss: 0.067305\t F1:0.789%\n",
            "Epoch : 2 [81600/1395 (61%)]\tLoss: 0.046248\t F1:0.788%\n",
            "Epoch : 2 [86400/1395 (65%)]\tLoss: 0.047148\t F1:0.788%\n",
            "Epoch : 2 [91200/1395 (68%)]\tLoss: 0.034684\t F1:0.789%\n",
            "Epoch : 2 [96000/1395 (72%)]\tLoss: 0.051745\t F1:0.788%\n",
            "Epoch : 2 [100800/1395 (75%)]\tLoss: 0.032155\t F1:0.787%\n",
            "Epoch : 2 [105600/1395 (79%)]\tLoss: 0.038653\t F1:0.787%\n",
            "Epoch : 2 [110400/1395 (82%)]\tLoss: 0.049026\t F1:0.787%\n",
            "Epoch : 2 [115200/1395 (86%)]\tLoss: 0.031647\t F1:0.786%\n",
            "Epoch : 2 [120000/1395 (90%)]\tLoss: 0.048091\t F1:0.786%\n",
            "Epoch : 2 [124800/1395 (93%)]\tLoss: 0.042763\t F1:0.785%\n",
            "Epoch : 2 [129600/1395 (97%)]\tLoss: 0.054142\t F1:0.786%\n",
            "Validation F1 Score: 0.7534089726241282\n",
            "Epoch : 3 [0/1395 (0%)]\tLoss: 0.035841\t F1:0.809%\n",
            "Epoch : 3 [4800/1395 (4%)]\tLoss: 0.048807\t F1:0.807%\n",
            "Epoch : 3 [9600/1395 (7%)]\tLoss: 0.039675\t F1:0.809%\n",
            "Epoch : 3 [14400/1395 (11%)]\tLoss: 0.029540\t F1:0.805%\n",
            "Epoch : 3 [19200/1395 (14%)]\tLoss: 0.030299\t F1:0.809%\n",
            "Epoch : 3 [24000/1395 (18%)]\tLoss: 0.038223\t F1:0.808%\n",
            "Epoch : 3 [28800/1395 (22%)]\tLoss: 0.034840\t F1:0.808%\n",
            "Epoch : 3 [33600/1395 (25%)]\tLoss: 0.032051\t F1:0.807%\n",
            "Epoch : 3 [38400/1395 (29%)]\tLoss: 0.040673\t F1:0.805%\n",
            "Epoch : 3 [43200/1395 (32%)]\tLoss: 0.045449\t F1:0.805%\n",
            "Epoch : 3 [48000/1395 (36%)]\tLoss: 0.025724\t F1:0.805%\n",
            "Epoch : 3 [52800/1395 (39%)]\tLoss: 0.028764\t F1:0.806%\n",
            "Epoch : 3 [57600/1395 (43%)]\tLoss: 0.025302\t F1:0.806%\n",
            "Epoch : 3 [62400/1395 (47%)]\tLoss: 0.055520\t F1:0.805%\n",
            "Epoch : 3 [67200/1395 (50%)]\tLoss: 0.024153\t F1:0.803%\n",
            "Epoch : 3 [72000/1395 (54%)]\tLoss: 0.025436\t F1:0.803%\n",
            "Epoch : 3 [76800/1395 (57%)]\tLoss: 0.055388\t F1:0.804%\n",
            "Epoch : 3 [81600/1395 (61%)]\tLoss: 0.039768\t F1:0.803%\n",
            "Epoch : 3 [86400/1395 (65%)]\tLoss: 0.044494\t F1:0.803%\n",
            "Epoch : 3 [91200/1395 (68%)]\tLoss: 0.034006\t F1:0.803%\n",
            "Epoch : 3 [96000/1395 (72%)]\tLoss: 0.054401\t F1:0.802%\n",
            "Epoch : 3 [100800/1395 (75%)]\tLoss: 0.023254\t F1:0.802%\n",
            "Epoch : 3 [105600/1395 (79%)]\tLoss: 0.038257\t F1:0.801%\n",
            "Epoch : 3 [110400/1395 (82%)]\tLoss: 0.047711\t F1:0.802%\n",
            "Epoch : 3 [115200/1395 (86%)]\tLoss: 0.030094\t F1:0.800%\n",
            "Epoch : 3 [120000/1395 (90%)]\tLoss: 0.049829\t F1:0.799%\n",
            "Epoch : 3 [124800/1395 (93%)]\tLoss: 0.042890\t F1:0.799%\n",
            "Epoch : 3 [129600/1395 (97%)]\tLoss: 0.054187\t F1:0.799%\n",
            "Validation F1 Score: 0.7450687706578527\n",
            "Epoch : 4 [0/1395 (0%)]\tLoss: 0.029151\t F1:0.826%\n",
            "Epoch : 4 [4800/1395 (4%)]\tLoss: 0.039931\t F1:0.820%\n",
            "Epoch : 4 [9600/1395 (7%)]\tLoss: 0.023446\t F1:0.822%\n",
            "Epoch : 4 [14400/1395 (11%)]\tLoss: 0.041231\t F1:0.813%\n",
            "Epoch : 4 [19200/1395 (14%)]\tLoss: 0.030669\t F1:0.818%\n",
            "Epoch : 4 [24000/1395 (18%)]\tLoss: 0.033377\t F1:0.819%\n",
            "Epoch : 4 [28800/1395 (22%)]\tLoss: 0.035782\t F1:0.815%\n",
            "Epoch : 4 [33600/1395 (25%)]\tLoss: 0.025441\t F1:0.815%\n",
            "Epoch : 4 [38400/1395 (29%)]\tLoss: 0.045975\t F1:0.813%\n",
            "Epoch : 4 [43200/1395 (32%)]\tLoss: 0.040128\t F1:0.812%\n",
            "Epoch : 4 [48000/1395 (36%)]\tLoss: 0.023588\t F1:0.814%\n",
            "Epoch : 4 [52800/1395 (39%)]\tLoss: 0.033008\t F1:0.815%\n",
            "Epoch : 4 [57600/1395 (43%)]\tLoss: 0.022018\t F1:0.815%\n",
            "Epoch : 4 [62400/1395 (47%)]\tLoss: 0.044766\t F1:0.815%\n",
            "Epoch : 4 [67200/1395 (50%)]\tLoss: 0.028617\t F1:0.814%\n",
            "Epoch : 4 [72000/1395 (54%)]\tLoss: 0.028292\t F1:0.815%\n",
            "Epoch : 4 [76800/1395 (57%)]\tLoss: 0.059258\t F1:0.815%\n",
            "Epoch : 4 [81600/1395 (61%)]\tLoss: 0.037326\t F1:0.814%\n",
            "Epoch : 4 [86400/1395 (65%)]\tLoss: 0.043495\t F1:0.813%\n",
            "Epoch : 4 [91200/1395 (68%)]\tLoss: 0.031294\t F1:0.813%\n",
            "Epoch : 4 [96000/1395 (72%)]\tLoss: 0.048071\t F1:0.813%\n",
            "Epoch : 4 [100800/1395 (75%)]\tLoss: 0.023923\t F1:0.812%\n",
            "Epoch : 4 [105600/1395 (79%)]\tLoss: 0.038254\t F1:0.812%\n",
            "Epoch : 4 [110400/1395 (82%)]\tLoss: 0.048675\t F1:0.812%\n",
            "Epoch : 4 [115200/1395 (86%)]\tLoss: 0.031604\t F1:0.811%\n",
            "Epoch : 4 [120000/1395 (90%)]\tLoss: 0.046275\t F1:0.810%\n",
            "Epoch : 4 [124800/1395 (93%)]\tLoss: 0.039877\t F1:0.810%\n",
            "Epoch : 4 [129600/1395 (97%)]\tLoss: 0.038934\t F1:0.810%\n",
            "Validation F1 Score: 0.7389173060528559\n",
            "Epoch : 5 [0/1395 (0%)]\tLoss: 0.029455\t F1:0.826%\n",
            "Epoch : 5 [4800/1395 (4%)]\tLoss: 0.036317\t F1:0.828%\n",
            "Epoch : 5 [9600/1395 (7%)]\tLoss: 0.027725\t F1:0.826%\n",
            "Epoch : 5 [14400/1395 (11%)]\tLoss: 0.023595\t F1:0.822%\n",
            "Epoch : 5 [19200/1395 (14%)]\tLoss: 0.029470\t F1:0.828%\n",
            "Epoch : 5 [24000/1395 (18%)]\tLoss: 0.028141\t F1:0.830%\n",
            "Epoch : 5 [28800/1395 (22%)]\tLoss: 0.032011\t F1:0.830%\n",
            "Epoch : 5 [33600/1395 (25%)]\tLoss: 0.038451\t F1:0.829%\n",
            "Epoch : 5 [38400/1395 (29%)]\tLoss: 0.037478\t F1:0.827%\n",
            "Epoch : 5 [43200/1395 (32%)]\tLoss: 0.041463\t F1:0.826%\n",
            "Epoch : 5 [48000/1395 (36%)]\tLoss: 0.025169\t F1:0.827%\n",
            "Epoch : 5 [52800/1395 (39%)]\tLoss: 0.028533\t F1:0.828%\n",
            "Epoch : 5 [57600/1395 (43%)]\tLoss: 0.027987\t F1:0.827%\n",
            "Epoch : 5 [62400/1395 (47%)]\tLoss: 0.051992\t F1:0.827%\n",
            "Epoch : 5 [67200/1395 (50%)]\tLoss: 0.026398\t F1:0.826%\n",
            "Epoch : 5 [72000/1395 (54%)]\tLoss: 0.020470\t F1:0.826%\n",
            "Epoch : 5 [76800/1395 (57%)]\tLoss: 0.050265\t F1:0.827%\n",
            "Epoch : 5 [81600/1395 (61%)]\tLoss: 0.027712\t F1:0.825%\n",
            "Epoch : 5 [86400/1395 (65%)]\tLoss: 0.042161\t F1:0.825%\n",
            "Epoch : 5 [91200/1395 (68%)]\tLoss: 0.032190\t F1:0.826%\n",
            "Epoch : 5 [96000/1395 (72%)]\tLoss: 0.044427\t F1:0.825%\n",
            "Epoch : 5 [100800/1395 (75%)]\tLoss: 0.020428\t F1:0.824%\n",
            "Epoch : 5 [105600/1395 (79%)]\tLoss: 0.035692\t F1:0.824%\n",
            "Epoch : 5 [110400/1395 (82%)]\tLoss: 0.044892\t F1:0.824%\n",
            "Epoch : 5 [115200/1395 (86%)]\tLoss: 0.032806\t F1:0.823%\n",
            "Epoch : 5 [120000/1395 (90%)]\tLoss: 0.042565\t F1:0.823%\n",
            "Epoch : 5 [124800/1395 (93%)]\tLoss: 0.036475\t F1:0.823%\n",
            "Epoch : 5 [129600/1395 (97%)]\tLoss: 0.039504\t F1:0.824%\n",
            "Validation F1 Score: 0.7518091140230785\n",
            "Epoch : 6 [0/1395 (0%)]\tLoss: 0.033216\t F1:0.826%\n",
            "Epoch : 6 [4800/1395 (4%)]\tLoss: 0.039774\t F1:0.841%\n",
            "Epoch : 6 [9600/1395 (7%)]\tLoss: 0.026249\t F1:0.838%\n",
            "Epoch : 6 [14400/1395 (11%)]\tLoss: 0.022905\t F1:0.835%\n",
            "Epoch : 6 [19200/1395 (14%)]\tLoss: 0.024018\t F1:0.837%\n",
            "Epoch : 6 [24000/1395 (18%)]\tLoss: 0.028833\t F1:0.840%\n",
            "Epoch : 6 [28800/1395 (22%)]\tLoss: 0.023112\t F1:0.837%\n",
            "Epoch : 6 [33600/1395 (25%)]\tLoss: 0.023683\t F1:0.837%\n",
            "Epoch : 6 [38400/1395 (29%)]\tLoss: 0.031200\t F1:0.835%\n",
            "Epoch : 6 [43200/1395 (32%)]\tLoss: 0.039738\t F1:0.834%\n",
            "Epoch : 6 [48000/1395 (36%)]\tLoss: 0.022310\t F1:0.836%\n",
            "Epoch : 6 [52800/1395 (39%)]\tLoss: 0.022748\t F1:0.837%\n",
            "Epoch : 6 [57600/1395 (43%)]\tLoss: 0.028370\t F1:0.838%\n",
            "Epoch : 6 [62400/1395 (47%)]\tLoss: 0.038129\t F1:0.838%\n",
            "Epoch : 6 [67200/1395 (50%)]\tLoss: 0.023967\t F1:0.837%\n",
            "Epoch : 6 [72000/1395 (54%)]\tLoss: 0.023940\t F1:0.837%\n",
            "Epoch : 6 [76800/1395 (57%)]\tLoss: 0.051971\t F1:0.837%\n",
            "Epoch : 6 [81600/1395 (61%)]\tLoss: 0.030937\t F1:0.836%\n",
            "Epoch : 6 [86400/1395 (65%)]\tLoss: 0.031528\t F1:0.836%\n",
            "Epoch : 6 [91200/1395 (68%)]\tLoss: 0.029627\t F1:0.836%\n",
            "Epoch : 6 [96000/1395 (72%)]\tLoss: 0.035810\t F1:0.835%\n",
            "Epoch : 6 [100800/1395 (75%)]\tLoss: 0.027955\t F1:0.835%\n",
            "Epoch : 6 [105600/1395 (79%)]\tLoss: 0.031912\t F1:0.834%\n",
            "Epoch : 6 [110400/1395 (82%)]\tLoss: 0.037834\t F1:0.834%\n",
            "Epoch : 6 [115200/1395 (86%)]\tLoss: 0.029973\t F1:0.834%\n",
            "Epoch : 6 [120000/1395 (90%)]\tLoss: 0.044095\t F1:0.833%\n",
            "Epoch : 6 [124800/1395 (93%)]\tLoss: 0.032725\t F1:0.834%\n",
            "Epoch : 6 [129600/1395 (97%)]\tLoss: 0.040648\t F1:0.834%\n",
            "Validation F1 Score: 0.7464862051015096\n",
            "Epoch : 7 [0/1395 (0%)]\tLoss: 0.034957\t F1:0.773%\n",
            "Epoch : 7 [4800/1395 (4%)]\tLoss: 0.033407\t F1:0.849%\n",
            "Epoch : 7 [9600/1395 (7%)]\tLoss: 0.026367\t F1:0.849%\n",
            "Epoch : 7 [14400/1395 (11%)]\tLoss: 0.032921\t F1:0.847%\n",
            "Epoch : 7 [19200/1395 (14%)]\tLoss: 0.024181\t F1:0.850%\n",
            "Epoch : 7 [24000/1395 (18%)]\tLoss: 0.031652\t F1:0.850%\n",
            "Epoch : 7 [28800/1395 (22%)]\tLoss: 0.020691\t F1:0.850%\n",
            "Epoch : 7 [33600/1395 (25%)]\tLoss: 0.028089\t F1:0.849%\n",
            "Epoch : 7 [38400/1395 (29%)]\tLoss: 0.027741\t F1:0.847%\n",
            "Epoch : 7 [43200/1395 (32%)]\tLoss: 0.032312\t F1:0.846%\n",
            "Epoch : 7 [48000/1395 (36%)]\tLoss: 0.022984\t F1:0.847%\n",
            "Epoch : 7 [52800/1395 (39%)]\tLoss: 0.029599\t F1:0.847%\n",
            "Epoch : 7 [57600/1395 (43%)]\tLoss: 0.022103\t F1:0.847%\n",
            "Epoch : 7 [62400/1395 (47%)]\tLoss: 0.050949\t F1:0.847%\n",
            "Epoch : 7 [67200/1395 (50%)]\tLoss: 0.027675\t F1:0.846%\n",
            "Epoch : 7 [72000/1395 (54%)]\tLoss: 0.024102\t F1:0.846%\n",
            "Epoch : 7 [76800/1395 (57%)]\tLoss: 0.048201\t F1:0.846%\n",
            "Epoch : 7 [81600/1395 (61%)]\tLoss: 0.030401\t F1:0.844%\n",
            "Epoch : 7 [86400/1395 (65%)]\tLoss: 0.038732\t F1:0.844%\n",
            "Epoch : 7 [91200/1395 (68%)]\tLoss: 0.032584\t F1:0.844%\n",
            "Epoch : 7 [96000/1395 (72%)]\tLoss: 0.031501\t F1:0.843%\n",
            "Epoch : 7 [100800/1395 (75%)]\tLoss: 0.023443\t F1:0.843%\n",
            "Epoch : 7 [105600/1395 (79%)]\tLoss: 0.024022\t F1:0.842%\n",
            "Epoch : 7 [110400/1395 (82%)]\tLoss: 0.035679\t F1:0.843%\n",
            "Epoch : 7 [115200/1395 (86%)]\tLoss: 0.021705\t F1:0.842%\n",
            "Epoch : 7 [120000/1395 (90%)]\tLoss: 0.037521\t F1:0.841%\n",
            "Epoch : 7 [124800/1395 (93%)]\tLoss: 0.031030\t F1:0.841%\n",
            "Epoch : 7 [129600/1395 (97%)]\tLoss: 0.042523\t F1:0.842%\n",
            "Validation F1 Score: 0.7358167415970883\n",
            "Epoch : 8 [0/1395 (0%)]\tLoss: 0.025411\t F1:0.864%\n",
            "Epoch : 8 [4800/1395 (4%)]\tLoss: 0.027482\t F1:0.859%\n",
            "Epoch : 8 [9600/1395 (7%)]\tLoss: 0.023219\t F1:0.857%\n",
            "Epoch : 8 [14400/1395 (11%)]\tLoss: 0.022945\t F1:0.851%\n",
            "Epoch : 8 [19200/1395 (14%)]\tLoss: 0.029779\t F1:0.851%\n",
            "Epoch : 8 [24000/1395 (18%)]\tLoss: 0.021310\t F1:0.850%\n",
            "Epoch : 8 [28800/1395 (22%)]\tLoss: 0.021500\t F1:0.850%\n",
            "Epoch : 8 [33600/1395 (25%)]\tLoss: 0.032853\t F1:0.850%\n",
            "Epoch : 8 [38400/1395 (29%)]\tLoss: 0.035343\t F1:0.849%\n",
            "Epoch : 8 [43200/1395 (32%)]\tLoss: 0.022517\t F1:0.850%\n",
            "Epoch : 8 [48000/1395 (36%)]\tLoss: 0.022398\t F1:0.851%\n",
            "Epoch : 8 [52800/1395 (39%)]\tLoss: 0.033019\t F1:0.851%\n",
            "Epoch : 8 [57600/1395 (43%)]\tLoss: 0.026087\t F1:0.852%\n",
            "Epoch : 8 [62400/1395 (47%)]\tLoss: 0.037125\t F1:0.852%\n",
            "Epoch : 8 [67200/1395 (50%)]\tLoss: 0.024054\t F1:0.851%\n",
            "Epoch : 8 [72000/1395 (54%)]\tLoss: 0.029307\t F1:0.852%\n",
            "Epoch : 8 [76800/1395 (57%)]\tLoss: 0.044092\t F1:0.852%\n",
            "Epoch : 8 [81600/1395 (61%)]\tLoss: 0.018137\t F1:0.850%\n",
            "Epoch : 8 [86400/1395 (65%)]\tLoss: 0.030265\t F1:0.850%\n",
            "Epoch : 8 [91200/1395 (68%)]\tLoss: 0.024514\t F1:0.851%\n",
            "Epoch : 8 [96000/1395 (72%)]\tLoss: 0.030584\t F1:0.850%\n",
            "Epoch : 8 [100800/1395 (75%)]\tLoss: 0.018866\t F1:0.849%\n",
            "Epoch : 8 [105600/1395 (79%)]\tLoss: 0.020185\t F1:0.849%\n",
            "Epoch : 8 [110400/1395 (82%)]\tLoss: 0.037944\t F1:0.849%\n",
            "Epoch : 8 [115200/1395 (86%)]\tLoss: 0.020098\t F1:0.848%\n",
            "Epoch : 8 [120000/1395 (90%)]\tLoss: 0.036859\t F1:0.847%\n",
            "Epoch : 8 [124800/1395 (93%)]\tLoss: 0.029193\t F1:0.847%\n",
            "Epoch : 8 [129600/1395 (97%)]\tLoss: 0.051599\t F1:0.847%\n",
            "Validation F1 Score: 0.7290406222990492\n",
            "Epoch : 9 [0/1395 (0%)]\tLoss: 0.027247\t F1:0.844%\n",
            "Epoch : 9 [4800/1395 (4%)]\tLoss: 0.048684\t F1:0.857%\n",
            "Epoch : 9 [9600/1395 (7%)]\tLoss: 0.018578\t F1:0.859%\n",
            "Epoch : 9 [14400/1395 (11%)]\tLoss: 0.020056\t F1:0.856%\n",
            "Epoch : 9 [19200/1395 (14%)]\tLoss: 0.021607\t F1:0.859%\n",
            "Epoch : 9 [24000/1395 (18%)]\tLoss: 0.025065\t F1:0.861%\n",
            "Epoch : 9 [28800/1395 (22%)]\tLoss: 0.017879\t F1:0.858%\n",
            "Epoch : 9 [33600/1395 (25%)]\tLoss: 0.022422\t F1:0.860%\n",
            "Epoch : 9 [38400/1395 (29%)]\tLoss: 0.031650\t F1:0.859%\n",
            "Epoch : 9 [43200/1395 (32%)]\tLoss: 0.021530\t F1:0.859%\n",
            "Epoch : 9 [48000/1395 (36%)]\tLoss: 0.016858\t F1:0.859%\n",
            "Epoch : 9 [52800/1395 (39%)]\tLoss: 0.025676\t F1:0.858%\n",
            "Epoch : 9 [57600/1395 (43%)]\tLoss: 0.022885\t F1:0.859%\n",
            "Epoch : 9 [62400/1395 (47%)]\tLoss: 0.024000\t F1:0.859%\n",
            "Epoch : 9 [67200/1395 (50%)]\tLoss: 0.025927\t F1:0.858%\n",
            "Epoch : 9 [72000/1395 (54%)]\tLoss: 0.027141\t F1:0.858%\n",
            "Epoch : 9 [76800/1395 (57%)]\tLoss: 0.024599\t F1:0.859%\n",
            "Epoch : 9 [81600/1395 (61%)]\tLoss: 0.042115\t F1:0.858%\n",
            "Epoch : 9 [86400/1395 (65%)]\tLoss: 0.029580\t F1:0.858%\n",
            "Epoch : 9 [91200/1395 (68%)]\tLoss: 0.024432\t F1:0.858%\n",
            "Epoch : 9 [96000/1395 (72%)]\tLoss: 0.029340\t F1:0.857%\n",
            "Epoch : 9 [100800/1395 (75%)]\tLoss: 0.021023\t F1:0.857%\n",
            "Epoch : 9 [105600/1395 (79%)]\tLoss: 0.020298\t F1:0.857%\n",
            "Epoch : 9 [110400/1395 (82%)]\tLoss: 0.034366\t F1:0.857%\n",
            "Epoch : 9 [115200/1395 (86%)]\tLoss: 0.026522\t F1:0.856%\n",
            "Epoch : 9 [120000/1395 (90%)]\tLoss: 0.041297\t F1:0.856%\n",
            "Epoch : 9 [124800/1395 (93%)]\tLoss: 0.025022\t F1:0.855%\n",
            "Epoch : 9 [129600/1395 (97%)]\tLoss: 0.043109\t F1:0.855%\n",
            "Validation F1 Score: 0.7308626333016577\n",
            "Epoch : 10 [0/1395 (0%)]\tLoss: 0.032276\t F1:0.844%\n",
            "Epoch : 10 [4800/1395 (4%)]\tLoss: 0.032510\t F1:0.867%\n",
            "Epoch : 10 [9600/1395 (7%)]\tLoss: 0.018948\t F1:0.867%\n",
            "Epoch : 10 [14400/1395 (11%)]\tLoss: 0.023063\t F1:0.865%\n",
            "Epoch : 10 [19200/1395 (14%)]\tLoss: 0.024844\t F1:0.866%\n",
            "Epoch : 10 [24000/1395 (18%)]\tLoss: 0.030426\t F1:0.864%\n",
            "Epoch : 10 [28800/1395 (22%)]\tLoss: 0.023882\t F1:0.864%\n",
            "Epoch : 10 [33600/1395 (25%)]\tLoss: 0.027829\t F1:0.864%\n",
            "Epoch : 10 [38400/1395 (29%)]\tLoss: 0.024174\t F1:0.863%\n",
            "Epoch : 10 [43200/1395 (32%)]\tLoss: 0.019029\t F1:0.862%\n",
            "Epoch : 10 [48000/1395 (36%)]\tLoss: 0.022200\t F1:0.862%\n",
            "Epoch : 10 [52800/1395 (39%)]\tLoss: 0.020074\t F1:0.863%\n",
            "Epoch : 10 [57600/1395 (43%)]\tLoss: 0.018800\t F1:0.863%\n",
            "Epoch : 10 [62400/1395 (47%)]\tLoss: 0.038538\t F1:0.864%\n",
            "Epoch : 10 [67200/1395 (50%)]\tLoss: 0.020893\t F1:0.863%\n",
            "Epoch : 10 [72000/1395 (54%)]\tLoss: 0.022606\t F1:0.864%\n",
            "Epoch : 10 [76800/1395 (57%)]\tLoss: 0.024606\t F1:0.864%\n",
            "Epoch : 10 [81600/1395 (61%)]\tLoss: 0.020146\t F1:0.864%\n",
            "Epoch : 10 [86400/1395 (65%)]\tLoss: 0.038355\t F1:0.864%\n",
            "Epoch : 10 [91200/1395 (68%)]\tLoss: 0.035717\t F1:0.864%\n",
            "Epoch : 10 [96000/1395 (72%)]\tLoss: 0.031102\t F1:0.863%\n",
            "Epoch : 10 [100800/1395 (75%)]\tLoss: 0.016623\t F1:0.862%\n",
            "Epoch : 10 [105600/1395 (79%)]\tLoss: 0.027340\t F1:0.862%\n",
            "Epoch : 10 [110400/1395 (82%)]\tLoss: 0.034387\t F1:0.862%\n",
            "Epoch : 10 [115200/1395 (86%)]\tLoss: 0.021905\t F1:0.861%\n",
            "Epoch : 10 [120000/1395 (90%)]\tLoss: 0.024753\t F1:0.861%\n",
            "Epoch : 10 [124800/1395 (93%)]\tLoss: 0.025137\t F1:0.861%\n",
            "Epoch : 10 [129600/1395 (97%)]\tLoss: 0.027990\t F1:0.861%\n",
            "Validation F1 Score: 0.7332569524007917\n",
            "Epoch : 11 [0/1395 (0%)]\tLoss: 0.020302\t F1:0.894%\n",
            "Epoch : 11 [4800/1395 (4%)]\tLoss: 0.031335\t F1:0.879%\n",
            "Epoch : 11 [9600/1395 (7%)]\tLoss: 0.018914\t F1:0.875%\n",
            "Epoch : 11 [14400/1395 (11%)]\tLoss: 0.020278\t F1:0.874%\n",
            "Epoch : 11 [19200/1395 (14%)]\tLoss: 0.023272\t F1:0.876%\n",
            "Epoch : 11 [24000/1395 (18%)]\tLoss: 0.036995\t F1:0.872%\n",
            "Epoch : 11 [28800/1395 (22%)]\tLoss: 0.015853\t F1:0.871%\n",
            "Epoch : 11 [33600/1395 (25%)]\tLoss: 0.020849\t F1:0.870%\n",
            "Epoch : 11 [38400/1395 (29%)]\tLoss: 0.028761\t F1:0.870%\n",
            "Epoch : 11 [43200/1395 (32%)]\tLoss: 0.026780\t F1:0.871%\n",
            "Epoch : 11 [48000/1395 (36%)]\tLoss: 0.012990\t F1:0.871%\n",
            "Epoch : 11 [52800/1395 (39%)]\tLoss: 0.026273\t F1:0.871%\n",
            "Epoch : 11 [57600/1395 (43%)]\tLoss: 0.020313\t F1:0.873%\n",
            "Epoch : 11 [62400/1395 (47%)]\tLoss: 0.020211\t F1:0.873%\n",
            "Epoch : 11 [67200/1395 (50%)]\tLoss: 0.022339\t F1:0.872%\n",
            "Epoch : 11 [72000/1395 (54%)]\tLoss: 0.024431\t F1:0.871%\n",
            "Epoch : 11 [76800/1395 (57%)]\tLoss: 0.032811\t F1:0.871%\n",
            "Epoch : 11 [81600/1395 (61%)]\tLoss: 0.021819\t F1:0.870%\n",
            "Epoch : 11 [86400/1395 (65%)]\tLoss: 0.036810\t F1:0.870%\n",
            "Epoch : 11 [91200/1395 (68%)]\tLoss: 0.026257\t F1:0.871%\n",
            "Epoch : 11 [96000/1395 (72%)]\tLoss: 0.025908\t F1:0.870%\n",
            "Epoch : 11 [100800/1395 (75%)]\tLoss: 0.022294\t F1:0.871%\n",
            "Epoch : 11 [105600/1395 (79%)]\tLoss: 0.020835\t F1:0.870%\n",
            "Epoch : 11 [110400/1395 (82%)]\tLoss: 0.035359\t F1:0.870%\n",
            "Epoch : 11 [115200/1395 (86%)]\tLoss: 0.018662\t F1:0.869%\n",
            "Epoch : 11 [120000/1395 (90%)]\tLoss: 0.023217\t F1:0.869%\n",
            "Epoch : 11 [124800/1395 (93%)]\tLoss: 0.038146\t F1:0.869%\n",
            "Epoch : 11 [129600/1395 (97%)]\tLoss: 0.023832\t F1:0.869%\n",
            "Validation F1 Score: 0.7425959053866031\n",
            "Epoch : 12 [0/1395 (0%)]\tLoss: 0.020906\t F1:0.913%\n",
            "Epoch : 12 [4800/1395 (4%)]\tLoss: 0.030290\t F1:0.873%\n",
            "Epoch : 12 [9600/1395 (7%)]\tLoss: 0.017002\t F1:0.875%\n",
            "Epoch : 12 [14400/1395 (11%)]\tLoss: 0.021799\t F1:0.875%\n",
            "Epoch : 12 [19200/1395 (14%)]\tLoss: 0.020496\t F1:0.875%\n",
            "Epoch : 12 [24000/1395 (18%)]\tLoss: 0.026486\t F1:0.875%\n",
            "Epoch : 12 [28800/1395 (22%)]\tLoss: 0.011496\t F1:0.875%\n",
            "Epoch : 12 [33600/1395 (25%)]\tLoss: 0.026134\t F1:0.874%\n",
            "Epoch : 12 [38400/1395 (29%)]\tLoss: 0.020797\t F1:0.874%\n",
            "Epoch : 12 [43200/1395 (32%)]\tLoss: 0.018391\t F1:0.874%\n",
            "Epoch : 12 [48000/1395 (36%)]\tLoss: 0.022584\t F1:0.875%\n",
            "Epoch : 12 [52800/1395 (39%)]\tLoss: 0.022658\t F1:0.875%\n",
            "Epoch : 12 [57600/1395 (43%)]\tLoss: 0.020541\t F1:0.875%\n",
            "Epoch : 12 [62400/1395 (47%)]\tLoss: 0.018151\t F1:0.875%\n",
            "Epoch : 12 [67200/1395 (50%)]\tLoss: 0.022697\t F1:0.874%\n",
            "Epoch : 12 [72000/1395 (54%)]\tLoss: 0.019520\t F1:0.874%\n",
            "Epoch : 12 [76800/1395 (57%)]\tLoss: 0.036507\t F1:0.874%\n",
            "Epoch : 12 [81600/1395 (61%)]\tLoss: 0.028175\t F1:0.873%\n",
            "Epoch : 12 [86400/1395 (65%)]\tLoss: 0.018857\t F1:0.873%\n",
            "Epoch : 12 [91200/1395 (68%)]\tLoss: 0.027172\t F1:0.873%\n",
            "Epoch : 12 [96000/1395 (72%)]\tLoss: 0.035674\t F1:0.872%\n",
            "Epoch : 12 [100800/1395 (75%)]\tLoss: 0.021387\t F1:0.872%\n",
            "Epoch : 12 [105600/1395 (79%)]\tLoss: 0.024367\t F1:0.872%\n",
            "Epoch : 12 [110400/1395 (82%)]\tLoss: 0.026144\t F1:0.872%\n",
            "Epoch : 12 [115200/1395 (86%)]\tLoss: 0.015759\t F1:0.871%\n",
            "Epoch : 12 [120000/1395 (90%)]\tLoss: 0.026419\t F1:0.870%\n",
            "Epoch : 12 [124800/1395 (93%)]\tLoss: 0.027108\t F1:0.870%\n",
            "Epoch : 12 [129600/1395 (97%)]\tLoss: 0.030623\t F1:0.870%\n",
            "Validation F1 Score: 0.7432497822510403\n",
            "Epoch : 13 [0/1395 (0%)]\tLoss: 0.025931\t F1:0.875%\n",
            "Epoch : 13 [4800/1395 (4%)]\tLoss: 0.024975\t F1:0.885%\n",
            "Epoch : 13 [9600/1395 (7%)]\tLoss: 0.023702\t F1:0.880%\n",
            "Epoch : 13 [14400/1395 (11%)]\tLoss: 0.017538\t F1:0.880%\n",
            "Epoch : 13 [19200/1395 (14%)]\tLoss: 0.016858\t F1:0.880%\n",
            "Epoch : 13 [24000/1395 (18%)]\tLoss: 0.023989\t F1:0.881%\n",
            "Epoch : 13 [28800/1395 (22%)]\tLoss: 0.012616\t F1:0.879%\n",
            "Epoch : 13 [33600/1395 (25%)]\tLoss: 0.015457\t F1:0.879%\n",
            "Epoch : 13 [38400/1395 (29%)]\tLoss: 0.022336\t F1:0.878%\n",
            "Epoch : 13 [43200/1395 (32%)]\tLoss: 0.035341\t F1:0.879%\n",
            "Epoch : 13 [48000/1395 (36%)]\tLoss: 0.019747\t F1:0.880%\n",
            "Epoch : 13 [52800/1395 (39%)]\tLoss: 0.023000\t F1:0.879%\n",
            "Epoch : 13 [57600/1395 (43%)]\tLoss: 0.019470\t F1:0.880%\n",
            "Epoch : 13 [62400/1395 (47%)]\tLoss: 0.034889\t F1:0.879%\n",
            "Epoch : 13 [67200/1395 (50%)]\tLoss: 0.021269\t F1:0.878%\n",
            "Epoch : 13 [72000/1395 (54%)]\tLoss: 0.017346\t F1:0.877%\n",
            "Epoch : 13 [76800/1395 (57%)]\tLoss: 0.025894\t F1:0.877%\n",
            "Epoch : 13 [81600/1395 (61%)]\tLoss: 0.023969\t F1:0.876%\n",
            "Epoch : 13 [86400/1395 (65%)]\tLoss: 0.030870\t F1:0.876%\n",
            "Epoch : 13 [91200/1395 (68%)]\tLoss: 0.019727\t F1:0.876%\n",
            "Epoch : 13 [96000/1395 (72%)]\tLoss: 0.025676\t F1:0.875%\n",
            "Epoch : 13 [100800/1395 (75%)]\tLoss: 0.014441\t F1:0.874%\n",
            "Epoch : 13 [105600/1395 (79%)]\tLoss: 0.021031\t F1:0.874%\n",
            "Epoch : 13 [110400/1395 (82%)]\tLoss: 0.030766\t F1:0.874%\n",
            "Epoch : 13 [115200/1395 (86%)]\tLoss: 0.016035\t F1:0.873%\n",
            "Epoch : 13 [120000/1395 (90%)]\tLoss: 0.022133\t F1:0.873%\n",
            "Epoch : 13 [124800/1395 (93%)]\tLoss: 0.026421\t F1:0.873%\n",
            "Epoch : 13 [129600/1395 (97%)]\tLoss: 0.023112\t F1:0.873%\n",
            "Validation F1 Score: 0.7397833803586057\n",
            "Epoch : 14 [0/1395 (0%)]\tLoss: 0.024221\t F1:0.846%\n",
            "Epoch : 14 [4800/1395 (4%)]\tLoss: 0.026198\t F1:0.879%\n",
            "Epoch : 14 [9600/1395 (7%)]\tLoss: 0.019359\t F1:0.886%\n",
            "Epoch : 14 [14400/1395 (11%)]\tLoss: 0.012621\t F1:0.884%\n",
            "Epoch : 14 [19200/1395 (14%)]\tLoss: 0.022489\t F1:0.884%\n",
            "Epoch : 14 [24000/1395 (18%)]\tLoss: 0.030346\t F1:0.882%\n",
            "Epoch : 14 [28800/1395 (22%)]\tLoss: 0.016553\t F1:0.880%\n",
            "Epoch : 14 [33600/1395 (25%)]\tLoss: 0.030292\t F1:0.880%\n",
            "Epoch : 14 [38400/1395 (29%)]\tLoss: 0.019457\t F1:0.879%\n",
            "Epoch : 14 [43200/1395 (32%)]\tLoss: 0.016853\t F1:0.880%\n",
            "Epoch : 14 [48000/1395 (36%)]\tLoss: 0.017781\t F1:0.881%\n",
            "Epoch : 14 [52800/1395 (39%)]\tLoss: 0.024170\t F1:0.881%\n",
            "Epoch : 14 [57600/1395 (43%)]\tLoss: 0.009493\t F1:0.881%\n",
            "Epoch : 14 [62400/1395 (47%)]\tLoss: 0.019357\t F1:0.882%\n",
            "Epoch : 14 [67200/1395 (50%)]\tLoss: 0.027243\t F1:0.881%\n",
            "Epoch : 14 [72000/1395 (54%)]\tLoss: 0.021270\t F1:0.881%\n",
            "Epoch : 14 [76800/1395 (57%)]\tLoss: 0.035723\t F1:0.880%\n",
            "Epoch : 14 [81600/1395 (61%)]\tLoss: 0.024236\t F1:0.880%\n",
            "Epoch : 14 [86400/1395 (65%)]\tLoss: 0.037648\t F1:0.879%\n",
            "Epoch : 14 [91200/1395 (68%)]\tLoss: 0.021732\t F1:0.879%\n",
            "Epoch : 14 [96000/1395 (72%)]\tLoss: 0.027689\t F1:0.878%\n",
            "Epoch : 14 [100800/1395 (75%)]\tLoss: 0.029884\t F1:0.877%\n",
            "Epoch : 14 [105600/1395 (79%)]\tLoss: 0.018477\t F1:0.877%\n",
            "Epoch : 14 [110400/1395 (82%)]\tLoss: 0.035452\t F1:0.877%\n",
            "Epoch : 14 [115200/1395 (86%)]\tLoss: 0.017291\t F1:0.876%\n",
            "Epoch : 14 [120000/1395 (90%)]\tLoss: 0.025730\t F1:0.875%\n",
            "Epoch : 14 [124800/1395 (93%)]\tLoss: 0.024340\t F1:0.875%\n",
            "Epoch : 14 [129600/1395 (97%)]\tLoss: 0.031524\t F1:0.875%\n",
            "Validation F1 Score: 0.7286275299567013\n",
            "Epoch : 15 [0/1395 (0%)]\tLoss: 0.026263\t F1:0.898%\n",
            "Epoch : 15 [4800/1395 (4%)]\tLoss: 0.036357\t F1:0.883%\n",
            "Epoch : 15 [9600/1395 (7%)]\tLoss: 0.010645\t F1:0.889%\n",
            "Epoch : 15 [14400/1395 (11%)]\tLoss: 0.013849\t F1:0.888%\n",
            "Epoch : 15 [19200/1395 (14%)]\tLoss: 0.014687\t F1:0.890%\n",
            "Epoch : 15 [24000/1395 (18%)]\tLoss: 0.024264\t F1:0.890%\n",
            "Epoch : 15 [28800/1395 (22%)]\tLoss: 0.012474\t F1:0.889%\n",
            "Epoch : 15 [33600/1395 (25%)]\tLoss: 0.027878\t F1:0.887%\n",
            "Epoch : 15 [38400/1395 (29%)]\tLoss: 0.021972\t F1:0.887%\n",
            "Epoch : 15 [43200/1395 (32%)]\tLoss: 0.015630\t F1:0.887%\n",
            "Epoch : 15 [48000/1395 (36%)]\tLoss: 0.022981\t F1:0.887%\n",
            "Epoch : 15 [52800/1395 (39%)]\tLoss: 0.027354\t F1:0.887%\n",
            "Epoch : 15 [57600/1395 (43%)]\tLoss: 0.012785\t F1:0.886%\n",
            "Epoch : 15 [62400/1395 (47%)]\tLoss: 0.032596\t F1:0.886%\n",
            "Epoch : 15 [67200/1395 (50%)]\tLoss: 0.031563\t F1:0.886%\n",
            "Epoch : 15 [72000/1395 (54%)]\tLoss: 0.027069\t F1:0.885%\n",
            "Epoch : 15 [76800/1395 (57%)]\tLoss: 0.020944\t F1:0.884%\n",
            "Epoch : 15 [81600/1395 (61%)]\tLoss: 0.033460\t F1:0.884%\n",
            "Epoch : 15 [86400/1395 (65%)]\tLoss: 0.017299\t F1:0.884%\n",
            "Epoch : 15 [91200/1395 (68%)]\tLoss: 0.024777\t F1:0.884%\n",
            "Epoch : 15 [96000/1395 (72%)]\tLoss: 0.023096\t F1:0.884%\n",
            "Epoch : 15 [100800/1395 (75%)]\tLoss: 0.015773\t F1:0.883%\n",
            "Epoch : 15 [105600/1395 (79%)]\tLoss: 0.015556\t F1:0.883%\n",
            "Epoch : 15 [110400/1395 (82%)]\tLoss: 0.046226\t F1:0.883%\n",
            "Epoch : 15 [115200/1395 (86%)]\tLoss: 0.027226\t F1:0.883%\n",
            "Epoch : 15 [120000/1395 (90%)]\tLoss: 0.024294\t F1:0.882%\n",
            "Epoch : 15 [124800/1395 (93%)]\tLoss: 0.035644\t F1:0.882%\n",
            "Epoch : 15 [129600/1395 (97%)]\tLoss: 0.025273\t F1:0.882%\n",
            "Validation F1 Score: 0.7353144436765723\n",
            "Epoch : 16 [0/1395 (0%)]\tLoss: 0.022481\t F1:0.889%\n",
            "Epoch : 16 [4800/1395 (4%)]\tLoss: 0.025752\t F1:0.893%\n",
            "Epoch : 16 [9600/1395 (7%)]\tLoss: 0.013699\t F1:0.889%\n",
            "Epoch : 16 [14400/1395 (11%)]\tLoss: 0.016165\t F1:0.887%\n",
            "Epoch : 16 [19200/1395 (14%)]\tLoss: 0.018689\t F1:0.890%\n",
            "Epoch : 16 [24000/1395 (18%)]\tLoss: 0.016308\t F1:0.889%\n",
            "Epoch : 16 [28800/1395 (22%)]\tLoss: 0.007606\t F1:0.889%\n",
            "Epoch : 16 [33600/1395 (25%)]\tLoss: 0.017562\t F1:0.889%\n",
            "Epoch : 16 [38400/1395 (29%)]\tLoss: 0.018051\t F1:0.889%\n",
            "Epoch : 16 [43200/1395 (32%)]\tLoss: 0.015990\t F1:0.889%\n",
            "Epoch : 16 [48000/1395 (36%)]\tLoss: 0.017781\t F1:0.890%\n",
            "Epoch : 16 [52800/1395 (39%)]\tLoss: 0.020180\t F1:0.889%\n",
            "Epoch : 16 [57600/1395 (43%)]\tLoss: 0.027413\t F1:0.889%\n",
            "Epoch : 16 [62400/1395 (47%)]\tLoss: 0.026812\t F1:0.889%\n",
            "Epoch : 16 [67200/1395 (50%)]\tLoss: 0.026732\t F1:0.889%\n",
            "Epoch : 16 [72000/1395 (54%)]\tLoss: 0.017996\t F1:0.889%\n",
            "Epoch : 16 [76800/1395 (57%)]\tLoss: 0.026275\t F1:0.889%\n",
            "Epoch : 16 [81600/1395 (61%)]\tLoss: 0.020828\t F1:0.888%\n",
            "Epoch : 16 [86400/1395 (65%)]\tLoss: 0.030603\t F1:0.888%\n",
            "Epoch : 16 [91200/1395 (68%)]\tLoss: 0.013628\t F1:0.889%\n",
            "Epoch : 16 [96000/1395 (72%)]\tLoss: 0.024311\t F1:0.888%\n",
            "Epoch : 16 [100800/1395 (75%)]\tLoss: 0.016326\t F1:0.887%\n",
            "Epoch : 16 [105600/1395 (79%)]\tLoss: 0.015782\t F1:0.887%\n",
            "Epoch : 16 [110400/1395 (82%)]\tLoss: 0.036451\t F1:0.887%\n",
            "Epoch : 16 [115200/1395 (86%)]\tLoss: 0.018299\t F1:0.886%\n",
            "Epoch : 16 [120000/1395 (90%)]\tLoss: 0.021900\t F1:0.886%\n",
            "Epoch : 16 [124800/1395 (93%)]\tLoss: 0.019343\t F1:0.886%\n",
            "Epoch : 16 [129600/1395 (97%)]\tLoss: 0.028543\t F1:0.886%\n",
            "Validation F1 Score: 0.7329873125720876\n",
            "Epoch : 17 [0/1395 (0%)]\tLoss: 0.018400\t F1:0.894%\n",
            "Epoch : 17 [4800/1395 (4%)]\tLoss: 0.027100\t F1:0.890%\n",
            "Epoch : 17 [9600/1395 (7%)]\tLoss: 0.013730\t F1:0.892%\n",
            "Epoch : 17 [14400/1395 (11%)]\tLoss: 0.011778\t F1:0.896%\n",
            "Epoch : 17 [19200/1395 (14%)]\tLoss: 0.025858\t F1:0.896%\n",
            "Epoch : 17 [24000/1395 (18%)]\tLoss: 0.016332\t F1:0.897%\n",
            "Epoch : 17 [28800/1395 (22%)]\tLoss: 0.007759\t F1:0.895%\n",
            "Epoch : 17 [33600/1395 (25%)]\tLoss: 0.024966\t F1:0.893%\n",
            "Epoch : 17 [38400/1395 (29%)]\tLoss: 0.028068\t F1:0.891%\n",
            "Epoch : 17 [43200/1395 (32%)]\tLoss: 0.020665\t F1:0.890%\n",
            "Epoch : 17 [48000/1395 (36%)]\tLoss: 0.024482\t F1:0.890%\n",
            "Epoch : 17 [52800/1395 (39%)]\tLoss: 0.017796\t F1:0.890%\n",
            "Epoch : 17 [57600/1395 (43%)]\tLoss: 0.015529\t F1:0.891%\n",
            "Epoch : 17 [62400/1395 (47%)]\tLoss: 0.032215\t F1:0.891%\n",
            "Epoch : 17 [67200/1395 (50%)]\tLoss: 0.026727\t F1:0.888%\n",
            "Epoch : 17 [72000/1395 (54%)]\tLoss: 0.013317\t F1:0.888%\n",
            "Epoch : 17 [76800/1395 (57%)]\tLoss: 0.026862\t F1:0.887%\n",
            "Epoch : 17 [81600/1395 (61%)]\tLoss: 0.016068\t F1:0.887%\n",
            "Epoch : 17 [86400/1395 (65%)]\tLoss: 0.022047\t F1:0.887%\n",
            "Epoch : 17 [91200/1395 (68%)]\tLoss: 0.019632\t F1:0.888%\n",
            "Epoch : 17 [96000/1395 (72%)]\tLoss: 0.030071\t F1:0.888%\n",
            "Epoch : 17 [100800/1395 (75%)]\tLoss: 0.022603\t F1:0.887%\n",
            "Epoch : 17 [105600/1395 (79%)]\tLoss: 0.024453\t F1:0.887%\n",
            "Epoch : 17 [110400/1395 (82%)]\tLoss: 0.040901\t F1:0.887%\n",
            "Epoch : 17 [115200/1395 (86%)]\tLoss: 0.016242\t F1:0.886%\n",
            "Epoch : 17 [120000/1395 (90%)]\tLoss: 0.023702\t F1:0.886%\n",
            "Epoch : 17 [124800/1395 (93%)]\tLoss: 0.021377\t F1:0.885%\n",
            "Epoch : 17 [129600/1395 (97%)]\tLoss: 0.023407\t F1:0.886%\n",
            "Validation F1 Score: 0.7284035936420181\n",
            "Epoch : 18 [0/1395 (0%)]\tLoss: 0.024169\t F1:0.898%\n",
            "Epoch : 18 [4800/1395 (4%)]\tLoss: 0.021702\t F1:0.898%\n",
            "Epoch : 18 [9600/1395 (7%)]\tLoss: 0.010731\t F1:0.897%\n",
            "Epoch : 18 [14400/1395 (11%)]\tLoss: 0.023834\t F1:0.897%\n",
            "Epoch : 18 [19200/1395 (14%)]\tLoss: 0.020609\t F1:0.895%\n",
            "Epoch : 18 [24000/1395 (18%)]\tLoss: 0.019069\t F1:0.894%\n",
            "Epoch : 18 [28800/1395 (22%)]\tLoss: 0.013254\t F1:0.894%\n",
            "Epoch : 18 [33600/1395 (25%)]\tLoss: 0.020344\t F1:0.892%\n",
            "Epoch : 18 [38400/1395 (29%)]\tLoss: 0.010992\t F1:0.892%\n",
            "Epoch : 18 [43200/1395 (32%)]\tLoss: 0.020600\t F1:0.892%\n",
            "Epoch : 18 [48000/1395 (36%)]\tLoss: 0.012291\t F1:0.891%\n",
            "Epoch : 18 [52800/1395 (39%)]\tLoss: 0.017584\t F1:0.891%\n",
            "Epoch : 18 [57600/1395 (43%)]\tLoss: 0.010142\t F1:0.891%\n",
            "Epoch : 18 [62400/1395 (47%)]\tLoss: 0.023202\t F1:0.890%\n",
            "Epoch : 18 [67200/1395 (50%)]\tLoss: 0.017564\t F1:0.889%\n",
            "Epoch : 18 [72000/1395 (54%)]\tLoss: 0.016369\t F1:0.889%\n",
            "Epoch : 18 [76800/1395 (57%)]\tLoss: 0.031752\t F1:0.889%\n",
            "Epoch : 18 [81600/1395 (61%)]\tLoss: 0.021242\t F1:0.888%\n",
            "Epoch : 18 [86400/1395 (65%)]\tLoss: 0.037115\t F1:0.889%\n",
            "Epoch : 18 [91200/1395 (68%)]\tLoss: 0.017138\t F1:0.889%\n",
            "Epoch : 18 [96000/1395 (72%)]\tLoss: 0.035734\t F1:0.889%\n",
            "Epoch : 18 [100800/1395 (75%)]\tLoss: 0.017177\t F1:0.889%\n",
            "Epoch : 18 [105600/1395 (79%)]\tLoss: 0.016421\t F1:0.889%\n",
            "Epoch : 18 [110400/1395 (82%)]\tLoss: 0.028204\t F1:0.889%\n",
            "Epoch : 18 [115200/1395 (86%)]\tLoss: 0.018457\t F1:0.888%\n",
            "Epoch : 18 [120000/1395 (90%)]\tLoss: 0.024155\t F1:0.888%\n",
            "Epoch : 18 [124800/1395 (93%)]\tLoss: 0.023268\t F1:0.888%\n",
            "Epoch : 18 [129600/1395 (97%)]\tLoss: 0.022480\t F1:0.888%\n",
            "Validation F1 Score: 0.7232030264817151\n",
            "Epoch : 19 [0/1395 (0%)]\tLoss: 0.016303\t F1:0.936%\n",
            "Epoch : 19 [4800/1395 (4%)]\tLoss: 0.033790\t F1:0.894%\n",
            "Epoch : 19 [9600/1395 (7%)]\tLoss: 0.016811\t F1:0.896%\n",
            "Epoch : 19 [14400/1395 (11%)]\tLoss: 0.031505\t F1:0.894%\n",
            "Epoch : 19 [19200/1395 (14%)]\tLoss: 0.022861\t F1:0.896%\n",
            "Epoch : 19 [24000/1395 (18%)]\tLoss: 0.026479\t F1:0.897%\n",
            "Epoch : 19 [28800/1395 (22%)]\tLoss: 0.015339\t F1:0.895%\n",
            "Epoch : 19 [33600/1395 (25%)]\tLoss: 0.012769\t F1:0.895%\n",
            "Epoch : 19 [38400/1395 (29%)]\tLoss: 0.018255\t F1:0.895%\n",
            "Epoch : 19 [43200/1395 (32%)]\tLoss: 0.020043\t F1:0.895%\n",
            "Epoch : 19 [48000/1395 (36%)]\tLoss: 0.014134\t F1:0.895%\n",
            "Epoch : 19 [52800/1395 (39%)]\tLoss: 0.019807\t F1:0.896%\n",
            "Epoch : 19 [57600/1395 (43%)]\tLoss: 0.024049\t F1:0.895%\n",
            "Epoch : 19 [62400/1395 (47%)]\tLoss: 0.013340\t F1:0.895%\n",
            "Epoch : 19 [67200/1395 (50%)]\tLoss: 0.020657\t F1:0.895%\n",
            "Epoch : 19 [72000/1395 (54%)]\tLoss: 0.019119\t F1:0.894%\n",
            "Epoch : 19 [76800/1395 (57%)]\tLoss: 0.029206\t F1:0.894%\n",
            "Epoch : 19 [81600/1395 (61%)]\tLoss: 0.014674\t F1:0.893%\n",
            "Epoch : 19 [86400/1395 (65%)]\tLoss: 0.019112\t F1:0.893%\n",
            "Epoch : 19 [91200/1395 (68%)]\tLoss: 0.021924\t F1:0.894%\n",
            "Epoch : 19 [96000/1395 (72%)]\tLoss: 0.030599\t F1:0.894%\n",
            "Epoch : 19 [100800/1395 (75%)]\tLoss: 0.027233\t F1:0.893%\n",
            "Epoch : 19 [105600/1395 (79%)]\tLoss: 0.021256\t F1:0.893%\n",
            "Epoch : 19 [110400/1395 (82%)]\tLoss: 0.020682\t F1:0.893%\n",
            "Epoch : 19 [115200/1395 (86%)]\tLoss: 0.021070\t F1:0.892%\n",
            "Epoch : 19 [120000/1395 (90%)]\tLoss: 0.022023\t F1:0.892%\n",
            "Epoch : 19 [124800/1395 (93%)]\tLoss: 0.018437\t F1:0.892%\n",
            "Epoch : 19 [129600/1395 (97%)]\tLoss: 0.022838\t F1:0.892%\n",
            "Validation F1 Score: 0.7219358232509205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KQyP_QBuqAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(TCMFitter.model.state_dict(), \"TCM_4.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1npXIw8yuqAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2FZy8iOmNf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}