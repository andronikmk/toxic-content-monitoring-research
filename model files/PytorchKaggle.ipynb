{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchnlp.word_to_vector import FastText\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"toxic-train-kaggle-clean.csv\")\n",
    "df[\"word_splits\"] = df[\"word_splits\"].apply(eval)\n",
    "df = df[(df[\"word_splits\"].apply(len) > 0) & (df[\"word_splits\"].apply(len) <= 560)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAD_LENGTH = max(df[\"word_splits\"].apply(len))\n",
    "PAD_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"word_splits\"], df.drop(\"word_splits\", axis=1), test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = FastText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "\n",
    "class ToxicClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToxicClassifierModel, self).__init__()\n",
    "        self.BiGRU = nn.GRU(300, hidden_size = LSTM_UNITS, bidirectional=True, num_layers=1)\n",
    "        self.BiRNN = nn.RNN(input_size = 2 * LSTM_UNITS, hidden_size = LSTM_UNITS, bidirectional=True)\n",
    "        self.hidden1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        self.hidden2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
    "        self.hidden3 = nn.Linear(DENSE_HIDDEN_UNITS, 6)\n",
    "        self.vectors = FastText()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        depth = X.size()[0]\n",
    "        word_num = X.shape[1]\n",
    "        word_emb = X.shape[2]\n",
    "        \n",
    "        #print(\"input:\", X.shape)\n",
    "        \n",
    "        X = X.permute(0, 2, 1)\n",
    "        X = F.dropout2d(X, 0.2, training=self.training)\n",
    "        X = X.permute(0, 2, 1)\n",
    "        \n",
    "        #print(\"Spacial:\", X.shape)\n",
    "        \n",
    "        X = self.BiGRU(X)\n",
    "        #print(\"GRU0:\", X[0].shape)\n",
    "        # print(\"GRU1:\", X[1].shape)\n",
    "        \n",
    "        X = self.BiRNN(X[0])\n",
    "        #print(\"RNN0:\", X[0].shape)\n",
    "        # print(\"RNN1:\", X[1].shape)\n",
    "        \n",
    "        X = X[0]\n",
    "        # X = X[0].permute(0, 2, 1)\n",
    "        \n",
    "        # print(torch.max(X, 1))\n",
    "        \n",
    "        # print(\"Max pool:\", torch.max(X, 1).values.shape)\n",
    "        # print(\"Avg pool:\", torch.mean(X, 1).shape)\n",
    "        \n",
    "        X = torch.cat((torch.max(X, 1).values, torch.mean(X, 1)), 1)\n",
    "        \n",
    "        #print(\"cat:\", X.shape)\n",
    "        \n",
    "        X = X.add(F.relu(self.hidden1(X)))\n",
    "        \n",
    "        #print(\"Dense1:\", X.shape)\n",
    "        \n",
    "        X = X.add(F.relu(self.hidden2(X)))\n",
    "        \n",
    "        #print(\"Dense2:\", X.shape)\n",
    "        \n",
    "        X = torch.sigmoid(self.hidden3(X))\n",
    "        \n",
    "        #print(\"Out:\", X.shape)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TCM = ToxicClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "batched_X_train = []\n",
    "batched_y_train = []\n",
    "\n",
    "i=0\n",
    "while (i+1) * BATCH_SIZE < len(X_train):\n",
    "    batched_X_train.append(X_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "    batched_y_train.append(y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "    i+=1\n",
    "batched_X_train.append(X_train[i*BATCH_SIZE:])\n",
    "batched_y_train.append(y_train[i*BATCH_SIZE:])\n",
    "\n",
    "batched_X_test = []\n",
    "batched_y_test = []\n",
    "\n",
    "del X_train\n",
    "del y_train\n",
    "\n",
    "i=0\n",
    "while (i+1) * BATCH_SIZE < len(X_test):\n",
    "    batched_X_test.append(X_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "    batched_y_test.append(y_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "    i+=1\n",
    "batched_X_test.append(X_test[i*BATCH_SIZE:])\n",
    "batched_y_test.append(y_test[i*BATCH_SIZE:])\n",
    "\n",
    "del X_test\n",
    "del y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCM\n",
    "optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "batch_idx, (X_batch, y_batch) = list(enumerate(zip(batched_X_train, batched_y_train)))[0]\n",
    "var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float()\n",
    "var_y_batch = Variable(torch.from_numpy(y_batch))\n",
    "optimizer.zero_grad()\n",
    "output = model(var_X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[:,5].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = nn.BCELoss()\n",
    "loss = error(output, var_y_batch.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, batched_X_train, batched_y_train):\n",
    "    global acc\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.BCELoss()\n",
    "    EPOCHS = 5\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        acc2 = acc\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
    "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
    "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = output.data.round()\n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, float(correct*100) / float(6 * BATCH_SIZE*(batch_idx+1))))\n",
    "            del var_X_batch\n",
    "            del var_y_batch\n",
    "            del loss\n",
    "            del output\n",
    "            del predicted\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
    "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
    "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
    "            output = TCM(var_X_batch)\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = output.data.round()\n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            del var_X_batch\n",
    "            del var_y_batch\n",
    "            del output\n",
    "            del predicted\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        acc = float(correct*100) / float(6 * BATCH_SIZE * len(batched_X_test))\n",
    "        print(\"Validation Accuracy:\", acc)\n",
    "        del correct\n",
    "\n",
    "        if acc > acc2:\n",
    "            torch.save(TCM.state_dict(), \"TCM_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToxicClassifierModel(\n",
       "  (BiGRU): GRU(300, 128, bidirectional=True)\n",
       "  (BiRNN): RNN(256, 128, bidirectional=True)\n",
       "  (hidden1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden3): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCM.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/2092 (0%)]\tLoss: 0.040024\t Accuracy:98.698%\n",
      "Epoch : 0 [3200/2092 (2%)]\tLoss: 0.028701\t Accuracy:98.626%\n",
      "Epoch : 0 [6400/2092 (5%)]\tLoss: 0.018538\t Accuracy:98.523%\n",
      "Epoch : 0 [9600/2092 (7%)]\tLoss: 0.057085\t Accuracy:98.493%\n",
      "Epoch : 0 [12800/2092 (10%)]\tLoss: 0.042686\t Accuracy:98.488%\n",
      "Epoch : 0 [16000/2092 (12%)]\tLoss: 0.040517\t Accuracy:98.500%\n",
      "Epoch : 0 [19200/2092 (14%)]\tLoss: 0.030784\t Accuracy:98.508%\n",
      "Epoch : 0 [22400/2092 (17%)]\tLoss: 0.033126\t Accuracy:98.494%\n",
      "Epoch : 0 [25600/2092 (19%)]\tLoss: 0.069360\t Accuracy:98.495%\n",
      "Epoch : 0 [28800/2092 (22%)]\tLoss: 0.060049\t Accuracy:98.472%\n",
      "Epoch : 0 [32000/2092 (24%)]\tLoss: 0.035940\t Accuracy:98.466%\n",
      "Epoch : 0 [35200/2092 (26%)]\tLoss: 0.033035\t Accuracy:98.471%\n",
      "Epoch : 0 [38400/2092 (29%)]\tLoss: 0.082789\t Accuracy:98.473%\n",
      "Epoch : 0 [41600/2092 (31%)]\tLoss: 0.016304\t Accuracy:98.480%\n",
      "Epoch : 0 [44800/2092 (33%)]\tLoss: 0.020245\t Accuracy:98.478%\n",
      "Epoch : 0 [48000/2092 (36%)]\tLoss: 0.033250\t Accuracy:98.486%\n",
      "Epoch : 0 [51200/2092 (38%)]\tLoss: 0.015244\t Accuracy:98.491%\n",
      "Epoch : 0 [54400/2092 (41%)]\tLoss: 0.010979\t Accuracy:98.491%\n",
      "Epoch : 0 [57600/2092 (43%)]\tLoss: 0.046121\t Accuracy:98.493%\n",
      "Epoch : 0 [60800/2092 (45%)]\tLoss: 0.047338\t Accuracy:98.481%\n",
      "Epoch : 0 [64000/2092 (48%)]\tLoss: 0.025895\t Accuracy:98.480%\n",
      "Epoch : 0 [67200/2092 (50%)]\tLoss: 0.048420\t Accuracy:98.483%\n",
      "Epoch : 0 [70400/2092 (53%)]\tLoss: 0.034807\t Accuracy:98.481%\n",
      "Epoch : 0 [73600/2092 (55%)]\tLoss: 0.039344\t Accuracy:98.479%\n",
      "Epoch : 0 [76800/2092 (57%)]\tLoss: 0.035564\t Accuracy:98.480%\n",
      "Epoch : 0 [80000/2092 (60%)]\tLoss: 0.020162\t Accuracy:98.481%\n",
      "Epoch : 0 [83200/2092 (62%)]\tLoss: 0.022192\t Accuracy:98.483%\n",
      "Epoch : 0 [86400/2092 (65%)]\tLoss: 0.035851\t Accuracy:98.485%\n",
      "Epoch : 0 [89600/2092 (67%)]\tLoss: 0.030705\t Accuracy:98.486%\n",
      "Epoch : 0 [92800/2092 (69%)]\tLoss: 0.058784\t Accuracy:98.489%\n",
      "Epoch : 0 [96000/2092 (72%)]\tLoss: 0.037975\t Accuracy:98.490%\n",
      "Epoch : 0 [99200/2092 (74%)]\tLoss: 0.071341\t Accuracy:98.493%\n",
      "Epoch : 0 [102400/2092 (76%)]\tLoss: 0.019554\t Accuracy:98.494%\n",
      "Epoch : 0 [105600/2092 (79%)]\tLoss: 0.047835\t Accuracy:98.489%\n",
      "Epoch : 0 [108800/2092 (81%)]\tLoss: 0.035310\t Accuracy:98.493%\n",
      "Epoch : 0 [112000/2092 (84%)]\tLoss: 0.018382\t Accuracy:98.496%\n",
      "Epoch : 0 [115200/2092 (86%)]\tLoss: 0.021871\t Accuracy:98.497%\n",
      "Epoch : 0 [118400/2092 (88%)]\tLoss: 0.076385\t Accuracy:98.498%\n",
      "Epoch : 0 [121600/2092 (91%)]\tLoss: 0.027441\t Accuracy:98.495%\n",
      "Epoch : 0 [124800/2092 (93%)]\tLoss: 0.021591\t Accuracy:98.501%\n",
      "Epoch : 0 [128000/2092 (96%)]\tLoss: 0.028473\t Accuracy:98.503%\n",
      "Epoch : 0 [131200/2092 (98%)]\tLoss: 0.024309\t Accuracy:98.506%\n",
      "Validation Accuracy: 97.92722409909909\n",
      "Epoch : 1 [0/2092 (0%)]\tLoss: 0.032511\t Accuracy:98.438%\n",
      "Epoch : 1 [3200/2092 (2%)]\tLoss: 0.029660\t Accuracy:98.632%\n",
      "Epoch : 1 [6400/2092 (5%)]\tLoss: 0.020202\t Accuracy:98.559%\n",
      "Epoch : 1 [9600/2092 (7%)]\tLoss: 0.048834\t Accuracy:98.525%\n",
      "Epoch : 1 [12800/2092 (10%)]\tLoss: 0.044985\t Accuracy:98.542%\n",
      "Epoch : 1 [16000/2092 (12%)]\tLoss: 0.039100\t Accuracy:98.564%\n",
      "Epoch : 1 [19200/2092 (14%)]\tLoss: 0.033814\t Accuracy:98.564%\n",
      "Epoch : 1 [22400/2092 (17%)]\tLoss: 0.031891\t Accuracy:98.563%\n",
      "Epoch : 1 [25600/2092 (19%)]\tLoss: 0.061047\t Accuracy:98.572%\n",
      "Epoch : 1 [28800/2092 (22%)]\tLoss: 0.065424\t Accuracy:98.550%\n",
      "Epoch : 1 [32000/2092 (24%)]\tLoss: 0.034383\t Accuracy:98.541%\n",
      "Epoch : 1 [35200/2092 (26%)]\tLoss: 0.031474\t Accuracy:98.545%\n",
      "Epoch : 1 [38400/2092 (29%)]\tLoss: 0.093379\t Accuracy:98.546%\n",
      "Epoch : 1 [41600/2092 (31%)]\tLoss: 0.014899\t Accuracy:98.557%\n",
      "Epoch : 1 [44800/2092 (33%)]\tLoss: 0.019652\t Accuracy:98.559%\n",
      "Epoch : 1 [48000/2092 (36%)]\tLoss: 0.035830\t Accuracy:98.566%\n",
      "Epoch : 1 [51200/2092 (38%)]\tLoss: 0.014751\t Accuracy:98.567%\n",
      "Epoch : 1 [54400/2092 (41%)]\tLoss: 0.012285\t Accuracy:98.552%\n",
      "Epoch : 1 [57600/2092 (43%)]\tLoss: 0.045912\t Accuracy:98.554%\n",
      "Epoch : 1 [60800/2092 (45%)]\tLoss: 0.040296\t Accuracy:98.548%\n",
      "Epoch : 1 [64000/2092 (48%)]\tLoss: 0.021365\t Accuracy:98.545%\n",
      "Epoch : 1 [67200/2092 (50%)]\tLoss: 0.041611\t Accuracy:98.543%\n",
      "Epoch : 1 [70400/2092 (53%)]\tLoss: 0.025649\t Accuracy:98.541%\n",
      "Epoch : 1 [73600/2092 (55%)]\tLoss: 0.031924\t Accuracy:98.547%\n",
      "Epoch : 1 [76800/2092 (57%)]\tLoss: 0.034308\t Accuracy:98.544%\n",
      "Epoch : 1 [80000/2092 (60%)]\tLoss: 0.018568\t Accuracy:98.542%\n",
      "Epoch : 1 [83200/2092 (62%)]\tLoss: 0.025478\t Accuracy:98.544%\n",
      "Epoch : 1 [86400/2092 (65%)]\tLoss: 0.039149\t Accuracy:98.546%\n",
      "Epoch : 1 [89600/2092 (67%)]\tLoss: 0.028408\t Accuracy:98.549%\n",
      "Epoch : 1 [92800/2092 (69%)]\tLoss: 0.057195\t Accuracy:98.552%\n",
      "Epoch : 1 [96000/2092 (72%)]\tLoss: 0.035731\t Accuracy:98.555%\n",
      "Epoch : 1 [99200/2092 (74%)]\tLoss: 0.049444\t Accuracy:98.558%\n",
      "Epoch : 1 [102400/2092 (76%)]\tLoss: 0.016715\t Accuracy:98.562%\n",
      "Epoch : 1 [105600/2092 (79%)]\tLoss: 0.042063\t Accuracy:98.559%\n",
      "Epoch : 1 [108800/2092 (81%)]\tLoss: 0.039865\t Accuracy:98.562%\n",
      "Epoch : 1 [112000/2092 (84%)]\tLoss: 0.015863\t Accuracy:98.566%\n",
      "Epoch : 1 [115200/2092 (86%)]\tLoss: 0.020980\t Accuracy:98.569%\n",
      "Epoch : 1 [118400/2092 (88%)]\tLoss: 0.075071\t Accuracy:98.574%\n",
      "Epoch : 1 [121600/2092 (91%)]\tLoss: 0.030076\t Accuracy:98.571%\n",
      "Epoch : 1 [124800/2092 (93%)]\tLoss: 0.020296\t Accuracy:98.577%\n",
      "Epoch : 1 [128000/2092 (96%)]\tLoss: 0.036403\t Accuracy:98.576%\n",
      "Epoch : 1 [131200/2092 (98%)]\tLoss: 0.017114\t Accuracy:98.579%\n",
      "Validation Accuracy: 97.97226914414415\n",
      "Epoch : 2 [0/2092 (0%)]\tLoss: 0.033962\t Accuracy:98.958%\n",
      "Epoch : 2 [3200/2092 (2%)]\tLoss: 0.035504\t Accuracy:98.693%\n",
      "Epoch : 2 [6400/2092 (5%)]\tLoss: 0.021038\t Accuracy:98.613%\n",
      "Epoch : 2 [9600/2092 (7%)]\tLoss: 0.041747\t Accuracy:98.584%\n",
      "Epoch : 2 [12800/2092 (10%)]\tLoss: 0.045851\t Accuracy:98.611%\n",
      "Epoch : 2 [16000/2092 (12%)]\tLoss: 0.033903\t Accuracy:98.630%\n",
      "Epoch : 2 [19200/2092 (14%)]\tLoss: 0.030094\t Accuracy:98.622%\n",
      "Epoch : 2 [22400/2092 (17%)]\tLoss: 0.021867\t Accuracy:98.607%\n",
      "Epoch : 2 [25600/2092 (19%)]\tLoss: 0.055603\t Accuracy:98.621%\n",
      "Epoch : 2 [28800/2092 (22%)]\tLoss: 0.063328\t Accuracy:98.599%\n",
      "Epoch : 2 [32000/2092 (24%)]\tLoss: 0.031544\t Accuracy:98.590%\n",
      "Epoch : 2 [35200/2092 (26%)]\tLoss: 0.026517\t Accuracy:98.604%\n",
      "Epoch : 2 [38400/2092 (29%)]\tLoss: 0.074911\t Accuracy:98.613%\n",
      "Epoch : 2 [41600/2092 (31%)]\tLoss: 0.015189\t Accuracy:98.618%\n",
      "Epoch : 2 [44800/2092 (33%)]\tLoss: 0.018388\t Accuracy:98.626%\n",
      "Epoch : 2 [48000/2092 (36%)]\tLoss: 0.039862\t Accuracy:98.629%\n",
      "Epoch : 2 [51200/2092 (38%)]\tLoss: 0.021433\t Accuracy:98.627%\n",
      "Epoch : 2 [54400/2092 (41%)]\tLoss: 0.008237\t Accuracy:98.623%\n",
      "Epoch : 2 [57600/2092 (43%)]\tLoss: 0.038921\t Accuracy:98.626%\n",
      "Epoch : 2 [60800/2092 (45%)]\tLoss: 0.037724\t Accuracy:98.610%\n",
      "Epoch : 2 [64000/2092 (48%)]\tLoss: 0.022736\t Accuracy:98.608%\n",
      "Epoch : 2 [67200/2092 (50%)]\tLoss: 0.036975\t Accuracy:98.611%\n",
      "Epoch : 2 [70400/2092 (53%)]\tLoss: 0.018767\t Accuracy:98.613%\n",
      "Epoch : 2 [73600/2092 (55%)]\tLoss: 0.030569\t Accuracy:98.614%\n",
      "Epoch : 2 [76800/2092 (57%)]\tLoss: 0.028878\t Accuracy:98.616%\n",
      "Epoch : 2 [80000/2092 (60%)]\tLoss: 0.023885\t Accuracy:98.618%\n",
      "Epoch : 2 [83200/2092 (62%)]\tLoss: 0.025727\t Accuracy:98.619%\n",
      "Epoch : 2 [86400/2092 (65%)]\tLoss: 0.032004\t Accuracy:98.621%\n",
      "Epoch : 2 [89600/2092 (67%)]\tLoss: 0.027414\t Accuracy:98.622%\n",
      "Epoch : 2 [92800/2092 (69%)]\tLoss: 0.055506\t Accuracy:98.625%\n",
      "Epoch : 2 [96000/2092 (72%)]\tLoss: 0.032843\t Accuracy:98.623%\n",
      "Epoch : 2 [99200/2092 (74%)]\tLoss: 0.055915\t Accuracy:98.625%\n",
      "Epoch : 2 [102400/2092 (76%)]\tLoss: 0.012958\t Accuracy:98.627%\n",
      "Epoch : 2 [105600/2092 (79%)]\tLoss: 0.041001\t Accuracy:98.623%\n",
      "Epoch : 2 [108800/2092 (81%)]\tLoss: 0.028968\t Accuracy:98.625%\n",
      "Epoch : 2 [112000/2092 (84%)]\tLoss: 0.018914\t Accuracy:98.630%\n",
      "Epoch : 2 [115200/2092 (86%)]\tLoss: 0.018885\t Accuracy:98.632%\n",
      "Epoch : 2 [118400/2092 (88%)]\tLoss: 0.068875\t Accuracy:98.635%\n",
      "Epoch : 2 [121600/2092 (91%)]\tLoss: 0.022804\t Accuracy:98.633%\n",
      "Epoch : 2 [124800/2092 (93%)]\tLoss: 0.016078\t Accuracy:98.641%\n",
      "Epoch : 2 [128000/2092 (96%)]\tLoss: 0.026444\t Accuracy:98.643%\n",
      "Epoch : 2 [131200/2092 (98%)]\tLoss: 0.018236\t Accuracy:98.647%\n",
      "Validation Accuracy: 97.92159346846847\n",
      "Epoch : 3 [0/2092 (0%)]\tLoss: 0.040857\t Accuracy:98.177%\n",
      "Epoch : 3 [3200/2092 (2%)]\tLoss: 0.031863\t Accuracy:98.718%\n",
      "Epoch : 3 [6400/2092 (5%)]\tLoss: 0.020346\t Accuracy:98.682%\n",
      "Epoch : 3 [9600/2092 (7%)]\tLoss: 0.046601\t Accuracy:98.663%\n",
      "Epoch : 3 [12800/2092 (10%)]\tLoss: 0.028907\t Accuracy:98.671%\n",
      "Epoch : 3 [16000/2092 (12%)]\tLoss: 0.041140\t Accuracy:98.680%\n",
      "Epoch : 3 [19200/2092 (14%)]\tLoss: 0.026446\t Accuracy:98.678%\n",
      "Epoch : 3 [22400/2092 (17%)]\tLoss: 0.021630\t Accuracy:98.665%\n",
      "Epoch : 3 [25600/2092 (19%)]\tLoss: 0.051318\t Accuracy:98.673%\n",
      "Epoch : 3 [28800/2092 (22%)]\tLoss: 0.060541\t Accuracy:98.658%\n",
      "Epoch : 3 [32000/2092 (24%)]\tLoss: 0.023135\t Accuracy:98.649%\n",
      "Epoch : 3 [35200/2092 (26%)]\tLoss: 0.021301\t Accuracy:98.646%\n",
      "Epoch : 3 [38400/2092 (29%)]\tLoss: 0.066459\t Accuracy:98.664%\n",
      "Epoch : 3 [41600/2092 (31%)]\tLoss: 0.015544\t Accuracy:98.666%\n",
      "Epoch : 3 [44800/2092 (33%)]\tLoss: 0.021211\t Accuracy:98.670%\n",
      "Epoch : 3 [48000/2092 (36%)]\tLoss: 0.036940\t Accuracy:98.671%\n",
      "Epoch : 3 [51200/2092 (38%)]\tLoss: 0.023893\t Accuracy:98.679%\n",
      "Epoch : 3 [54400/2092 (41%)]\tLoss: 0.010787\t Accuracy:98.672%\n",
      "Epoch : 3 [57600/2092 (43%)]\tLoss: 0.045861\t Accuracy:98.675%\n",
      "Epoch : 3 [60800/2092 (45%)]\tLoss: 0.040321\t Accuracy:98.661%\n",
      "Epoch : 3 [64000/2092 (48%)]\tLoss: 0.022261\t Accuracy:98.654%\n",
      "Epoch : 3 [67200/2092 (50%)]\tLoss: 0.040638\t Accuracy:98.650%\n",
      "Epoch : 3 [70400/2092 (53%)]\tLoss: 0.014249\t Accuracy:98.652%\n",
      "Epoch : 3 [73600/2092 (55%)]\tLoss: 0.030965\t Accuracy:98.657%\n",
      "Epoch : 3 [76800/2092 (57%)]\tLoss: 0.024365\t Accuracy:98.659%\n",
      "Epoch : 3 [80000/2092 (60%)]\tLoss: 0.019940\t Accuracy:98.661%\n",
      "Epoch : 3 [83200/2092 (62%)]\tLoss: 0.021985\t Accuracy:98.663%\n",
      "Epoch : 3 [86400/2092 (65%)]\tLoss: 0.042700\t Accuracy:98.663%\n",
      "Epoch : 3 [89600/2092 (67%)]\tLoss: 0.023872\t Accuracy:98.666%\n",
      "Epoch : 3 [92800/2092 (69%)]\tLoss: 0.042904\t Accuracy:98.672%\n",
      "Epoch : 3 [96000/2092 (72%)]\tLoss: 0.034145\t Accuracy:98.673%\n",
      "Epoch : 3 [99200/2092 (74%)]\tLoss: 0.043010\t Accuracy:98.677%\n",
      "Epoch : 3 [102400/2092 (76%)]\tLoss: 0.012464\t Accuracy:98.680%\n",
      "Epoch : 3 [105600/2092 (79%)]\tLoss: 0.033419\t Accuracy:98.679%\n",
      "Epoch : 3 [108800/2092 (81%)]\tLoss: 0.036240\t Accuracy:98.682%\n",
      "Epoch : 3 [112000/2092 (84%)]\tLoss: 0.015775\t Accuracy:98.684%\n",
      "Epoch : 3 [115200/2092 (86%)]\tLoss: 0.019382\t Accuracy:98.687%\n",
      "Epoch : 3 [118400/2092 (88%)]\tLoss: 0.056986\t Accuracy:98.694%\n",
      "Epoch : 3 [121600/2092 (91%)]\tLoss: 0.020563\t Accuracy:98.693%\n",
      "Epoch : 3 [124800/2092 (93%)]\tLoss: 0.018302\t Accuracy:98.700%\n",
      "Epoch : 3 [128000/2092 (96%)]\tLoss: 0.026904\t Accuracy:98.702%\n",
      "Epoch : 3 [131200/2092 (98%)]\tLoss: 0.026504\t Accuracy:98.705%\n",
      "Validation Accuracy: 97.93848536036036\n",
      "Epoch : 4 [0/2092 (0%)]\tLoss: 0.039634\t Accuracy:98.177%\n",
      "Epoch : 4 [3200/2092 (2%)]\tLoss: 0.026853\t Accuracy:98.846%\n",
      "Epoch : 4 [6400/2092 (5%)]\tLoss: 0.015086\t Accuracy:98.806%\n",
      "Epoch : 4 [9600/2092 (7%)]\tLoss: 0.040530\t Accuracy:98.748%\n",
      "Epoch : 4 [12800/2092 (10%)]\tLoss: 0.029741\t Accuracy:98.754%\n",
      "Epoch : 4 [16000/2092 (12%)]\tLoss: 0.038321\t Accuracy:98.787%\n",
      "Epoch : 4 [19200/2092 (14%)]\tLoss: 0.023727\t Accuracy:98.766%\n",
      "Epoch : 4 [22400/2092 (17%)]\tLoss: 0.017720\t Accuracy:98.767%\n",
      "Epoch : 4 [25600/2092 (19%)]\tLoss: 0.039425\t Accuracy:98.778%\n",
      "Epoch : 4 [28800/2092 (22%)]\tLoss: 0.064597\t Accuracy:98.747%\n",
      "Epoch : 4 [32000/2092 (24%)]\tLoss: 0.025974\t Accuracy:98.734%\n",
      "Epoch : 4 [35200/2092 (26%)]\tLoss: 0.022756\t Accuracy:98.731%\n",
      "Epoch : 4 [38400/2092 (29%)]\tLoss: 0.072295\t Accuracy:98.744%\n",
      "Epoch : 4 [41600/2092 (31%)]\tLoss: 0.008141\t Accuracy:98.742%\n",
      "Epoch : 4 [44800/2092 (33%)]\tLoss: 0.020191\t Accuracy:98.742%\n",
      "Epoch : 4 [48000/2092 (36%)]\tLoss: 0.036576\t Accuracy:98.744%\n",
      "Epoch : 4 [51200/2092 (38%)]\tLoss: 0.009249\t Accuracy:98.750%\n",
      "Epoch : 4 [54400/2092 (41%)]\tLoss: 0.012554\t Accuracy:98.745%\n",
      "Epoch : 4 [57600/2092 (43%)]\tLoss: 0.033336\t Accuracy:98.743%\n",
      "Epoch : 4 [60800/2092 (45%)]\tLoss: 0.036810\t Accuracy:98.726%\n",
      "Epoch : 4 [64000/2092 (48%)]\tLoss: 0.018320\t Accuracy:98.722%\n",
      "Epoch : 4 [67200/2092 (50%)]\tLoss: 0.048222\t Accuracy:98.721%\n",
      "Epoch : 4 [70400/2092 (53%)]\tLoss: 0.021725\t Accuracy:98.727%\n",
      "Epoch : 4 [73600/2092 (55%)]\tLoss: 0.028559\t Accuracy:98.726%\n",
      "Epoch : 4 [76800/2092 (57%)]\tLoss: 0.027976\t Accuracy:98.723%\n",
      "Epoch : 4 [80000/2092 (60%)]\tLoss: 0.025230\t Accuracy:98.718%\n",
      "Epoch : 4 [83200/2092 (62%)]\tLoss: 0.023012\t Accuracy:98.719%\n",
      "Epoch : 4 [86400/2092 (65%)]\tLoss: 0.028021\t Accuracy:98.722%\n",
      "Epoch : 4 [89600/2092 (67%)]\tLoss: 0.039136\t Accuracy:98.724%\n",
      "Epoch : 4 [92800/2092 (69%)]\tLoss: 0.041447\t Accuracy:98.731%\n",
      "Epoch : 4 [96000/2092 (72%)]\tLoss: 0.038420\t Accuracy:98.732%\n",
      "Epoch : 4 [99200/2092 (74%)]\tLoss: 0.040342\t Accuracy:98.733%\n",
      "Epoch : 4 [102400/2092 (76%)]\tLoss: 0.011921\t Accuracy:98.734%\n",
      "Epoch : 4 [105600/2092 (79%)]\tLoss: 0.028770\t Accuracy:98.731%\n",
      "Epoch : 4 [108800/2092 (81%)]\tLoss: 0.028912\t Accuracy:98.736%\n",
      "Epoch : 4 [112000/2092 (84%)]\tLoss: 0.011312\t Accuracy:98.741%\n",
      "Epoch : 4 [115200/2092 (86%)]\tLoss: 0.018154\t Accuracy:98.744%\n",
      "Epoch : 4 [118400/2092 (88%)]\tLoss: 0.052820\t Accuracy:98.750%\n",
      "Epoch : 4 [121600/2092 (91%)]\tLoss: 0.017033\t Accuracy:98.750%\n",
      "Epoch : 4 [124800/2092 (93%)]\tLoss: 0.029262\t Accuracy:98.758%\n",
      "Epoch : 4 [128000/2092 (96%)]\tLoss: 0.022850\t Accuracy:98.761%\n",
      "Epoch : 4 [131200/2092 (98%)]\tLoss: 0.020275\t Accuracy:98.764%\n",
      "Validation Accuracy: 97.92229729729729\n"
     ]
    }
   ],
   "source": [
    "fit(TCM, batched_X_train, batched_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(TCM.state_dict(), \"TCM_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToxicClassifierModel(\n",
       "  (BiGRU): GRU(300, 128, bidirectional=True)\n",
       "  (BiRNN): RNN(256, 128, bidirectional=True)\n",
       "  (hidden1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden3): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ToxicClassifierModel()\n",
    "model.load_state_dict(torch.load(\"TCM_2.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "del TCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToxicClassifierModel(\n",
       "  (BiGRU): GRU(300, 128, bidirectional=True)\n",
       "  (BiRNN): RNN(256, 128, bidirectional=True)\n",
       "  (hidden1): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (hidden3): Linear(in_features=512, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predProb = []\n",
    "truePreds = []\n",
    "for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
    "    var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
    "    var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
    "    output = model(var_X_batch)\n",
    "\n",
    "    predProb = predProb + [ x for X in output.data for x in X ]\n",
    "    truePreds = truePreds + [ x for X in var_y_batch for x in X ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predProb = [ float(p) for p in predProb ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [ round(p) for p in predProb ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "truePreds = [ int(p) for p in truePreds ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9871023395825137\n",
      "0.7533161561217673\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(truePreds, predProb))\n",
    "print(f1_score(truePreds, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
