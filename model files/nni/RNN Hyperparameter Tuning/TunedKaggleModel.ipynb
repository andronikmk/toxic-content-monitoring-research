{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # to handle matrix and data operation\n",
    "import pandas as pd # to read csv and handle dataframe\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchnlp.word_to_vector import FastText\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_location = \"TCM_7.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = FastText()\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "BATCH_SIZE = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''Load dataset, data cleaned using Kaggle method.'''\n",
    "    df = pd.read_csv(\"toxic-train-kaggle-clean.csv\")\n",
    "    df[\"word_splits\"] = df[\"word_splits\"].apply(eval)\n",
    "    df = df[(df[\"word_splits\"].apply(len) > 0) & (df[\"word_splits\"].apply(len) <= 560)]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"word_splits\"], df.drop(\"word_splits\", axis=1), random_state=99, test_size=0.15)\n",
    "\n",
    "    X_train = X_train.values\n",
    "    y_train = y_train.values\n",
    "\n",
    "    X_test = X_test.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    batched_X_train = []\n",
    "    batched_y_train = []\n",
    "\n",
    "    i=0\n",
    "    while (i+1) * BATCH_SIZE < len(X_train):\n",
    "        batched_X_train.append(X_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        batched_y_train.append(y_train[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        i+=1\n",
    "    batched_X_train.append(X_train[i*BATCH_SIZE:])\n",
    "    batched_y_train.append(y_train[i*BATCH_SIZE:])\n",
    "\n",
    "    batched_X_test = []\n",
    "    batched_y_test = []\n",
    "\n",
    "    del X_train\n",
    "    del y_train\n",
    "\n",
    "    i=0\n",
    "    while (i+1) * BATCH_SIZE < len(X_test):\n",
    "        batched_X_test.append(X_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        batched_y_test.append(y_test[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "        i+=1\n",
    "    batched_X_test.append(X_test[i*BATCH_SIZE:])\n",
    "    batched_y_test.append(y_test[i*BATCH_SIZE:])\n",
    "\n",
    "    del X_test\n",
    "    del y_test\n",
    "\n",
    "    return batched_X_train, batched_y_train, batched_X_test, batched_y_test\n",
    "\n",
    "batched_X_train, batched_y_train, batched_X_test, batched_y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToxicClassifierModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 LSTM_UNITS = 128,\n",
    "                 dropout_rate = 0.2,\n",
    "                 hidden1Activation = F.relu,\n",
    "                 hidden2Activation = F.relu,\n",
    "                 #hidden1Size = 512,\n",
    "                 #hidden2Size = 512\n",
    "                 ):\n",
    "        super(ToxicClassifierModel, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.BiGRU = nn.GRU(300, hidden_size = LSTM_UNITS, bidirectional=True, num_layers=1)\n",
    "        self.BiRNN = nn.RNN(input_size = 2 * LSTM_UNITS, hidden_size = LSTM_UNITS, bidirectional=True)\n",
    "        self.hidden1 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
    "        self.hidden1Activation = hidden1Activation\n",
    "        self.hidden2 = nn.Linear(4 * LSTM_UNITS, 4 * LSTM_UNITS)\n",
    "        self.hidden2Activation = hidden2Activation\n",
    "        self.hidden3 = nn.Linear(4 * LSTM_UNITS, 6)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = X.permute(0, 2, 1)\n",
    "        X = F.dropout2d(X, self.dropout_rate, training=self.training)\n",
    "        X = X.permute(0, 2, 1)\n",
    "        \n",
    "        X = self.BiGRU(X)\n",
    "        \n",
    "        X = self.BiRNN(X[0])\n",
    "        \n",
    "        X = X[0]\n",
    "        \n",
    "        X = torch.cat((torch.max(X, 1).values, torch.mean(X, 1)), 1)\n",
    "        \n",
    "        X = X.add(self.hidden1Activation(self.hidden1(X)))\n",
    "        \n",
    "        X = X.add(self.hidden2Activation(self.hidden2(X)))\n",
    "        \n",
    "        X = torch.sigmoid(self.hidden3(X))\n",
    "        \n",
    "        return X\n",
    "\n",
    "class ToxicClassifierFitter():\n",
    "    def __init__(self,\n",
    "                 optimizer,\n",
    "                 error,\n",
    "                 model,\n",
    "                 vectors,\n",
    "                 device,\n",
    "                 EPOCHS = 2,\n",
    "                 seed_acc = 0.5,\n",
    "                 save_checkpoint = True,\n",
    "                 model_save_location = model_save_location\n",
    "                 ):\n",
    "        self.optimizer = optimizer\n",
    "        self.error = error\n",
    "        self.model = model\n",
    "        self.EPOCHS = EPOCHS\n",
    "        self.acc = seed_acc\n",
    "        self.vectors = vectors\n",
    "        self.device = device\n",
    "        self.model_save_location = model_save_location\n",
    "        self.save_checkpoint = save_checkpoint\n",
    "    \n",
    "    def accuracy(self, batched_X_test, batched_y_test):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
    "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
    "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
    "            output = self.model(var_X_batch)\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = output.data.round()\n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            del var_X_batch\n",
    "            del var_y_batch\n",
    "            del output\n",
    "            del predicted\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        self.acc = float(correct*100) / float(6 * BATCH_SIZE * len(batched_X_test))\n",
    "            \n",
    "        return self.acc\n",
    "\n",
    "    def F1Score(self, batched_X_test, batched_y_test):\n",
    "        preds = []\n",
    "        truePreds = []\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
    "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ vectors[X] for X in X_batch]).permute(1,0,2)).float().to(device)\n",
    "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(device)\n",
    "            output = self.model(var_X_batch)\n",
    "\n",
    "            preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
    "            truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
    "            del var_X_batch\n",
    "            del var_y_batch\n",
    "            del output\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return f1_score(truePreds, preds)\n",
    "\n",
    "    def predict(self, batched_X_test, batched_y_test):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_test, batched_y_test)):\n",
    "            var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
    "            var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
    "            output = self.model(var_X_batch)\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = output.data.round()\n",
    "            del var_X_batch\n",
    "            del var_y_batch\n",
    "            del output\n",
    "            del predicted\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        return predicted\n",
    "    \n",
    "    def fit(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            correct = 0\n",
    "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
    "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
    "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(var_X_batch)\n",
    "                loss = self.error(output, var_y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                # Total correct predictions\n",
    "                predicted = output.data.round()\n",
    "                correct += (predicted == var_y_batch).sum()\n",
    "                #print(correct)\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, float(correct*100) / float(6 * BATCH_SIZE*(batch_idx+1))))\n",
    "                del var_X_batch\n",
    "                del var_y_batch\n",
    "                del loss\n",
    "                del output\n",
    "                del predicted\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            if self.save_checkpoint:\n",
    "                acc2 = self.accuracy(batched_X_test, batched_y_test)\n",
    "                \n",
    "                print(\"Validation accuracy Score:\", acc2)\n",
    "                \n",
    "                if acc2 > self.acc:\n",
    "                    print(\"Saving best model...\")\n",
    "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
    "                 \n",
    "                    self.acc = acc2\n",
    "\n",
    "    def fitF1(self, batched_X_train, batched_y_train, batched_X_test = None, batched_y_test = None):\n",
    "        for epoch in range(self.EPOCHS):\n",
    "            preds = []\n",
    "            truePreds = []\n",
    "            for batch_idx, (X_batch, y_batch) in enumerate(zip(batched_X_train, batched_y_train)):\n",
    "                var_X_batch = Variable(torch.nn.utils.rnn.pad_sequence([ self.vectors[X] for X in X_batch]).permute(1,0,2)).float().to(self.device)\n",
    "                var_y_batch = Variable(torch.from_numpy(y_batch)).float().to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(var_X_batch)\n",
    "                loss = self.error(output, var_y_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                preds = preds + [ round(float(x)) for X in output.data for x in X ]\n",
    "                truePreds = truePreds + [ round(float(x)) for X in var_y_batch for x in X ]\n",
    "\n",
    "                if batch_idx % 50 == 0:\n",
    "                    print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t F1:{:.3f}%'.format(\n",
    "                        epoch, batch_idx*len(X_batch), len(batched_X_train), 100.*batch_idx / len(batched_X_train), loss.data, f1_score(truePreds, preds)))\n",
    "                del var_X_batch\n",
    "                del var_y_batch\n",
    "                del loss\n",
    "                del output\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            if self.save_checkpoint:\n",
    "                acc2 = self.F1Score(batched_X_test, batched_y_test)\n",
    "                \n",
    "                print(\"Validation F1 Score:\", acc2)\n",
    "                \n",
    "                if acc2 > self.acc:\n",
    "                    print(\"Saving best model...\")\n",
    "                    torch.save(self.model.state_dict(), self.model_save_location)\n",
    "                 \n",
    "                    self.acc = acc2\n",
    "                \n",
    "\n",
    "def createFitter(LSTM_UNITS = 128,\n",
    "                 #hidden1Size = 512,\n",
    "                 #hidden2Size = 512,\n",
    "                 dropout_rate = 0.2,\n",
    "                 hidden1Activation = F.relu,\n",
    "                 hidden2Activation = F.relu,\n",
    "                 learning_rate=0.001,\n",
    "                 beta_1 = 0.9,\n",
    "                 beta_2 = 0.999,\n",
    "                 amsgrad=False,\n",
    "                 weight_decay=0,\n",
    "                 epochs = 1,\n",
    "                 model_save_location=model_save_location,\n",
    "                 vectors=vectors\n",
    "                 ):\n",
    "    \n",
    "    # get device\n",
    "    \n",
    "    model = ToxicClassifierModel(LSTM_UNITS = LSTM_UNITS,\n",
    "                                 dropout_rate = dropout_rate,\n",
    "                                 hidden1Activation = hidden1Activation,\n",
    "                                 hidden2Activation = hidden2Activation,\n",
    "                                 #hidden1Size = hidden1Size,\n",
    "                                 #hidden2Size = hidden2Size\n",
    "                                )\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(beta_1,beta_2), amsgrad=amsgrad, weight_decay=weight_decay)\n",
    "    \n",
    "    error = nn.BCELoss()\n",
    "    \n",
    "    # return final fitter \n",
    "\n",
    "    return ToxicClassifierFitter(optimizer, error,\n",
    "                                 model,\n",
    "                                 vectors,\n",
    "                                 device,\n",
    "                                 EPOCHS = epochs,\n",
    "                                 model_save_location = model_save_location,\n",
    "                                 save_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dict = {'relu':F.relu\n",
    "                  ,'leaky_relu':F.leaky_relu\n",
    "                  ,'softmax':F.softmax\n",
    "                  ,'selu':F.selu\n",
    "                  ,'tanh':F.tanh\n",
    "                  ,'sigmoid':torch.sigmoid\n",
    "                  ,'elu':F.elu\n",
    "                  }\n",
    "                      \n",
    "TCMFitter = createFitter(\n",
    "                 LSTM_UNITS = 128,\n",
    "                 dropout_rate = 0.2,\n",
    "                 hidden1Activation = activation_dict[\"relu\"],\n",
    "                 hidden2Activation = activation_dict[\"sigmoid\"],\n",
    "                 learning_rate = 1e-3, #0.002683035186257151,\n",
    "                 amsgrad = False,\n",
    "                 weight_decay = 0,\n",
    "                 epochs = 20\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCMFitter.model.load_state_dict(torch.load(\"TCM_2.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/1395 (0%)]\tLoss: 0.035944\t F1:0.833%\n",
      "Epoch : 0 [4800/1395 (4%)]\tLoss: 0.051169\t F1:0.779%\n",
      "Epoch : 0 [9600/1395 (7%)]\tLoss: 0.028557\t F1:0.777%\n",
      "Epoch : 0 [14400/1395 (11%)]\tLoss: 0.043880\t F1:0.767%\n",
      "Epoch : 0 [19200/1395 (14%)]\tLoss: 0.054635\t F1:0.768%\n",
      "Epoch : 0 [24000/1395 (18%)]\tLoss: 0.039390\t F1:0.763%\n",
      "Epoch : 0 [28800/1395 (22%)]\tLoss: 0.040801\t F1:0.763%\n",
      "Epoch : 0 [33600/1395 (25%)]\tLoss: 0.037225\t F1:0.761%\n",
      "Epoch : 0 [38400/1395 (29%)]\tLoss: 0.044237\t F1:0.760%\n",
      "Epoch : 0 [43200/1395 (32%)]\tLoss: 0.041323\t F1:0.760%\n",
      "Epoch : 0 [48000/1395 (36%)]\tLoss: 0.035321\t F1:0.761%\n",
      "Epoch : 0 [52800/1395 (39%)]\tLoss: 0.036408\t F1:0.762%\n",
      "Epoch : 0 [57600/1395 (43%)]\tLoss: 0.026249\t F1:0.763%\n",
      "Epoch : 0 [62400/1395 (47%)]\tLoss: 0.058635\t F1:0.763%\n",
      "Epoch : 0 [67200/1395 (50%)]\tLoss: 0.028999\t F1:0.760%\n",
      "Epoch : 0 [72000/1395 (54%)]\tLoss: 0.035399\t F1:0.760%\n",
      "Epoch : 0 [76800/1395 (57%)]\tLoss: 0.064828\t F1:0.759%\n",
      "Epoch : 0 [81600/1395 (61%)]\tLoss: 0.058292\t F1:0.757%\n",
      "Epoch : 0 [86400/1395 (65%)]\tLoss: 0.052412\t F1:0.756%\n",
      "Epoch : 0 [91200/1395 (68%)]\tLoss: 0.038853\t F1:0.756%\n",
      "Epoch : 0 [96000/1395 (72%)]\tLoss: 0.068514\t F1:0.755%\n",
      "Epoch : 0 [100800/1395 (75%)]\tLoss: 0.029588\t F1:0.755%\n",
      "Epoch : 0 [105600/1395 (79%)]\tLoss: 0.049276\t F1:0.755%\n",
      "Epoch : 0 [110400/1395 (82%)]\tLoss: 0.049378\t F1:0.755%\n",
      "Epoch : 0 [115200/1395 (86%)]\tLoss: 0.033299\t F1:0.754%\n",
      "Epoch : 0 [120000/1395 (90%)]\tLoss: 0.056740\t F1:0.754%\n",
      "Epoch : 0 [124800/1395 (93%)]\tLoss: 0.044332\t F1:0.754%\n",
      "Epoch : 0 [129600/1395 (97%)]\tLoss: 0.056996\t F1:0.754%\n",
      "Validation F1 Score: 0.7611116893931509\n",
      "Saving best model...\n",
      "Epoch : 1 [0/1395 (0%)]\tLoss: 0.038367\t F1:0.756%\n",
      "Epoch : 1 [4800/1395 (4%)]\tLoss: 0.051357\t F1:0.784%\n",
      "Epoch : 1 [9600/1395 (7%)]\tLoss: 0.028714\t F1:0.787%\n",
      "Epoch : 1 [14400/1395 (11%)]\tLoss: 0.033227\t F1:0.782%\n",
      "Epoch : 1 [19200/1395 (14%)]\tLoss: 0.046008\t F1:0.781%\n",
      "Epoch : 1 [24000/1395 (18%)]\tLoss: 0.040936\t F1:0.781%\n",
      "Epoch : 1 [28800/1395 (22%)]\tLoss: 0.035323\t F1:0.782%\n",
      "Epoch : 1 [33600/1395 (25%)]\tLoss: 0.039551\t F1:0.782%\n",
      "Epoch : 1 [38400/1395 (29%)]\tLoss: 0.042174\t F1:0.781%\n",
      "Epoch : 1 [43200/1395 (32%)]\tLoss: 0.044259\t F1:0.780%\n",
      "Epoch : 1 [48000/1395 (36%)]\tLoss: 0.025755\t F1:0.781%\n",
      "Epoch : 1 [52800/1395 (39%)]\tLoss: 0.034846\t F1:0.782%\n",
      "Epoch : 1 [57600/1395 (43%)]\tLoss: 0.028510\t F1:0.782%\n",
      "Epoch : 1 [62400/1395 (47%)]\tLoss: 0.057020\t F1:0.781%\n",
      "Epoch : 1 [67200/1395 (50%)]\tLoss: 0.025249\t F1:0.779%\n",
      "Epoch : 1 [72000/1395 (54%)]\tLoss: 0.027165\t F1:0.779%\n",
      "Epoch : 1 [76800/1395 (57%)]\tLoss: 0.062580\t F1:0.778%\n",
      "Epoch : 1 [81600/1395 (61%)]\tLoss: 0.042219\t F1:0.777%\n",
      "Epoch : 1 [86400/1395 (65%)]\tLoss: 0.057500\t F1:0.775%\n",
      "Epoch : 1 [91200/1395 (68%)]\tLoss: 0.036853\t F1:0.776%\n",
      "Epoch : 1 [96000/1395 (72%)]\tLoss: 0.059336\t F1:0.775%\n",
      "Epoch : 1 [100800/1395 (75%)]\tLoss: 0.029840\t F1:0.775%\n",
      "Epoch : 1 [105600/1395 (79%)]\tLoss: 0.048393\t F1:0.775%\n",
      "Epoch : 1 [110400/1395 (82%)]\tLoss: 0.046922\t F1:0.775%\n",
      "Epoch : 1 [115200/1395 (86%)]\tLoss: 0.035784\t F1:0.775%\n",
      "Epoch : 1 [120000/1395 (90%)]\tLoss: 0.057845\t F1:0.774%\n",
      "Epoch : 1 [124800/1395 (93%)]\tLoss: 0.046107\t F1:0.774%\n",
      "Epoch : 1 [129600/1395 (97%)]\tLoss: 0.053124\t F1:0.774%\n",
      "Validation F1 Score: 0.7568363483382416\n",
      "Epoch : 2 [0/1395 (0%)]\tLoss: 0.033833\t F1:0.773%\n",
      "Epoch : 2 [4800/1395 (4%)]\tLoss: 0.057576\t F1:0.800%\n",
      "Epoch : 2 [9600/1395 (7%)]\tLoss: 0.026576\t F1:0.802%\n",
      "Epoch : 2 [14400/1395 (11%)]\tLoss: 0.033158\t F1:0.798%\n",
      "Epoch : 2 [19200/1395 (14%)]\tLoss: 0.044517\t F1:0.798%\n",
      "Epoch : 2 [24000/1395 (18%)]\tLoss: 0.036083\t F1:0.798%\n",
      "Epoch : 2 [28800/1395 (22%)]\tLoss: 0.040705\t F1:0.797%\n",
      "Epoch : 2 [33600/1395 (25%)]\tLoss: 0.033573\t F1:0.797%\n",
      "Epoch : 2 [38400/1395 (29%)]\tLoss: 0.043728\t F1:0.795%\n",
      "Epoch : 2 [43200/1395 (32%)]\tLoss: 0.035558\t F1:0.795%\n",
      "Epoch : 2 [48000/1395 (36%)]\tLoss: 0.029002\t F1:0.795%\n",
      "Epoch : 2 [52800/1395 (39%)]\tLoss: 0.030316\t F1:0.795%\n",
      "Epoch : 2 [57600/1395 (43%)]\tLoss: 0.028255\t F1:0.795%\n",
      "Epoch : 2 [62400/1395 (47%)]\tLoss: 0.053213\t F1:0.794%\n",
      "Epoch : 2 [67200/1395 (50%)]\tLoss: 0.022716\t F1:0.793%\n",
      "Epoch : 2 [72000/1395 (54%)]\tLoss: 0.029240\t F1:0.793%\n",
      "Epoch : 2 [76800/1395 (57%)]\tLoss: 0.056364\t F1:0.792%\n",
      "Epoch : 2 [81600/1395 (61%)]\tLoss: 0.039210\t F1:0.791%\n",
      "Epoch : 2 [86400/1395 (65%)]\tLoss: 0.053106\t F1:0.789%\n",
      "Epoch : 2 [91200/1395 (68%)]\tLoss: 0.038927\t F1:0.790%\n",
      "Epoch : 2 [96000/1395 (72%)]\tLoss: 0.055905\t F1:0.789%\n",
      "Epoch : 2 [100800/1395 (75%)]\tLoss: 0.027048\t F1:0.789%\n",
      "Epoch : 2 [105600/1395 (79%)]\tLoss: 0.047553\t F1:0.788%\n",
      "Epoch : 2 [110400/1395 (82%)]\tLoss: 0.050125\t F1:0.789%\n",
      "Epoch : 2 [115200/1395 (86%)]\tLoss: 0.035048\t F1:0.788%\n",
      "Epoch : 2 [120000/1395 (90%)]\tLoss: 0.051569\t F1:0.787%\n",
      "Epoch : 2 [124800/1395 (93%)]\tLoss: 0.042376\t F1:0.787%\n",
      "Epoch : 2 [129600/1395 (97%)]\tLoss: 0.042896\t F1:0.787%\n",
      "Validation F1 Score: 0.7604943315289551\n",
      "Epoch : 3 [0/1395 (0%)]\tLoss: 0.034983\t F1:0.714%\n",
      "Epoch : 3 [4800/1395 (4%)]\tLoss: 0.053823\t F1:0.806%\n",
      "Epoch : 3 [9600/1395 (7%)]\tLoss: 0.025900\t F1:0.805%\n",
      "Epoch : 3 [14400/1395 (11%)]\tLoss: 0.029930\t F1:0.801%\n",
      "Epoch : 3 [19200/1395 (14%)]\tLoss: 0.032792\t F1:0.802%\n",
      "Epoch : 3 [24000/1395 (18%)]\tLoss: 0.038774\t F1:0.802%\n",
      "Epoch : 3 [28800/1395 (22%)]\tLoss: 0.034403\t F1:0.801%\n",
      "Epoch : 3 [33600/1395 (25%)]\tLoss: 0.028563\t F1:0.802%\n",
      "Epoch : 3 [38400/1395 (29%)]\tLoss: 0.041767\t F1:0.802%\n",
      "Epoch : 3 [43200/1395 (32%)]\tLoss: 0.037476\t F1:0.802%\n",
      "Epoch : 3 [48000/1395 (36%)]\tLoss: 0.030226\t F1:0.804%\n",
      "Epoch : 3 [52800/1395 (39%)]\tLoss: 0.028614\t F1:0.805%\n",
      "Epoch : 3 [57600/1395 (43%)]\tLoss: 0.031088\t F1:0.805%\n",
      "Epoch : 3 [62400/1395 (47%)]\tLoss: 0.055050\t F1:0.805%\n",
      "Epoch : 3 [67200/1395 (50%)]\tLoss: 0.026949\t F1:0.804%\n",
      "Epoch : 3 [72000/1395 (54%)]\tLoss: 0.025365\t F1:0.804%\n",
      "Epoch : 3 [76800/1395 (57%)]\tLoss: 0.051503\t F1:0.804%\n",
      "Epoch : 3 [81600/1395 (61%)]\tLoss: 0.041168\t F1:0.803%\n",
      "Epoch : 3 [86400/1395 (65%)]\tLoss: 0.040545\t F1:0.802%\n",
      "Epoch : 3 [91200/1395 (68%)]\tLoss: 0.039019\t F1:0.802%\n",
      "Epoch : 3 [96000/1395 (72%)]\tLoss: 0.059597\t F1:0.801%\n",
      "Epoch : 3 [100800/1395 (75%)]\tLoss: 0.025213\t F1:0.801%\n",
      "Epoch : 3 [105600/1395 (79%)]\tLoss: 0.044006\t F1:0.800%\n",
      "Epoch : 3 [110400/1395 (82%)]\tLoss: 0.041717\t F1:0.801%\n",
      "Epoch : 3 [115200/1395 (86%)]\tLoss: 0.031592\t F1:0.800%\n",
      "Epoch : 3 [120000/1395 (90%)]\tLoss: 0.055330\t F1:0.799%\n",
      "Epoch : 3 [124800/1395 (93%)]\tLoss: 0.044979\t F1:0.799%\n",
      "Epoch : 3 [129600/1395 (97%)]\tLoss: 0.046953\t F1:0.799%\n",
      "Validation F1 Score: 0.7462972828982418\n",
      "Epoch : 4 [0/1395 (0%)]\tLoss: 0.033813\t F1:0.756%\n",
      "Epoch : 4 [4800/1395 (4%)]\tLoss: 0.051878\t F1:0.831%\n",
      "Epoch : 4 [9600/1395 (7%)]\tLoss: 0.029248\t F1:0.827%\n",
      "Epoch : 4 [14400/1395 (11%)]\tLoss: 0.027035\t F1:0.819%\n",
      "Epoch : 4 [19200/1395 (14%)]\tLoss: 0.040481\t F1:0.820%\n",
      "Epoch : 4 [24000/1395 (18%)]\tLoss: 0.038222\t F1:0.819%\n",
      "Epoch : 4 [28800/1395 (22%)]\tLoss: 0.025738\t F1:0.817%\n",
      "Epoch : 4 [33600/1395 (25%)]\tLoss: 0.031191\t F1:0.817%\n",
      "Epoch : 4 [38400/1395 (29%)]\tLoss: 0.043781\t F1:0.816%\n",
      "Epoch : 4 [43200/1395 (32%)]\tLoss: 0.025022\t F1:0.817%\n",
      "Epoch : 4 [48000/1395 (36%)]\tLoss: 0.022472\t F1:0.818%\n",
      "Epoch : 4 [52800/1395 (39%)]\tLoss: 0.033379\t F1:0.819%\n",
      "Epoch : 4 [57600/1395 (43%)]\tLoss: 0.026810\t F1:0.819%\n",
      "Epoch : 4 [62400/1395 (47%)]\tLoss: 0.043592\t F1:0.820%\n",
      "Epoch : 4 [67200/1395 (50%)]\tLoss: 0.024635\t F1:0.818%\n",
      "Epoch : 4 [72000/1395 (54%)]\tLoss: 0.026190\t F1:0.818%\n",
      "Epoch : 4 [76800/1395 (57%)]\tLoss: 0.052660\t F1:0.818%\n",
      "Epoch : 4 [81600/1395 (61%)]\tLoss: 0.034952\t F1:0.817%\n",
      "Epoch : 4 [86400/1395 (65%)]\tLoss: 0.040419\t F1:0.816%\n",
      "Epoch : 4 [91200/1395 (68%)]\tLoss: 0.034974\t F1:0.816%\n",
      "Epoch : 4 [96000/1395 (72%)]\tLoss: 0.046840\t F1:0.815%\n",
      "Epoch : 4 [100800/1395 (75%)]\tLoss: 0.022032\t F1:0.815%\n",
      "Epoch : 4 [105600/1395 (79%)]\tLoss: 0.039611\t F1:0.814%\n",
      "Epoch : 4 [110400/1395 (82%)]\tLoss: 0.046297\t F1:0.814%\n",
      "Epoch : 4 [115200/1395 (86%)]\tLoss: 0.029720\t F1:0.813%\n",
      "Epoch : 4 [120000/1395 (90%)]\tLoss: 0.042075\t F1:0.813%\n",
      "Epoch : 4 [124800/1395 (93%)]\tLoss: 0.033788\t F1:0.813%\n",
      "Epoch : 4 [129600/1395 (97%)]\tLoss: 0.039726\t F1:0.813%\n",
      "Validation F1 Score: 0.7500260933096755\n",
      "Epoch : 5 [0/1395 (0%)]\tLoss: 0.035806\t F1:0.826%\n",
      "Epoch : 5 [4800/1395 (4%)]\tLoss: 0.041623\t F1:0.833%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-901c754b4d3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTCMFitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitF1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_y_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_X_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_y_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-5a4a5d3ca89c>\u001b[0m in \u001b[0;36mfitF1\u001b[1;34m(self, batched_X_train, batched_y_train, batched_X_test, batched_y_test)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[0mtruePreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatched_X_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatched_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[0mvar_X_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m                 \u001b[0mvar_y_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TCMFitter.fitF1(batched_X_train, batched_y_train, batched_X_test, batched_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(TCMFitter.model.state_dict(), \"TCM_4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
