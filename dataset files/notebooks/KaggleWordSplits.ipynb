{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"toxic-train-clean.csv\")\n",
    "comments = train[\"comment_text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordFiles = [\"identity_hateWordFile.txt\", \"insultWordFile.txt\", \"threatWordFile.txt\", \"toxicWordFile.txt\", \"obsceneWordFile.txt\", \"severe_toxicWordFile.txt\", \"toxicWordFile.txt\"]\n",
    "\n",
    "toxic_words = set([])\n",
    "\n",
    "for link in wordFiles:\n",
    "    word_file = open(link, \"r\")\n",
    "    toxic_words = toxic_words.union(set(word_file.read().split(\"\\n\")))\n",
    "\n",
    "# Only include words with length greater than or equal to 4\n",
    "toxic_words = set(filter(lambda x: len(x) >= 4, toxic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_threshold = 20000\n",
    "word_count_threshold = 900\n",
    "words_limit = 310000\n",
    "\n",
    "valid_characters = \" \" + \"@$\" + \"'!?-\" + \"abcdefghijklmnopqrstuvwxyz\" + \"abcdefghijklmnopqrstuvwxyz\".upper()\n",
    "valid_set = set(x for x in valid_characters)\n",
    "\n",
    "astericks_words = [('mother****ers', 'motherfuckers'), ('motherf*cking', 'motherfucking'), ('mother****er', 'motherfucker'), ('motherf*cker', 'motherfucker'), ('bullsh*t', 'bullshit'), ('f**cking', 'fucking'), ('f*ucking', 'fucking'), ('fu*cking', 'fucking'), ('****ing', 'fucking'), ('a**hole', 'asshole'), ('assh*le', 'asshole'), ('f******', 'fucking'), ('f*****g', 'fucking'), ('f***ing', 'fucking'), ('f**king', 'fucking'), ('f*cking', 'fucking'), ('fu**ing', 'fucking'), ('fu*king', 'fucking'), ('fuc*ers', 'fuckers'), ('f*****', 'fucking'), ('f***ed', 'fucked'), ('f**ker', 'fucker'), ('f*cked', 'fucked'), ('f*cker', 'fucker'), ('f*ckin', 'fucking'), ('fu*ker', 'fucker'), ('fuc**n', 'fucking'), ('ni**as', 'niggas'), ('b**ch', 'bitch'), ('b*tch', 'bitch'), ('c*unt', 'cunt'), ('f**ks', 'fucks'), ('f*ing', 'fucking'), ('ni**a', 'nigga'), ('c*ck', 'cock'), ('c*nt', 'cunt'), ('cr*p', 'crap'), ('d*ck', 'dick'), ('f***', 'fuck'), ('f**k', 'fuck'), ('f*ck', 'fuck'), ('fc*k', 'fuck'), ('fu**', 'fuck'), ('fu*k', 'fuck'), ('s***', 'shit'), ('s**t', 'shit'), ('sh**', 'shit'), ('sh*t', 'shit'), ('tw*t', 'twat')]\n",
    "\n",
    "def split_word(word, toxic_words):\n",
    "    if word == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    lower = word.lower()\n",
    "    for toxic_word in toxic_words:\n",
    "        lower = lower.replace(toxic_word, \" \" + toxic_word + \" \")\n",
    "        \n",
    "    return lower\n",
    "\n",
    "tknzr = TweetTokenizer(strip_handles=False, reduce_len=True)\n",
    "def word_tokenize(sentence):\n",
    "    sentence = sentence.replace(\"$\", \"s\")\n",
    "    sentence = sentence.replace(\"@\", \"a\")    \n",
    "    sentence = sentence.replace(\"!\", \" ! \")\n",
    "    sentence = sentence.replace(\"?\", \" ? \")\n",
    "    \n",
    "    return tknzr.tokenize(sentence)\n",
    "\n",
    "def normalize_comment(comment):\n",
    "    comment = unidecode(comment)\n",
    "    comment = comment[:length_threshold]\n",
    "    \n",
    "    normalized_words = []\n",
    "    \n",
    "    for w in astericks_words:\n",
    "        if w[0] in comment:\n",
    "            comment = comment.replace(w[0], w[1])\n",
    "        if w[0].upper() in comment:\n",
    "            comment = comment.replace(w[0].upper(), w[1].upper())\n",
    "    \n",
    "    for word in word_tokenize(comment):\n",
    "        #for (pattern, repl) in patterns:\n",
    "        #    word = re.sub(pattern, repl, word)\n",
    "\n",
    "        if word == \".\" or word == \",\":\n",
    "            normalized_words.append(word)\n",
    "            continue\n",
    "        \n",
    "        if word.count(\".\") == 1:\n",
    "            word = word.replace(\".\", \" \")\n",
    "        filtered_word = \"\".join([x for x in word if x in valid_set])\n",
    "                    \n",
    "        #For every word check if it has a toxic word as a part of it\n",
    "        #If so, split this word by swear and non-swear part.\n",
    "        normalized_word = split_word(filtered_word, toxic_words)\n",
    "\n",
    "        normalized_words.append(normalized_word)\n",
    "        \n",
    "    normalized_comment = \" \".join(normalized_words)\n",
    "    \n",
    "    result = []\n",
    "    for word in normalized_comment.split():\n",
    "        if word.upper() == word:\n",
    "            result.append(word)\n",
    "        else:\n",
    "            result.append(word.lower())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"word_splits\"] = train[\"comment_text\"].apply(normalize_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"toxic-train-kaggle-clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
