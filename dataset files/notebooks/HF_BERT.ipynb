{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"toxic-train-clean-small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\soobt\\.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at C:\\Users\\soobt\\.cache\\torch\\transformers\\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_tf_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-tf_model.h5 from cache at C:\\Users\\soobt\\.cache\\torch\\transformers\\d667df51ec24c20190f01fb4c20a21debc4c4fc12f7e2f5441ac0a99690e3ee9.4733ec82e81d40e9cf5fd04556267d8958fb150e9339390fc64206b7e5a79c83.h5\n",
      "INFO:transformers.modeling_tf_utils:Layers from pretrained model not used in TFBertModel: ['nsp___cls', 'mlm___cls']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = df[\"comment_text\"].apply(lambda x: tf.constant(tokenizer.encode(x, add_special_tokens=True))[None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "l = len(df)\n",
    "def get_vector(x):\n",
    "    global i\n",
    "    global l\n",
    "    i+=1\n",
    "    if i % 1000 == 0:\n",
    "        print(i, \"/\", l)\n",
    "    return model(x)[1][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 / 130285\n",
      "2000 / 130285\n",
      "3000 / 130285\n",
      "4000 / 130285\n",
      "5000 / 130285\n",
      "6000 / 130285\n",
      "7000 / 130285\n",
      "8000 / 130285\n",
      "9000 / 130285\n",
      "10000 / 130285\n",
      "11000 / 130285\n",
      "12000 / 130285\n",
      "13000 / 130285\n",
      "14000 / 130285\n",
      "15000 / 130285\n",
      "16000 / 130285\n",
      "17000 / 130285\n",
      "18000 / 130285\n",
      "19000 / 130285\n",
      "20000 / 130285\n",
      "21000 / 130285\n",
      "22000 / 130285\n",
      "23000 / 130285\n",
      "24000 / 130285\n",
      "25000 / 130285\n",
      "26000 / 130285\n",
      "27000 / 130285\n",
      "28000 / 130285\n",
      "29000 / 130285\n",
      "30000 / 130285\n",
      "31000 / 130285\n",
      "32000 / 130285\n",
      "33000 / 130285\n",
      "34000 / 130285\n",
      "35000 / 130285\n",
      "36000 / 130285\n",
      "37000 / 130285\n",
      "38000 / 130285\n",
      "39000 / 130285\n",
      "40000 / 130285\n",
      "41000 / 130285\n",
      "42000 / 130285\n",
      "43000 / 130285\n",
      "44000 / 130285\n",
      "45000 / 130285\n",
      "46000 / 130285\n",
      "47000 / 130285\n",
      "48000 / 130285\n",
      "49000 / 130285\n",
      "50000 / 130285\n",
      "51000 / 130285\n",
      "52000 / 130285\n",
      "53000 / 130285\n",
      "54000 / 130285\n",
      "55000 / 130285\n",
      "56000 / 130285\n",
      "57000 / 130285\n",
      "58000 / 130285\n",
      "59000 / 130285\n",
      "60000 / 130285\n",
      "61000 / 130285\n",
      "62000 / 130285\n",
      "63000 / 130285\n",
      "64000 / 130285\n",
      "65000 / 130285\n",
      "66000 / 130285\n",
      "67000 / 130285\n",
      "68000 / 130285\n",
      "69000 / 130285\n",
      "70000 / 130285\n",
      "71000 / 130285\n",
      "72000 / 130285\n",
      "73000 / 130285\n",
      "74000 / 130285\n",
      "75000 / 130285\n",
      "76000 / 130285\n",
      "77000 / 130285\n",
      "78000 / 130285\n",
      "79000 / 130285\n",
      "80000 / 130285\n",
      "81000 / 130285\n",
      "82000 / 130285\n",
      "83000 / 130285\n",
      "84000 / 130285\n",
      "85000 / 130285\n",
      "86000 / 130285\n",
      "87000 / 130285\n",
      "88000 / 130285\n",
      "89000 / 130285\n",
      "90000 / 130285\n",
      "91000 / 130285\n",
      "92000 / 130285\n",
      "93000 / 130285\n",
      "94000 / 130285\n",
      "95000 / 130285\n",
      "96000 / 130285\n",
      "97000 / 130285\n",
      "98000 / 130285\n",
      "99000 / 130285\n",
      "100000 / 130285\n",
      "101000 / 130285\n",
      "102000 / 130285\n",
      "103000 / 130285\n",
      "104000 / 130285\n",
      "105000 / 130285\n",
      "106000 / 130285\n",
      "107000 / 130285\n",
      "108000 / 130285\n",
      "109000 / 130285\n",
      "110000 / 130285\n",
      "111000 / 130285\n",
      "112000 / 130285\n",
      "113000 / 130285\n",
      "114000 / 130285\n",
      "115000 / 130285\n",
      "116000 / 130285\n",
      "117000 / 130285\n",
      "118000 / 130285\n",
      "119000 / 130285\n",
      "120000 / 130285\n",
      "121000 / 130285\n",
      "122000 / 130285\n",
      "123000 / 130285\n",
      "124000 / 130285\n",
      "125000 / 130285\n",
      "126000 / 130285\n",
      "127000 / 130285\n",
      "128000 / 130285\n",
      "129000 / 130285\n",
      "130000 / 130285\n"
     ]
    }
   ],
   "source": [
    "encodings = np.stack(input_ids.apply(get_vector).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('toxic_bert_matrix_small.out', encodings, delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
