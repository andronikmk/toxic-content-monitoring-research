{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUSBOOST Classifier With TFIDF\n",
    "\n",
    "**ROC-AUC:** 0.94934\n",
    "**F1-score:** 0.62395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "printable = set(string.printable)\n",
    "\n",
    "def clean_text(x):\n",
    "    \n",
    "    # remove newline characters\n",
    "    x = re.sub('\\\\n',' ',x)\n",
    "    # remove return characters\n",
    "    x = re.sub('\\\\r',' ',x)\n",
    "    x = x.strip()\n",
    "    # remove any text starting with User... \n",
    "    x = re.sub(\"\\[\\[User.*\", ' ', x)\n",
    "    # remove IP addresses or user IDs\n",
    "    x = re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\", ' ', x)\n",
    "    # remove URLs\n",
    "    x = re.sub(\"(http://.*?\\s)|(http://.*)\", ' ', x)\n",
    "    # remove non_printable characters eg unicode\n",
    "    x = \"\".join(list(filter(lambda c: c in printable, x)))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "df['none'] = 1-df[label_cols].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['comment_text'].apply(clean_text)\n",
    "y = df.iloc[:, 2:8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size= 0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 26.8min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 37.2min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 40.6min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 43.0min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 51.5min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 69.6min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed: 72.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 80.1min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 93.2min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 104.2min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed: 109.6min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 120.2min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 135.0min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 143.4min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 163.7min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 175.9min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 187.6min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed: 203.8min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed: 219.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 234.6min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed: 251.5min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 266.6min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed: 281.6min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed: 320.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=5,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='eng...\n",
       "                         'onevsrestclassifier__estimator__learning_rate': [0.25,\n",
       "                                                                           0.5,\n",
       "                                                                           0.75,\n",
       "                                                                           1],\n",
       "                         'onevsrestclassifier__estimator__n_estimators': [10,\n",
       "                                                                          50,\n",
       "                                                                          100,\n",
       "                                                                          250],\n",
       "                         'onevsrestclassifier__estimator__sampling_strategy': ['majority',\n",
       "                                                                               'not '\n",
       "                                                                               'minority',\n",
       "                                                                               'not '\n",
       "                                                                               'majority'],\n",
       "                         'tfidfvectorizer__max_features': [10000, 30000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(TfidfVectorizer(\n",
    "                                    stop_words='english',\n",
    "                                    strip_accents='unicode',\n",
    "                                    token_pattern=r'\\w{1,}', #accept tokens that have 1 or more characters\n",
    "                                    analyzer='word',\n",
    "                                    ngram_range=(1, 1),\n",
    "                                    min_df=5),\n",
    "                      OneVsRestClassifier(RUSBoostClassifier()))\n",
    "param_grid = {'tfidfvectorizer__max_features': [10000, 30000],\n",
    "              'onevsrestclassifier__estimator__algorithm': ['SAMME', 'SAMME.R'],\n",
    "              'onevsrestclassifier__estimator__sampling_strategy': ['majority', 'not minority', 'not majority'],\n",
    "              'onevsrestclassifier__estimator__n_estimators': [10, 50, 100, 250],\n",
    "              'onevsrestclassifier__estimator__learning_rate': [0.25, 0.5, 0.75, 1]\n",
    "             } \n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='roc_auc', verbose=10, n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'onevsrestclassifier__estimator__algorithm': 'SAMME.R',\n",
       " 'onevsrestclassifier__estimator__learning_rate': 0.5,\n",
       " 'onevsrestclassifier__estimator__n_estimators': 250,\n",
       " 'onevsrestclassifier__estimator__sampling_strategy': 'not majority',\n",
       " 'tfidfvectorizer__max_features': 30000}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9493412966535814"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, recall_score \n",
    "\n",
    "y_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6239501745777106"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Lab21)",
   "language": "python",
   "name": "lab21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
